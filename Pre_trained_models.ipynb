{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nM2o42If5oTo",
        "outputId": "2dc18d2c-a98b-4e10-8a5a-90ab0880fa28"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tf-watcher"
      ],
      "metadata": {
        "id": "I4tDQPOu0GEZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ovL4xmGz5rTq",
        "outputId": "b691b360-f4c7-4e6a-b7be-76eb4dca82f1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 2900 images belonging to 4 classes.\n",
            "Found 828 images belonging to 4 classes.\n",
            "Found 408 images belonging to 4 classes.\n"
          ]
        }
      ],
      "source": [
        "# Import Libraries\n",
        "\n",
        "import tensorflow as tf\n",
        "import keras\n",
        "import os\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense,Conv2D,MaxPool2D,Flatten, Dropout, BatchNormalization, Softmax, AveragePooling2D\n",
        "from keras.callbacks import EarlyStopping\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "from tensorflow.keras.applications import VGG16\n",
        "from tensorflow.keras.applications import DenseNet121\n",
        "from tensorflow.keras.models import Model\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "import tfwatcher\n",
        "import numpy\n",
        "import sklearn.metrics as metrics\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import ConfusionMatrixDisplay\n",
        "\n",
        "\n",
        "\n",
        "# Use ImageDataGenerator for data augmenntation\n",
        "train_datagen = ImageDataGenerator(rescale=1./255,\n",
        "                                   zoom_range = 0.4,\n",
        "                                   rotation_range = 10,\n",
        "                                   horizontal_flip = True,)\n",
        "valid_datagen = ImageDataGenerator(rescale=1./255,\n",
        "                                   zoom_range = 0.4,\n",
        "                                   rotation_range = 10,\n",
        "                                   horizontal_flip = True,)\n",
        "test_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "# Load the images\n",
        "train_generator = train_datagen.flow_from_directory(directory='/content/drive/MyDrive/Data/split_data_1/train', \n",
        "                                                    target_size=(224, 224),\n",
        "                                                    #color_mode=\"grayscale\",\n",
        "                                                    batch_size=32,\n",
        "                                                    class_mode=\"categorical\",\n",
        "                                                    shuffle=True,seed=42)\n",
        "\n",
        "valid_generator = valid_datagen.flow_from_directory(directory='/content/drive/MyDrive/Data/split_data_1/val', \n",
        "                                                    target_size=(224, 224),\n",
        "                                                    #color_mode=\"grayscale\",\n",
        "                                                    batch_size=32,\n",
        "                                                    class_mode=\"categorical\",\n",
        "                                                    shuffle=True,seed=42)\n",
        "\n",
        "\n",
        "test_generator = test_datagen.flow_from_directory(directory='/content/drive/MyDrive/Data/split_data_1/test',\n",
        "                                                  target_size=(224, 224),\n",
        "                                                  #color_mode=\"grayscale\",\n",
        "                                                  batch_size=1,\n",
        "                                                  class_mode=None,\n",
        "                                                  shuffle=False,\n",
        "                                                  seed=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F4R7TdPg5u9b",
        "outputId": "b2dc754b-bdbb-4214-b530-a3d1aa05c0f5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg16/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "58892288/58889256 [==============================] - 0s 0us/step\n",
            "58900480/58889256 [==============================] - 0s 0us/step\n",
            "Model: \"vgg16\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_1 (InputLayer)        [(None, 224, 224, 3)]     0         \n",
            "                                                                 \n",
            " block1_conv1 (Conv2D)       (None, 224, 224, 64)      1792      \n",
            "                                                                 \n",
            " block1_conv2 (Conv2D)       (None, 224, 224, 64)      36928     \n",
            "                                                                 \n",
            " block1_pool (MaxPooling2D)  (None, 112, 112, 64)      0         \n",
            "                                                                 \n",
            " block2_conv1 (Conv2D)       (None, 112, 112, 128)     73856     \n",
            "                                                                 \n",
            " block2_conv2 (Conv2D)       (None, 112, 112, 128)     147584    \n",
            "                                                                 \n",
            " block2_pool (MaxPooling2D)  (None, 56, 56, 128)       0         \n",
            "                                                                 \n",
            " block3_conv1 (Conv2D)       (None, 56, 56, 256)       295168    \n",
            "                                                                 \n",
            " block3_conv2 (Conv2D)       (None, 56, 56, 256)       590080    \n",
            "                                                                 \n",
            " block3_conv3 (Conv2D)       (None, 56, 56, 256)       590080    \n",
            "                                                                 \n",
            " block3_pool (MaxPooling2D)  (None, 28, 28, 256)       0         \n",
            "                                                                 \n",
            " block4_conv1 (Conv2D)       (None, 28, 28, 512)       1180160   \n",
            "                                                                 \n",
            " block4_conv2 (Conv2D)       (None, 28, 28, 512)       2359808   \n",
            "                                                                 \n",
            " block4_conv3 (Conv2D)       (None, 28, 28, 512)       2359808   \n",
            "                                                                 \n",
            " block4_pool (MaxPooling2D)  (None, 14, 14, 512)       0         \n",
            "                                                                 \n",
            " block5_conv1 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
            "                                                                 \n",
            " block5_conv2 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
            "                                                                 \n",
            " block5_conv3 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
            "                                                                 \n",
            " block5_pool (MaxPooling2D)  (None, 7, 7, 512)         0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 14,714,688\n",
            "Trainable params: 0\n",
            "Non-trainable params: 14,714,688\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "#Import base VGG16 model trained on imagenet\n",
        "IMAGE_SIZE = [224, 224]\n",
        "vgg16 = VGG16(input_shape= IMAGE_SIZE + [3], weights = 'imagenet', include_top = False)\n",
        "\n",
        "for layer in vgg16.layers:\n",
        "    layer.trainable = False\n",
        "    \n",
        "vgg16.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FUJewySO6VL1",
        "outputId": "5a76db5c-1e49-48a0-cc04-eb1045f96d2a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_1 (InputLayer)        [(None, 224, 224, 3)]     0         \n",
            "                                                                 \n",
            " block1_conv1 (Conv2D)       (None, 224, 224, 64)      1792      \n",
            "                                                                 \n",
            " block1_conv2 (Conv2D)       (None, 224, 224, 64)      36928     \n",
            "                                                                 \n",
            " block1_pool (MaxPooling2D)  (None, 112, 112, 64)      0         \n",
            "                                                                 \n",
            " block2_conv1 (Conv2D)       (None, 112, 112, 128)     73856     \n",
            "                                                                 \n",
            " block2_conv2 (Conv2D)       (None, 112, 112, 128)     147584    \n",
            "                                                                 \n",
            " block2_pool (MaxPooling2D)  (None, 56, 56, 128)       0         \n",
            "                                                                 \n",
            " block3_conv1 (Conv2D)       (None, 56, 56, 256)       295168    \n",
            "                                                                 \n",
            " block3_conv2 (Conv2D)       (None, 56, 56, 256)       590080    \n",
            "                                                                 \n",
            " block3_conv3 (Conv2D)       (None, 56, 56, 256)       590080    \n",
            "                                                                 \n",
            " block3_pool (MaxPooling2D)  (None, 28, 28, 256)       0         \n",
            "                                                                 \n",
            " block4_conv1 (Conv2D)       (None, 28, 28, 512)       1180160   \n",
            "                                                                 \n",
            " block4_conv2 (Conv2D)       (None, 28, 28, 512)       2359808   \n",
            "                                                                 \n",
            " block4_conv3 (Conv2D)       (None, 28, 28, 512)       2359808   \n",
            "                                                                 \n",
            " block4_pool (MaxPooling2D)  (None, 14, 14, 512)       0         \n",
            "                                                                 \n",
            " block5_conv1 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
            "                                                                 \n",
            " block5_conv2 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
            "                                                                 \n",
            " block5_conv3 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
            "                                                                 \n",
            " block5_pool (MaxPooling2D)  (None, 7, 7, 512)         0         \n",
            "                                                                 \n",
            " average_pooling2d (AverageP  (None, 1, 1, 512)        0         \n",
            " ooling2D)                                                       \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 512)               0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 32)                16416     \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 32)                0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 512)               16896     \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 4)                 2052      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 14,750,052\n",
            "Trainable params: 35,364\n",
            "Non-trainable params: 14,714,688\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "#Add extra layers to VGG16\n",
        "no_of_categories = 4\n",
        "x =  AveragePooling2D(pool_size = (4, 4))(vgg16.output)\n",
        "x = Flatten()(x)\n",
        "x = Dense(units = 32, activation = 'relu')(x)\n",
        "x = Dropout(0.2)(x)\n",
        "x = Dense(units = 512, activation = 'relu')(x)\n",
        "predictions = Dense(units = no_of_categories, activation = tf.nn.softmax)(x)\n",
        "model = Model(inputs = vgg16.input, outputs = predictions)\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QXw5-sbJ58j0"
      },
      "outputs": [],
      "source": [
        "#Create Callback methods for model\n",
        "EarlyStoppingCallBack = EarlyStopping(monitor='val_accuracy', mode='max', verbose=1, patience=20)\n",
        "CheckPointCallback = ModelCheckpoint(\"chest-xray.h5\", monitor='val_loss',save_best_only=True, mode='min',verbose=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0rKe1SSd6BFn"
      },
      "outputs": [],
      "source": [
        "#Compile the model\n",
        "model.compile(optimizer = 'adam', \n",
        "              loss = 'categorical_crossentropy', \n",
        "              metrics = ['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8E73XpuS6FTb",
        "outputId": "ff4f3380-1ed8-4341-a672-eb0e73da1b79"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "91/91 [==============================] - ETA: 0s - loss: 1.2672 - accuracy: 0.4124\n",
            "Epoch 1: val_loss improved from inf to 1.02591, saving model to chest-xray.h5\n",
            "91/91 [==============================] - 82s 889ms/step - loss: 1.2672 - accuracy: 0.4124 - val_loss: 1.0259 - val_accuracy: 0.5942\n",
            "Epoch 2/100\n",
            "91/91 [==============================] - ETA: 0s - loss: 0.9713 - accuracy: 0.5841\n",
            "Epoch 2: val_loss improved from 1.02591 to 0.84014, saving model to chest-xray.h5\n",
            "91/91 [==============================] - 80s 879ms/step - loss: 0.9713 - accuracy: 0.5841 - val_loss: 0.8401 - val_accuracy: 0.6679\n",
            "Epoch 3/100\n",
            "91/91 [==============================] - ETA: 0s - loss: 0.8216 - accuracy: 0.6631\n",
            "Epoch 3: val_loss improved from 0.84014 to 0.72891, saving model to chest-xray.h5\n",
            "91/91 [==============================] - 79s 868ms/step - loss: 0.8216 - accuracy: 0.6631 - val_loss: 0.7289 - val_accuracy: 0.6981\n",
            "Epoch 4/100\n",
            "91/91 [==============================] - ETA: 0s - loss: 0.7607 - accuracy: 0.6834\n",
            "Epoch 4: val_loss improved from 0.72891 to 0.70329, saving model to chest-xray.h5\n",
            "91/91 [==============================] - 79s 872ms/step - loss: 0.7607 - accuracy: 0.6834 - val_loss: 0.7033 - val_accuracy: 0.7114\n",
            "Epoch 5/100\n",
            "91/91 [==============================] - ETA: 0s - loss: 0.7377 - accuracy: 0.6948\n",
            "Epoch 5: val_loss improved from 0.70329 to 0.65049, saving model to chest-xray.h5\n",
            "91/91 [==============================] - 80s 877ms/step - loss: 0.7377 - accuracy: 0.6948 - val_loss: 0.6505 - val_accuracy: 0.7307\n",
            "Epoch 6/100\n",
            "91/91 [==============================] - ETA: 0s - loss: 0.7022 - accuracy: 0.7124\n",
            "Epoch 6: val_loss did not improve from 0.65049\n",
            "91/91 [==============================] - 79s 872ms/step - loss: 0.7022 - accuracy: 0.7124 - val_loss: 0.7653 - val_accuracy: 0.6957\n",
            "Epoch 7/100\n",
            "91/91 [==============================] - ETA: 0s - loss: 0.6875 - accuracy: 0.7166\n",
            "Epoch 7: val_loss improved from 0.65049 to 0.63649, saving model to chest-xray.h5\n",
            "91/91 [==============================] - 78s 857ms/step - loss: 0.6875 - accuracy: 0.7166 - val_loss: 0.6365 - val_accuracy: 0.7524\n",
            "Epoch 8/100\n",
            "91/91 [==============================] - ETA: 0s - loss: 0.6751 - accuracy: 0.7314\n",
            "Epoch 8: val_loss did not improve from 0.63649\n",
            "91/91 [==============================] - 78s 851ms/step - loss: 0.6751 - accuracy: 0.7314 - val_loss: 0.6439 - val_accuracy: 0.7355\n",
            "Epoch 9/100\n",
            "91/91 [==============================] - ETA: 0s - loss: 0.6608 - accuracy: 0.7379\n",
            "Epoch 9: val_loss improved from 0.63649 to 0.63598, saving model to chest-xray.h5\n",
            "91/91 [==============================] - 78s 848ms/step - loss: 0.6608 - accuracy: 0.7379 - val_loss: 0.6360 - val_accuracy: 0.7415\n",
            "Epoch 10/100\n",
            "91/91 [==============================] - ETA: 0s - loss: 0.6470 - accuracy: 0.7524\n",
            "Epoch 10: val_loss improved from 0.63598 to 0.60256, saving model to chest-xray.h5\n",
            "91/91 [==============================] - 78s 855ms/step - loss: 0.6470 - accuracy: 0.7524 - val_loss: 0.6026 - val_accuracy: 0.7355\n",
            "Epoch 11/100\n",
            "91/91 [==============================] - ETA: 0s - loss: 0.6084 - accuracy: 0.7476\n",
            "Epoch 11: val_loss improved from 0.60256 to 0.57163, saving model to chest-xray.h5\n",
            "91/91 [==============================] - 77s 851ms/step - loss: 0.6084 - accuracy: 0.7476 - val_loss: 0.5716 - val_accuracy: 0.7560\n",
            "Epoch 12/100\n",
            "91/91 [==============================] - ETA: 0s - loss: 0.5632 - accuracy: 0.7707\n",
            "Epoch 12: val_loss did not improve from 0.57163\n",
            "91/91 [==============================] - 78s 853ms/step - loss: 0.5632 - accuracy: 0.7707 - val_loss: 0.5982 - val_accuracy: 0.7452\n",
            "Epoch 13/100\n",
            "91/91 [==============================] - ETA: 0s - loss: 0.5904 - accuracy: 0.7569\n",
            "Epoch 13: val_loss improved from 0.57163 to 0.55483, saving model to chest-xray.h5\n",
            "91/91 [==============================] - 78s 855ms/step - loss: 0.5904 - accuracy: 0.7569 - val_loss: 0.5548 - val_accuracy: 0.7802\n",
            "Epoch 14/100\n",
            "91/91 [==============================] - ETA: 0s - loss: 0.5632 - accuracy: 0.7734\n",
            "Epoch 14: val_loss did not improve from 0.55483\n",
            "91/91 [==============================] - 78s 854ms/step - loss: 0.5632 - accuracy: 0.7734 - val_loss: 0.5699 - val_accuracy: 0.7681\n",
            "Epoch 15/100\n",
            "91/91 [==============================] - ETA: 0s - loss: 0.5684 - accuracy: 0.7600\n",
            "Epoch 15: val_loss did not improve from 0.55483\n",
            "91/91 [==============================] - 78s 855ms/step - loss: 0.5684 - accuracy: 0.7600 - val_loss: 0.5667 - val_accuracy: 0.7621\n",
            "Epoch 16/100\n",
            "91/91 [==============================] - ETA: 0s - loss: 0.5675 - accuracy: 0.7628\n",
            "Epoch 16: val_loss did not improve from 0.55483\n",
            "91/91 [==============================] - 77s 852ms/step - loss: 0.5675 - accuracy: 0.7628 - val_loss: 0.5773 - val_accuracy: 0.7705\n",
            "Epoch 17/100\n",
            "91/91 [==============================] - ETA: 0s - loss: 0.5584 - accuracy: 0.7669\n",
            "Epoch 17: val_loss improved from 0.55483 to 0.54624, saving model to chest-xray.h5\n",
            "91/91 [==============================] - 78s 855ms/step - loss: 0.5584 - accuracy: 0.7669 - val_loss: 0.5462 - val_accuracy: 0.7645\n",
            "Epoch 18/100\n",
            "91/91 [==============================] - ETA: 0s - loss: 0.5544 - accuracy: 0.7748\n",
            "Epoch 18: val_loss improved from 0.54624 to 0.51492, saving model to chest-xray.h5\n",
            "91/91 [==============================] - 78s 857ms/step - loss: 0.5544 - accuracy: 0.7748 - val_loss: 0.5149 - val_accuracy: 0.7766\n",
            "Epoch 19/100\n",
            "91/91 [==============================] - ETA: 0s - loss: 0.5677 - accuracy: 0.7697\n",
            "Epoch 19: val_loss did not improve from 0.51492\n",
            "91/91 [==============================] - 78s 856ms/step - loss: 0.5677 - accuracy: 0.7697 - val_loss: 0.5279 - val_accuracy: 0.7802\n",
            "Epoch 20/100\n",
            "91/91 [==============================] - ETA: 0s - loss: 0.5446 - accuracy: 0.7790\n",
            "Epoch 20: val_loss did not improve from 0.51492\n",
            "91/91 [==============================] - 78s 853ms/step - loss: 0.5446 - accuracy: 0.7790 - val_loss: 0.5556 - val_accuracy: 0.7645\n",
            "Epoch 21/100\n",
            "91/91 [==============================] - ETA: 0s - loss: 0.5404 - accuracy: 0.7721\n",
            "Epoch 21: val_loss did not improve from 0.51492\n",
            "91/91 [==============================] - 79s 874ms/step - loss: 0.5404 - accuracy: 0.7721 - val_loss: 0.5582 - val_accuracy: 0.7766\n",
            "Epoch 22/100\n",
            "91/91 [==============================] - ETA: 0s - loss: 0.5293 - accuracy: 0.7821\n",
            "Epoch 22: val_loss did not improve from 0.51492\n",
            "91/91 [==============================] - 80s 876ms/step - loss: 0.5293 - accuracy: 0.7821 - val_loss: 0.5653 - val_accuracy: 0.7681\n",
            "Epoch 23/100\n",
            "91/91 [==============================] - ETA: 0s - loss: 0.5450 - accuracy: 0.7800\n",
            "Epoch 23: val_loss did not improve from 0.51492\n",
            "91/91 [==============================] - 78s 862ms/step - loss: 0.5450 - accuracy: 0.7800 - val_loss: 0.5280 - val_accuracy: 0.7729\n",
            "Epoch 24/100\n",
            "91/91 [==============================] - ETA: 0s - loss: 0.5233 - accuracy: 0.7910\n",
            "Epoch 24: val_loss did not improve from 0.51492\n",
            "91/91 [==============================] - 77s 852ms/step - loss: 0.5233 - accuracy: 0.7910 - val_loss: 0.5330 - val_accuracy: 0.7826\n",
            "Epoch 25/100\n",
            "91/91 [==============================] - ETA: 0s - loss: 0.5174 - accuracy: 0.7859\n",
            "Epoch 25: val_loss improved from 0.51492 to 0.49983, saving model to chest-xray.h5\n",
            "91/91 [==============================] - 78s 852ms/step - loss: 0.5174 - accuracy: 0.7859 - val_loss: 0.4998 - val_accuracy: 0.7838\n",
            "Epoch 26/100\n",
            "91/91 [==============================] - ETA: 0s - loss: 0.5125 - accuracy: 0.7966\n",
            "Epoch 26: val_loss improved from 0.49983 to 0.49443, saving model to chest-xray.h5\n",
            "91/91 [==============================] - 78s 854ms/step - loss: 0.5125 - accuracy: 0.7966 - val_loss: 0.4944 - val_accuracy: 0.7971\n",
            "Epoch 27/100\n",
            "91/91 [==============================] - ETA: 0s - loss: 0.5257 - accuracy: 0.7876\n",
            "Epoch 27: val_loss improved from 0.49443 to 0.49291, saving model to chest-xray.h5\n",
            "91/91 [==============================] - 78s 856ms/step - loss: 0.5257 - accuracy: 0.7876 - val_loss: 0.4929 - val_accuracy: 0.7971\n",
            "Epoch 28/100\n",
            "91/91 [==============================] - ETA: 0s - loss: 0.5131 - accuracy: 0.7841\n",
            "Epoch 28: val_loss did not improve from 0.49291\n",
            "91/91 [==============================] - 77s 849ms/step - loss: 0.5131 - accuracy: 0.7841 - val_loss: 0.5161 - val_accuracy: 0.7850\n",
            "Epoch 29/100\n",
            "91/91 [==============================] - ETA: 0s - loss: 0.5025 - accuracy: 0.7959\n",
            "Epoch 29: val_loss did not improve from 0.49291\n",
            "91/91 [==============================] - 77s 845ms/step - loss: 0.5025 - accuracy: 0.7959 - val_loss: 0.5578 - val_accuracy: 0.7669\n",
            "Epoch 30/100\n",
            "91/91 [==============================] - ETA: 0s - loss: 0.5201 - accuracy: 0.7962\n",
            "Epoch 30: val_loss did not improve from 0.49291\n",
            "91/91 [==============================] - 77s 848ms/step - loss: 0.5201 - accuracy: 0.7962 - val_loss: 0.5056 - val_accuracy: 0.7754\n",
            "Epoch 31/100\n",
            "91/91 [==============================] - ETA: 0s - loss: 0.5287 - accuracy: 0.7879\n",
            "Epoch 31: val_loss did not improve from 0.49291\n",
            "91/91 [==============================] - 77s 848ms/step - loss: 0.5287 - accuracy: 0.7879 - val_loss: 0.5476 - val_accuracy: 0.7693\n",
            "Epoch 32/100\n",
            "91/91 [==============================] - ETA: 0s - loss: 0.5052 - accuracy: 0.7897\n",
            "Epoch 32: val_loss did not improve from 0.49291\n",
            "91/91 [==============================] - 77s 850ms/step - loss: 0.5052 - accuracy: 0.7897 - val_loss: 0.5361 - val_accuracy: 0.7766\n",
            "Epoch 33/100\n",
            "91/91 [==============================] - ETA: 0s - loss: 0.4874 - accuracy: 0.8028\n",
            "Epoch 33: val_loss did not improve from 0.49291\n",
            "91/91 [==============================] - 77s 847ms/step - loss: 0.4874 - accuracy: 0.8028 - val_loss: 0.5222 - val_accuracy: 0.7874\n",
            "Epoch 34/100\n",
            "91/91 [==============================] - ETA: 0s - loss: 0.4894 - accuracy: 0.8041\n",
            "Epoch 34: val_loss did not improve from 0.49291\n",
            "91/91 [==============================] - 77s 848ms/step - loss: 0.4894 - accuracy: 0.8041 - val_loss: 0.5031 - val_accuracy: 0.7862\n",
            "Epoch 35/100\n",
            "91/91 [==============================] - ETA: 0s - loss: 0.5194 - accuracy: 0.7921\n",
            "Epoch 35: val_loss did not improve from 0.49291\n",
            "91/91 [==============================] - 77s 843ms/step - loss: 0.5194 - accuracy: 0.7921 - val_loss: 0.5176 - val_accuracy: 0.7935\n",
            "Epoch 36/100\n",
            "91/91 [==============================] - ETA: 0s - loss: 0.4998 - accuracy: 0.7969\n",
            "Epoch 36: val_loss did not improve from 0.49291\n",
            "91/91 [==============================] - 77s 844ms/step - loss: 0.4998 - accuracy: 0.7969 - val_loss: 0.5477 - val_accuracy: 0.7681\n",
            "Epoch 37/100\n",
            "91/91 [==============================] - ETA: 0s - loss: 0.5045 - accuracy: 0.7976\n",
            "Epoch 37: val_loss did not improve from 0.49291\n",
            "91/91 [==============================] - 77s 850ms/step - loss: 0.5045 - accuracy: 0.7976 - val_loss: 0.5077 - val_accuracy: 0.7790\n",
            "Epoch 38/100\n",
            "91/91 [==============================] - ETA: 0s - loss: 0.5041 - accuracy: 0.7917\n",
            "Epoch 38: val_loss did not improve from 0.49291\n",
            "91/91 [==============================] - 77s 846ms/step - loss: 0.5041 - accuracy: 0.7917 - val_loss: 0.4975 - val_accuracy: 0.7886\n",
            "Epoch 39/100\n",
            "91/91 [==============================] - ETA: 0s - loss: 0.5021 - accuracy: 0.7883\n",
            "Epoch 39: val_loss did not improve from 0.49291\n",
            "91/91 [==============================] - 77s 844ms/step - loss: 0.5021 - accuracy: 0.7883 - val_loss: 0.5719 - val_accuracy: 0.7657\n",
            "Epoch 40/100\n",
            "91/91 [==============================] - ETA: 0s - loss: 0.5122 - accuracy: 0.7931\n",
            "Epoch 40: val_loss improved from 0.49291 to 0.46259, saving model to chest-xray.h5\n",
            "91/91 [==============================] - 77s 848ms/step - loss: 0.5122 - accuracy: 0.7931 - val_loss: 0.4626 - val_accuracy: 0.7862\n",
            "Epoch 41/100\n",
            "91/91 [==============================] - ETA: 0s - loss: 0.5108 - accuracy: 0.7972\n",
            "Epoch 41: val_loss did not improve from 0.46259\n",
            "91/91 [==============================] - 77s 854ms/step - loss: 0.5108 - accuracy: 0.7972 - val_loss: 0.4916 - val_accuracy: 0.7911\n",
            "Epoch 42/100\n",
            "91/91 [==============================] - ETA: 0s - loss: 0.4788 - accuracy: 0.8062\n",
            "Epoch 42: val_loss did not improve from 0.46259\n",
            "91/91 [==============================] - 77s 848ms/step - loss: 0.4788 - accuracy: 0.8062 - val_loss: 0.5320 - val_accuracy: 0.7850\n",
            "Epoch 43/100\n",
            "91/91 [==============================] - ETA: 0s - loss: 0.4857 - accuracy: 0.8031\n",
            "Epoch 43: val_loss did not improve from 0.46259\n",
            "91/91 [==============================] - 78s 852ms/step - loss: 0.4857 - accuracy: 0.8031 - val_loss: 0.5116 - val_accuracy: 0.7862\n",
            "Epoch 44/100\n",
            "91/91 [==============================] - ETA: 0s - loss: 0.4784 - accuracy: 0.8079\n",
            "Epoch 44: val_loss did not improve from 0.46259\n",
            "91/91 [==============================] - 78s 860ms/step - loss: 0.4784 - accuracy: 0.8079 - val_loss: 0.4770 - val_accuracy: 0.7935\n",
            "Epoch 45/100\n",
            "91/91 [==============================] - ETA: 0s - loss: 0.4873 - accuracy: 0.7990\n",
            "Epoch 45: val_loss improved from 0.46259 to 0.45305, saving model to chest-xray.h5\n",
            "91/91 [==============================] - 79s 872ms/step - loss: 0.4873 - accuracy: 0.7990 - val_loss: 0.4530 - val_accuracy: 0.8116\n",
            "Epoch 46/100\n",
            "91/91 [==============================] - ETA: 0s - loss: 0.4847 - accuracy: 0.7976\n",
            "Epoch 46: val_loss did not improve from 0.45305\n",
            "91/91 [==============================] - 77s 850ms/step - loss: 0.4847 - accuracy: 0.7976 - val_loss: 0.4933 - val_accuracy: 0.7923\n",
            "Epoch 47/100\n",
            "91/91 [==============================] - ETA: 0s - loss: 0.4988 - accuracy: 0.7969\n",
            "Epoch 47: val_loss did not improve from 0.45305\n",
            "91/91 [==============================] - 77s 846ms/step - loss: 0.4988 - accuracy: 0.7969 - val_loss: 0.4794 - val_accuracy: 0.7971\n",
            "Epoch 48/100\n",
            "91/91 [==============================] - ETA: 0s - loss: 0.4803 - accuracy: 0.8100\n",
            "Epoch 48: val_loss did not improve from 0.45305\n",
            "91/91 [==============================] - 77s 849ms/step - loss: 0.4803 - accuracy: 0.8100 - val_loss: 0.4701 - val_accuracy: 0.8019\n",
            "Epoch 49/100\n",
            "91/91 [==============================] - ETA: 0s - loss: 0.4748 - accuracy: 0.7979\n",
            "Epoch 49: val_loss did not improve from 0.45305\n",
            "91/91 [==============================] - 77s 849ms/step - loss: 0.4748 - accuracy: 0.7979 - val_loss: 0.4850 - val_accuracy: 0.7838\n",
            "Epoch 50/100\n",
            "91/91 [==============================] - ETA: 0s - loss: 0.4945 - accuracy: 0.7931\n",
            "Epoch 50: val_loss did not improve from 0.45305\n",
            "91/91 [==============================] - 77s 850ms/step - loss: 0.4945 - accuracy: 0.7931 - val_loss: 0.4746 - val_accuracy: 0.8019\n",
            "Epoch 51/100\n",
            "91/91 [==============================] - ETA: 0s - loss: 0.4949 - accuracy: 0.7997\n",
            "Epoch 51: val_loss did not improve from 0.45305\n",
            "91/91 [==============================] - 77s 844ms/step - loss: 0.4949 - accuracy: 0.7997 - val_loss: 0.5113 - val_accuracy: 0.7886\n",
            "Epoch 52/100\n",
            "91/91 [==============================] - ETA: 0s - loss: 0.4899 - accuracy: 0.8007\n",
            "Epoch 52: val_loss did not improve from 0.45305\n",
            "91/91 [==============================] - 77s 845ms/step - loss: 0.4899 - accuracy: 0.8007 - val_loss: 0.5078 - val_accuracy: 0.7899\n",
            "Epoch 53/100\n",
            "91/91 [==============================] - ETA: 0s - loss: 0.4704 - accuracy: 0.8083\n",
            "Epoch 53: val_loss did not improve from 0.45305\n",
            "91/91 [==============================] - 77s 848ms/step - loss: 0.4704 - accuracy: 0.8083 - val_loss: 0.5186 - val_accuracy: 0.8068\n",
            "Epoch 54/100\n",
            "91/91 [==============================] - ETA: 0s - loss: 0.4659 - accuracy: 0.8162\n",
            "Epoch 54: val_loss did not improve from 0.45305\n",
            "91/91 [==============================] - 77s 849ms/step - loss: 0.4659 - accuracy: 0.8162 - val_loss: 0.4869 - val_accuracy: 0.8007\n",
            "Epoch 55/100\n",
            "91/91 [==============================] - ETA: 0s - loss: 0.5050 - accuracy: 0.7917\n",
            "Epoch 55: val_loss did not improve from 0.45305\n",
            "91/91 [==============================] - 77s 842ms/step - loss: 0.5050 - accuracy: 0.7917 - val_loss: 0.4668 - val_accuracy: 0.8140\n",
            "Epoch 56/100\n",
            "91/91 [==============================] - ETA: 0s - loss: 0.5009 - accuracy: 0.7928\n",
            "Epoch 56: val_loss improved from 0.45305 to 0.45219, saving model to chest-xray.h5\n",
            "91/91 [==============================] - 77s 852ms/step - loss: 0.5009 - accuracy: 0.7928 - val_loss: 0.4522 - val_accuracy: 0.8092\n",
            "Epoch 57/100\n",
            "91/91 [==============================] - ETA: 0s - loss: 0.4762 - accuracy: 0.8038\n",
            "Epoch 57: val_loss did not improve from 0.45219\n",
            "91/91 [==============================] - 77s 846ms/step - loss: 0.4762 - accuracy: 0.8038 - val_loss: 0.4923 - val_accuracy: 0.7790\n",
            "Epoch 58/100\n",
            "91/91 [==============================] - ETA: 0s - loss: 0.4760 - accuracy: 0.8021\n",
            "Epoch 58: val_loss did not improve from 0.45219\n",
            "91/91 [==============================] - 77s 848ms/step - loss: 0.4760 - accuracy: 0.8021 - val_loss: 0.4849 - val_accuracy: 0.7995\n",
            "Epoch 59/100\n",
            "91/91 [==============================] - ETA: 0s - loss: 0.4503 - accuracy: 0.8210\n",
            "Epoch 59: val_loss did not improve from 0.45219\n",
            "91/91 [==============================] - 77s 846ms/step - loss: 0.4503 - accuracy: 0.8210 - val_loss: 0.4688 - val_accuracy: 0.8068\n",
            "Epoch 60/100\n",
            "91/91 [==============================] - ETA: 0s - loss: 0.4708 - accuracy: 0.8076\n",
            "Epoch 60: val_loss did not improve from 0.45219\n",
            "91/91 [==============================] - 77s 849ms/step - loss: 0.4708 - accuracy: 0.8076 - val_loss: 0.4706 - val_accuracy: 0.7899\n",
            "Epoch 61/100\n",
            "91/91 [==============================] - ETA: 0s - loss: 0.4732 - accuracy: 0.8076\n",
            "Epoch 61: val_loss improved from 0.45219 to 0.43262, saving model to chest-xray.h5\n",
            "91/91 [==============================] - 78s 852ms/step - loss: 0.4732 - accuracy: 0.8076 - val_loss: 0.4326 - val_accuracy: 0.8261\n",
            "Epoch 62/100\n",
            "91/91 [==============================] - ETA: 0s - loss: 0.4401 - accuracy: 0.8210\n",
            "Epoch 62: val_loss did not improve from 0.43262\n",
            "91/91 [==============================] - 77s 850ms/step - loss: 0.4401 - accuracy: 0.8210 - val_loss: 0.4831 - val_accuracy: 0.7911\n",
            "Epoch 63/100\n",
            "91/91 [==============================] - ETA: 0s - loss: 0.4563 - accuracy: 0.8107\n",
            "Epoch 63: val_loss did not improve from 0.43262\n",
            "91/91 [==============================] - 77s 850ms/step - loss: 0.4563 - accuracy: 0.8107 - val_loss: 0.5064 - val_accuracy: 0.7923\n",
            "Epoch 64/100\n",
            "91/91 [==============================] - ETA: 0s - loss: 0.4413 - accuracy: 0.8172\n",
            "Epoch 64: val_loss did not improve from 0.43262\n",
            "91/91 [==============================] - 77s 848ms/step - loss: 0.4413 - accuracy: 0.8172 - val_loss: 0.4886 - val_accuracy: 0.7959\n",
            "Epoch 65/100\n",
            "91/91 [==============================] - ETA: 0s - loss: 0.4606 - accuracy: 0.8100\n",
            "Epoch 65: val_loss did not improve from 0.43262\n",
            "91/91 [==============================] - 77s 849ms/step - loss: 0.4606 - accuracy: 0.8100 - val_loss: 0.4733 - val_accuracy: 0.8068\n",
            "Epoch 66/100\n",
            "91/91 [==============================] - ETA: 0s - loss: 0.4497 - accuracy: 0.8183\n",
            "Epoch 66: val_loss did not improve from 0.43262\n",
            "91/91 [==============================] - 77s 848ms/step - loss: 0.4497 - accuracy: 0.8183 - val_loss: 0.4851 - val_accuracy: 0.8152\n",
            "Epoch 67/100\n",
            "91/91 [==============================] - ETA: 0s - loss: 0.4390 - accuracy: 0.8272\n",
            "Epoch 67: val_loss did not improve from 0.43262\n",
            "91/91 [==============================] - 77s 847ms/step - loss: 0.4390 - accuracy: 0.8272 - val_loss: 0.4624 - val_accuracy: 0.7959\n",
            "Epoch 68/100\n",
            "91/91 [==============================] - ETA: 0s - loss: 0.4458 - accuracy: 0.8162\n",
            "Epoch 68: val_loss did not improve from 0.43262\n",
            "91/91 [==============================] - 77s 845ms/step - loss: 0.4458 - accuracy: 0.8162 - val_loss: 0.4784 - val_accuracy: 0.7983\n",
            "Epoch 69/100\n",
            "91/91 [==============================] - ETA: 0s - loss: 0.4468 - accuracy: 0.8186\n",
            "Epoch 69: val_loss did not improve from 0.43262\n",
            "91/91 [==============================] - 77s 843ms/step - loss: 0.4468 - accuracy: 0.8186 - val_loss: 0.4968 - val_accuracy: 0.7874\n",
            "Epoch 70/100\n",
            "91/91 [==============================] - ETA: 0s - loss: 0.4370 - accuracy: 0.8248\n",
            "Epoch 70: val_loss did not improve from 0.43262\n",
            "91/91 [==============================] - 77s 841ms/step - loss: 0.4370 - accuracy: 0.8248 - val_loss: 0.4780 - val_accuracy: 0.8043\n",
            "Epoch 71/100\n",
            "91/91 [==============================] - ETA: 0s - loss: 0.4680 - accuracy: 0.8117\n",
            "Epoch 71: val_loss did not improve from 0.43262\n",
            "91/91 [==============================] - 76s 840ms/step - loss: 0.4680 - accuracy: 0.8117 - val_loss: 0.4933 - val_accuracy: 0.7971\n",
            "Epoch 72/100\n",
            "91/91 [==============================] - ETA: 0s - loss: 0.4535 - accuracy: 0.8155\n",
            "Epoch 72: val_loss did not improve from 0.43262\n",
            "91/91 [==============================] - 76s 838ms/step - loss: 0.4535 - accuracy: 0.8155 - val_loss: 0.4340 - val_accuracy: 0.8213\n",
            "Epoch 73/100\n",
            "91/91 [==============================] - ETA: 0s - loss: 0.4657 - accuracy: 0.8090\n",
            "Epoch 73: val_loss did not improve from 0.43262\n",
            "91/91 [==============================] - 76s 840ms/step - loss: 0.4657 - accuracy: 0.8090 - val_loss: 0.5107 - val_accuracy: 0.7874\n",
            "Epoch 74/100\n",
            "91/91 [==============================] - ETA: 0s - loss: 0.4577 - accuracy: 0.8138\n",
            "Epoch 74: val_loss did not improve from 0.43262\n",
            "91/91 [==============================] - 76s 842ms/step - loss: 0.4577 - accuracy: 0.8138 - val_loss: 0.4460 - val_accuracy: 0.8116\n",
            "Epoch 75/100\n",
            "91/91 [==============================] - ETA: 0s - loss: 0.4563 - accuracy: 0.8145\n",
            "Epoch 75: val_loss did not improve from 0.43262\n",
            "91/91 [==============================] - 77s 840ms/step - loss: 0.4563 - accuracy: 0.8145 - val_loss: 0.4728 - val_accuracy: 0.8249\n",
            "Epoch 76/100\n",
            "91/91 [==============================] - ETA: 0s - loss: 0.4472 - accuracy: 0.8203\n",
            "Epoch 76: val_loss did not improve from 0.43262\n",
            "91/91 [==============================] - 76s 839ms/step - loss: 0.4472 - accuracy: 0.8203 - val_loss: 0.4624 - val_accuracy: 0.8080\n",
            "Epoch 77/100\n",
            "91/91 [==============================] - ETA: 0s - loss: 0.4662 - accuracy: 0.8131\n",
            "Epoch 77: val_loss did not improve from 0.43262\n",
            "91/91 [==============================] - 77s 843ms/step - loss: 0.4662 - accuracy: 0.8131 - val_loss: 0.4484 - val_accuracy: 0.8140\n",
            "Epoch 78/100\n",
            "91/91 [==============================] - ETA: 0s - loss: 0.4419 - accuracy: 0.8248\n",
            "Epoch 78: val_loss did not improve from 0.43262\n",
            "91/91 [==============================] - 77s 845ms/step - loss: 0.4419 - accuracy: 0.8248 - val_loss: 0.4428 - val_accuracy: 0.8297\n",
            "Epoch 79/100\n",
            "91/91 [==============================] - ETA: 0s - loss: 0.4309 - accuracy: 0.8252\n",
            "Epoch 79: val_loss did not improve from 0.43262\n",
            "91/91 [==============================] - 76s 841ms/step - loss: 0.4309 - accuracy: 0.8252 - val_loss: 0.4748 - val_accuracy: 0.7923\n",
            "Epoch 80/100\n",
            "91/91 [==============================] - ETA: 0s - loss: 0.4715 - accuracy: 0.8017\n",
            "Epoch 80: val_loss did not improve from 0.43262\n",
            "91/91 [==============================] - 78s 855ms/step - loss: 0.4715 - accuracy: 0.8017 - val_loss: 0.4902 - val_accuracy: 0.7995\n",
            "Epoch 81/100\n",
            "91/91 [==============================] - ETA: 0s - loss: 0.4563 - accuracy: 0.8103\n",
            "Epoch 81: val_loss did not improve from 0.43262\n",
            "91/91 [==============================] - 77s 847ms/step - loss: 0.4563 - accuracy: 0.8103 - val_loss: 0.4344 - val_accuracy: 0.8188\n",
            "Epoch 82/100\n",
            "91/91 [==============================] - ETA: 0s - loss: 0.4523 - accuracy: 0.8172\n",
            "Epoch 82: val_loss did not improve from 0.43262\n",
            "91/91 [==============================] - 78s 856ms/step - loss: 0.4523 - accuracy: 0.8172 - val_loss: 0.4909 - val_accuracy: 0.7971\n",
            "Epoch 83/100\n",
            "91/91 [==============================] - ETA: 0s - loss: 0.4279 - accuracy: 0.8186\n",
            "Epoch 83: val_loss did not improve from 0.43262\n",
            "91/91 [==============================] - 77s 850ms/step - loss: 0.4279 - accuracy: 0.8186 - val_loss: 0.4419 - val_accuracy: 0.8152\n",
            "Epoch 84/100\n",
            "91/91 [==============================] - ETA: 0s - loss: 0.4555 - accuracy: 0.8110\n",
            "Epoch 84: val_loss did not improve from 0.43262\n",
            "91/91 [==============================] - 78s 856ms/step - loss: 0.4555 - accuracy: 0.8110 - val_loss: 0.4592 - val_accuracy: 0.8019\n",
            "Epoch 85/100\n",
            "91/91 [==============================] - ETA: 0s - loss: 0.4535 - accuracy: 0.8131\n",
            "Epoch 85: val_loss did not improve from 0.43262\n",
            "91/91 [==============================] - 78s 855ms/step - loss: 0.4535 - accuracy: 0.8131 - val_loss: 0.4638 - val_accuracy: 0.8152\n",
            "Epoch 86/100\n",
            "91/91 [==============================] - ETA: 0s - loss: 0.4361 - accuracy: 0.8245\n",
            "Epoch 86: val_loss did not improve from 0.43262\n",
            "91/91 [==============================] - 77s 847ms/step - loss: 0.4361 - accuracy: 0.8245 - val_loss: 0.4886 - val_accuracy: 0.7886\n",
            "Epoch 87/100\n",
            "91/91 [==============================] - ETA: 0s - loss: 0.4489 - accuracy: 0.8152\n",
            "Epoch 87: val_loss did not improve from 0.43262\n",
            "91/91 [==============================] - 77s 848ms/step - loss: 0.4489 - accuracy: 0.8152 - val_loss: 0.4797 - val_accuracy: 0.7971\n",
            "Epoch 88/100\n",
            "91/91 [==============================] - ETA: 0s - loss: 0.4722 - accuracy: 0.8079\n",
            "Epoch 88: val_loss did not improve from 0.43262\n",
            "91/91 [==============================] - 77s 851ms/step - loss: 0.4722 - accuracy: 0.8079 - val_loss: 0.4655 - val_accuracy: 0.8007\n",
            "Epoch 89/100\n",
            "91/91 [==============================] - ETA: 0s - loss: 0.4303 - accuracy: 0.8234\n",
            "Epoch 89: val_loss did not improve from 0.43262\n",
            "91/91 [==============================] - 78s 852ms/step - loss: 0.4303 - accuracy: 0.8234 - val_loss: 0.4764 - val_accuracy: 0.8068\n",
            "Epoch 90/100\n",
            "91/91 [==============================] - ETA: 0s - loss: 0.4524 - accuracy: 0.8169\n",
            "Epoch 90: val_loss did not improve from 0.43262\n",
            "91/91 [==============================] - 78s 859ms/step - loss: 0.4524 - accuracy: 0.8169 - val_loss: 0.4617 - val_accuracy: 0.8104\n",
            "Epoch 91/100\n",
            "91/91 [==============================] - ETA: 0s - loss: 0.4451 - accuracy: 0.8262\n",
            "Epoch 91: val_loss did not improve from 0.43262\n",
            "91/91 [==============================] - 78s 857ms/step - loss: 0.4451 - accuracy: 0.8262 - val_loss: 0.4411 - val_accuracy: 0.8273\n",
            "Epoch 92/100\n",
            "91/91 [==============================] - ETA: 0s - loss: 0.4316 - accuracy: 0.8255\n",
            "Epoch 92: val_loss did not improve from 0.43262\n",
            "91/91 [==============================] - 78s 861ms/step - loss: 0.4316 - accuracy: 0.8255 - val_loss: 0.5417 - val_accuracy: 0.7814\n",
            "Epoch 93/100\n",
            "91/91 [==============================] - ETA: 0s - loss: 0.4430 - accuracy: 0.8152\n",
            "Epoch 93: val_loss did not improve from 0.43262\n",
            "91/91 [==============================] - 78s 864ms/step - loss: 0.4430 - accuracy: 0.8152 - val_loss: 0.4849 - val_accuracy: 0.8007\n",
            "Epoch 94/100\n",
            "91/91 [==============================] - ETA: 0s - loss: 0.4609 - accuracy: 0.8141\n",
            "Epoch 94: val_loss did not improve from 0.43262\n",
            "91/91 [==============================] - 78s 862ms/step - loss: 0.4609 - accuracy: 0.8141 - val_loss: 0.4645 - val_accuracy: 0.8128\n",
            "Epoch 95/100\n",
            "91/91 [==============================] - ETA: 0s - loss: 0.4289 - accuracy: 0.8310\n",
            "Epoch 95: val_loss did not improve from 0.43262\n",
            "91/91 [==============================] - 78s 856ms/step - loss: 0.4289 - accuracy: 0.8310 - val_loss: 0.4473 - val_accuracy: 0.8092\n",
            "Epoch 96/100\n",
            "91/91 [==============================] - ETA: 0s - loss: 0.4473 - accuracy: 0.8121\n",
            "Epoch 96: val_loss did not improve from 0.43262\n",
            "91/91 [==============================] - 78s 856ms/step - loss: 0.4473 - accuracy: 0.8121 - val_loss: 0.4748 - val_accuracy: 0.7983\n",
            "Epoch 97/100\n",
            "91/91 [==============================] - ETA: 0s - loss: 0.4445 - accuracy: 0.8228\n",
            "Epoch 97: val_loss did not improve from 0.43262\n",
            "91/91 [==============================] - 78s 860ms/step - loss: 0.4445 - accuracy: 0.8228 - val_loss: 0.4967 - val_accuracy: 0.8031\n",
            "Epoch 98/100\n",
            "91/91 [==============================] - ETA: 0s - loss: 0.4417 - accuracy: 0.8290\n",
            "Epoch 98: val_loss did not improve from 0.43262\n",
            "91/91 [==============================] - 78s 858ms/step - loss: 0.4417 - accuracy: 0.8290 - val_loss: 0.5163 - val_accuracy: 0.7911\n",
            "Epoch 98: early stopping\n"
          ]
        }
      ],
      "source": [
        "#Train the Model\n",
        "history_vgg = model.fit(train_generator,\n",
        "                    epochs = 100,\n",
        "                    validation_data= valid_generator,\n",
        "                    callbacks = [EarlyStoppingCallBack, CheckPointCallback],\n",
        "                    verbose = 1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AT3oX56j7DLY"
      },
      "outputs": [],
      "source": [
        "#Save the Model\n",
        "model.save('/content/drive/MyDrive/models/vgg16_model_100.h5')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "21RM8lPH65Ln"
      },
      "outputs": [],
      "source": [
        "# Function to evaluate the model\n",
        "def eval_model(model, test_generator):\n",
        "    test_steps_per_epoch = numpy.math.ceil(test_generator.samples / test_generator.batch_size)\n",
        "    predictions = model.predict(test_generator, steps=test_steps_per_epoch)\n",
        "    # Get most likely class\n",
        "    predicted_classes = numpy.argmax(predictions, axis=1)\n",
        "    true_classes = test_generator.classes\n",
        "    class_labels = list(test_generator.class_indices.keys()) \n",
        "    report = metrics.classification_report(true_classes, predicted_classes, target_names=class_labels)\n",
        "    print(report) \n",
        "    print(confusion_matrix(true_classes, predicted_classes))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kD8KZ88N7AUt",
        "outputId": "da59985f-2e76-49db-ad59-d03c62074157"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "       covid       0.74      0.82      0.78       102\n",
            "      normal       0.77      0.69      0.73       102\n",
            "   pneumonia       0.91      0.98      0.94       102\n",
            "tuberculosis       0.97      0.89      0.93       102\n",
            "\n",
            "    accuracy                           0.85       408\n",
            "   macro avg       0.85      0.85      0.84       408\n",
            "weighted avg       0.85      0.85      0.84       408\n",
            "\n",
            "[[ 84  17   0   1]\n",
            " [ 21  70   9   2]\n",
            " [  1   1 100   0]\n",
            " [  7   3   1  91]]\n"
          ]
        }
      ],
      "source": [
        "#Call Evaluate Function\n",
        "eval_model(model, test_generator)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#DenseNet121"
      ],
      "metadata": {
        "id": "qOy5kUc-4oUJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "##Import base DenseNet121 model trained on imagenet\n",
        "IMAGE_SIZE = [224, 224]\n",
        "densenet121 = DenseNet121(input_shape= IMAGE_SIZE + [3], weights = 'imagenet', include_top = False)\n",
        "\n",
        "for layer in densenet121.layers:\n",
        "    layer.trainable = False\n",
        "    \n",
        "densenet121.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hf6NPE8fRYsh",
        "outputId": "b23f8e31-8979-42b5-8f8f-786b7cd63eb4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/densenet/densenet121_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "29089792/29084464 [==============================] - 0s 0us/step\n",
            "29097984/29084464 [==============================] - 0s 0us/step\n",
            "Model: \"densenet121\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_2 (InputLayer)           [(None, 224, 224, 3  0           []                               \n",
            "                                )]                                                                \n",
            "                                                                                                  \n",
            " zero_padding2d (ZeroPadding2D)  (None, 230, 230, 3)  0          ['input_2[0][0]']                \n",
            "                                                                                                  \n",
            " conv1/conv (Conv2D)            (None, 112, 112, 64  9408        ['zero_padding2d[0][0]']         \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv1/bn (BatchNormalization)  (None, 112, 112, 64  256         ['conv1/conv[0][0]']             \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv1/relu (Activation)        (None, 112, 112, 64  0           ['conv1/bn[0][0]']               \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " zero_padding2d_1 (ZeroPadding2  (None, 114, 114, 64  0          ['conv1/relu[0][0]']             \n",
            " D)                             )                                                                 \n",
            "                                                                                                  \n",
            " pool1 (MaxPooling2D)           (None, 56, 56, 64)   0           ['zero_padding2d_1[0][0]']       \n",
            "                                                                                                  \n",
            " conv2_block1_0_bn (BatchNormal  (None, 56, 56, 64)  256         ['pool1[0][0]']                  \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv2_block1_0_relu (Activatio  (None, 56, 56, 64)  0           ['conv2_block1_0_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv2_block1_1_conv (Conv2D)   (None, 56, 56, 128)  8192        ['conv2_block1_0_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv2_block1_1_bn (BatchNormal  (None, 56, 56, 128)  512        ['conv2_block1_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv2_block1_1_relu (Activatio  (None, 56, 56, 128)  0          ['conv2_block1_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv2_block1_2_conv (Conv2D)   (None, 56, 56, 32)   36864       ['conv2_block1_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv2_block1_concat (Concatena  (None, 56, 56, 96)  0           ['pool1[0][0]',                  \n",
            " te)                                                              'conv2_block1_2_conv[0][0]']    \n",
            "                                                                                                  \n",
            " conv2_block2_0_bn (BatchNormal  (None, 56, 56, 96)  384         ['conv2_block1_concat[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv2_block2_0_relu (Activatio  (None, 56, 56, 96)  0           ['conv2_block2_0_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv2_block2_1_conv (Conv2D)   (None, 56, 56, 128)  12288       ['conv2_block2_0_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv2_block2_1_bn (BatchNormal  (None, 56, 56, 128)  512        ['conv2_block2_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv2_block2_1_relu (Activatio  (None, 56, 56, 128)  0          ['conv2_block2_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv2_block2_2_conv (Conv2D)   (None, 56, 56, 32)   36864       ['conv2_block2_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv2_block2_concat (Concatena  (None, 56, 56, 128)  0          ['conv2_block1_concat[0][0]',    \n",
            " te)                                                              'conv2_block2_2_conv[0][0]']    \n",
            "                                                                                                  \n",
            " conv2_block3_0_bn (BatchNormal  (None, 56, 56, 128)  512        ['conv2_block2_concat[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv2_block3_0_relu (Activatio  (None, 56, 56, 128)  0          ['conv2_block3_0_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv2_block3_1_conv (Conv2D)   (None, 56, 56, 128)  16384       ['conv2_block3_0_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv2_block3_1_bn (BatchNormal  (None, 56, 56, 128)  512        ['conv2_block3_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv2_block3_1_relu (Activatio  (None, 56, 56, 128)  0          ['conv2_block3_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv2_block3_2_conv (Conv2D)   (None, 56, 56, 32)   36864       ['conv2_block3_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv2_block3_concat (Concatena  (None, 56, 56, 160)  0          ['conv2_block2_concat[0][0]',    \n",
            " te)                                                              'conv2_block3_2_conv[0][0]']    \n",
            "                                                                                                  \n",
            " conv2_block4_0_bn (BatchNormal  (None, 56, 56, 160)  640        ['conv2_block3_concat[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv2_block4_0_relu (Activatio  (None, 56, 56, 160)  0          ['conv2_block4_0_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv2_block4_1_conv (Conv2D)   (None, 56, 56, 128)  20480       ['conv2_block4_0_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv2_block4_1_bn (BatchNormal  (None, 56, 56, 128)  512        ['conv2_block4_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv2_block4_1_relu (Activatio  (None, 56, 56, 128)  0          ['conv2_block4_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv2_block4_2_conv (Conv2D)   (None, 56, 56, 32)   36864       ['conv2_block4_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv2_block4_concat (Concatena  (None, 56, 56, 192)  0          ['conv2_block3_concat[0][0]',    \n",
            " te)                                                              'conv2_block4_2_conv[0][0]']    \n",
            "                                                                                                  \n",
            " conv2_block5_0_bn (BatchNormal  (None, 56, 56, 192)  768        ['conv2_block4_concat[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv2_block5_0_relu (Activatio  (None, 56, 56, 192)  0          ['conv2_block5_0_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv2_block5_1_conv (Conv2D)   (None, 56, 56, 128)  24576       ['conv2_block5_0_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv2_block5_1_bn (BatchNormal  (None, 56, 56, 128)  512        ['conv2_block5_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv2_block5_1_relu (Activatio  (None, 56, 56, 128)  0          ['conv2_block5_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv2_block5_2_conv (Conv2D)   (None, 56, 56, 32)   36864       ['conv2_block5_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv2_block5_concat (Concatena  (None, 56, 56, 224)  0          ['conv2_block4_concat[0][0]',    \n",
            " te)                                                              'conv2_block5_2_conv[0][0]']    \n",
            "                                                                                                  \n",
            " conv2_block6_0_bn (BatchNormal  (None, 56, 56, 224)  896        ['conv2_block5_concat[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv2_block6_0_relu (Activatio  (None, 56, 56, 224)  0          ['conv2_block6_0_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv2_block6_1_conv (Conv2D)   (None, 56, 56, 128)  28672       ['conv2_block6_0_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv2_block6_1_bn (BatchNormal  (None, 56, 56, 128)  512        ['conv2_block6_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv2_block6_1_relu (Activatio  (None, 56, 56, 128)  0          ['conv2_block6_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv2_block6_2_conv (Conv2D)   (None, 56, 56, 32)   36864       ['conv2_block6_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv2_block6_concat (Concatena  (None, 56, 56, 256)  0          ['conv2_block5_concat[0][0]',    \n",
            " te)                                                              'conv2_block6_2_conv[0][0]']    \n",
            "                                                                                                  \n",
            " pool2_bn (BatchNormalization)  (None, 56, 56, 256)  1024        ['conv2_block6_concat[0][0]']    \n",
            "                                                                                                  \n",
            " pool2_relu (Activation)        (None, 56, 56, 256)  0           ['pool2_bn[0][0]']               \n",
            "                                                                                                  \n",
            " pool2_conv (Conv2D)            (None, 56, 56, 128)  32768       ['pool2_relu[0][0]']             \n",
            "                                                                                                  \n",
            " pool2_pool (AveragePooling2D)  (None, 28, 28, 128)  0           ['pool2_conv[0][0]']             \n",
            "                                                                                                  \n",
            " conv3_block1_0_bn (BatchNormal  (None, 28, 28, 128)  512        ['pool2_pool[0][0]']             \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv3_block1_0_relu (Activatio  (None, 28, 28, 128)  0          ['conv3_block1_0_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv3_block1_1_conv (Conv2D)   (None, 28, 28, 128)  16384       ['conv3_block1_0_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv3_block1_1_bn (BatchNormal  (None, 28, 28, 128)  512        ['conv3_block1_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv3_block1_1_relu (Activatio  (None, 28, 28, 128)  0          ['conv3_block1_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv3_block1_2_conv (Conv2D)   (None, 28, 28, 32)   36864       ['conv3_block1_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv3_block1_concat (Concatena  (None, 28, 28, 160)  0          ['pool2_pool[0][0]',             \n",
            " te)                                                              'conv3_block1_2_conv[0][0]']    \n",
            "                                                                                                  \n",
            " conv3_block2_0_bn (BatchNormal  (None, 28, 28, 160)  640        ['conv3_block1_concat[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv3_block2_0_relu (Activatio  (None, 28, 28, 160)  0          ['conv3_block2_0_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv3_block2_1_conv (Conv2D)   (None, 28, 28, 128)  20480       ['conv3_block2_0_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv3_block2_1_bn (BatchNormal  (None, 28, 28, 128)  512        ['conv3_block2_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv3_block2_1_relu (Activatio  (None, 28, 28, 128)  0          ['conv3_block2_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv3_block2_2_conv (Conv2D)   (None, 28, 28, 32)   36864       ['conv3_block2_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv3_block2_concat (Concatena  (None, 28, 28, 192)  0          ['conv3_block1_concat[0][0]',    \n",
            " te)                                                              'conv3_block2_2_conv[0][0]']    \n",
            "                                                                                                  \n",
            " conv3_block3_0_bn (BatchNormal  (None, 28, 28, 192)  768        ['conv3_block2_concat[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv3_block3_0_relu (Activatio  (None, 28, 28, 192)  0          ['conv3_block3_0_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv3_block3_1_conv (Conv2D)   (None, 28, 28, 128)  24576       ['conv3_block3_0_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv3_block3_1_bn (BatchNormal  (None, 28, 28, 128)  512        ['conv3_block3_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv3_block3_1_relu (Activatio  (None, 28, 28, 128)  0          ['conv3_block3_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv3_block3_2_conv (Conv2D)   (None, 28, 28, 32)   36864       ['conv3_block3_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv3_block3_concat (Concatena  (None, 28, 28, 224)  0          ['conv3_block2_concat[0][0]',    \n",
            " te)                                                              'conv3_block3_2_conv[0][0]']    \n",
            "                                                                                                  \n",
            " conv3_block4_0_bn (BatchNormal  (None, 28, 28, 224)  896        ['conv3_block3_concat[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv3_block4_0_relu (Activatio  (None, 28, 28, 224)  0          ['conv3_block4_0_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv3_block4_1_conv (Conv2D)   (None, 28, 28, 128)  28672       ['conv3_block4_0_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv3_block4_1_bn (BatchNormal  (None, 28, 28, 128)  512        ['conv3_block4_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv3_block4_1_relu (Activatio  (None, 28, 28, 128)  0          ['conv3_block4_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv3_block4_2_conv (Conv2D)   (None, 28, 28, 32)   36864       ['conv3_block4_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv3_block4_concat (Concatena  (None, 28, 28, 256)  0          ['conv3_block3_concat[0][0]',    \n",
            " te)                                                              'conv3_block4_2_conv[0][0]']    \n",
            "                                                                                                  \n",
            " conv3_block5_0_bn (BatchNormal  (None, 28, 28, 256)  1024       ['conv3_block4_concat[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv3_block5_0_relu (Activatio  (None, 28, 28, 256)  0          ['conv3_block5_0_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv3_block5_1_conv (Conv2D)   (None, 28, 28, 128)  32768       ['conv3_block5_0_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv3_block5_1_bn (BatchNormal  (None, 28, 28, 128)  512        ['conv3_block5_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv3_block5_1_relu (Activatio  (None, 28, 28, 128)  0          ['conv3_block5_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv3_block5_2_conv (Conv2D)   (None, 28, 28, 32)   36864       ['conv3_block5_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv3_block5_concat (Concatena  (None, 28, 28, 288)  0          ['conv3_block4_concat[0][0]',    \n",
            " te)                                                              'conv3_block5_2_conv[0][0]']    \n",
            "                                                                                                  \n",
            " conv3_block6_0_bn (BatchNormal  (None, 28, 28, 288)  1152       ['conv3_block5_concat[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv3_block6_0_relu (Activatio  (None, 28, 28, 288)  0          ['conv3_block6_0_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv3_block6_1_conv (Conv2D)   (None, 28, 28, 128)  36864       ['conv3_block6_0_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv3_block6_1_bn (BatchNormal  (None, 28, 28, 128)  512        ['conv3_block6_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv3_block6_1_relu (Activatio  (None, 28, 28, 128)  0          ['conv3_block6_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv3_block6_2_conv (Conv2D)   (None, 28, 28, 32)   36864       ['conv3_block6_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv3_block6_concat (Concatena  (None, 28, 28, 320)  0          ['conv3_block5_concat[0][0]',    \n",
            " te)                                                              'conv3_block6_2_conv[0][0]']    \n",
            "                                                                                                  \n",
            " conv3_block7_0_bn (BatchNormal  (None, 28, 28, 320)  1280       ['conv3_block6_concat[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv3_block7_0_relu (Activatio  (None, 28, 28, 320)  0          ['conv3_block7_0_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv3_block7_1_conv (Conv2D)   (None, 28, 28, 128)  40960       ['conv3_block7_0_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv3_block7_1_bn (BatchNormal  (None, 28, 28, 128)  512        ['conv3_block7_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv3_block7_1_relu (Activatio  (None, 28, 28, 128)  0          ['conv3_block7_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv3_block7_2_conv (Conv2D)   (None, 28, 28, 32)   36864       ['conv3_block7_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv3_block7_concat (Concatena  (None, 28, 28, 352)  0          ['conv3_block6_concat[0][0]',    \n",
            " te)                                                              'conv3_block7_2_conv[0][0]']    \n",
            "                                                                                                  \n",
            " conv3_block8_0_bn (BatchNormal  (None, 28, 28, 352)  1408       ['conv3_block7_concat[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv3_block8_0_relu (Activatio  (None, 28, 28, 352)  0          ['conv3_block8_0_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv3_block8_1_conv (Conv2D)   (None, 28, 28, 128)  45056       ['conv3_block8_0_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv3_block8_1_bn (BatchNormal  (None, 28, 28, 128)  512        ['conv3_block8_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv3_block8_1_relu (Activatio  (None, 28, 28, 128)  0          ['conv3_block8_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv3_block8_2_conv (Conv2D)   (None, 28, 28, 32)   36864       ['conv3_block8_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv3_block8_concat (Concatena  (None, 28, 28, 384)  0          ['conv3_block7_concat[0][0]',    \n",
            " te)                                                              'conv3_block8_2_conv[0][0]']    \n",
            "                                                                                                  \n",
            " conv3_block9_0_bn (BatchNormal  (None, 28, 28, 384)  1536       ['conv3_block8_concat[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv3_block9_0_relu (Activatio  (None, 28, 28, 384)  0          ['conv3_block9_0_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv3_block9_1_conv (Conv2D)   (None, 28, 28, 128)  49152       ['conv3_block9_0_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv3_block9_1_bn (BatchNormal  (None, 28, 28, 128)  512        ['conv3_block9_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv3_block9_1_relu (Activatio  (None, 28, 28, 128)  0          ['conv3_block9_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv3_block9_2_conv (Conv2D)   (None, 28, 28, 32)   36864       ['conv3_block9_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv3_block9_concat (Concatena  (None, 28, 28, 416)  0          ['conv3_block8_concat[0][0]',    \n",
            " te)                                                              'conv3_block9_2_conv[0][0]']    \n",
            "                                                                                                  \n",
            " conv3_block10_0_bn (BatchNorma  (None, 28, 28, 416)  1664       ['conv3_block9_concat[0][0]']    \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " conv3_block10_0_relu (Activati  (None, 28, 28, 416)  0          ['conv3_block10_0_bn[0][0]']     \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv3_block10_1_conv (Conv2D)  (None, 28, 28, 128)  53248       ['conv3_block10_0_relu[0][0]']   \n",
            "                                                                                                  \n",
            " conv3_block10_1_bn (BatchNorma  (None, 28, 28, 128)  512        ['conv3_block10_1_conv[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " conv3_block10_1_relu (Activati  (None, 28, 28, 128)  0          ['conv3_block10_1_bn[0][0]']     \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv3_block10_2_conv (Conv2D)  (None, 28, 28, 32)   36864       ['conv3_block10_1_relu[0][0]']   \n",
            "                                                                                                  \n",
            " conv3_block10_concat (Concaten  (None, 28, 28, 448)  0          ['conv3_block9_concat[0][0]',    \n",
            " ate)                                                             'conv3_block10_2_conv[0][0]']   \n",
            "                                                                                                  \n",
            " conv3_block11_0_bn (BatchNorma  (None, 28, 28, 448)  1792       ['conv3_block10_concat[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " conv3_block11_0_relu (Activati  (None, 28, 28, 448)  0          ['conv3_block11_0_bn[0][0]']     \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv3_block11_1_conv (Conv2D)  (None, 28, 28, 128)  57344       ['conv3_block11_0_relu[0][0]']   \n",
            "                                                                                                  \n",
            " conv3_block11_1_bn (BatchNorma  (None, 28, 28, 128)  512        ['conv3_block11_1_conv[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " conv3_block11_1_relu (Activati  (None, 28, 28, 128)  0          ['conv3_block11_1_bn[0][0]']     \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv3_block11_2_conv (Conv2D)  (None, 28, 28, 32)   36864       ['conv3_block11_1_relu[0][0]']   \n",
            "                                                                                                  \n",
            " conv3_block11_concat (Concaten  (None, 28, 28, 480)  0          ['conv3_block10_concat[0][0]',   \n",
            " ate)                                                             'conv3_block11_2_conv[0][0]']   \n",
            "                                                                                                  \n",
            " conv3_block12_0_bn (BatchNorma  (None, 28, 28, 480)  1920       ['conv3_block11_concat[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " conv3_block12_0_relu (Activati  (None, 28, 28, 480)  0          ['conv3_block12_0_bn[0][0]']     \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv3_block12_1_conv (Conv2D)  (None, 28, 28, 128)  61440       ['conv3_block12_0_relu[0][0]']   \n",
            "                                                                                                  \n",
            " conv3_block12_1_bn (BatchNorma  (None, 28, 28, 128)  512        ['conv3_block12_1_conv[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " conv3_block12_1_relu (Activati  (None, 28, 28, 128)  0          ['conv3_block12_1_bn[0][0]']     \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv3_block12_2_conv (Conv2D)  (None, 28, 28, 32)   36864       ['conv3_block12_1_relu[0][0]']   \n",
            "                                                                                                  \n",
            " conv3_block12_concat (Concaten  (None, 28, 28, 512)  0          ['conv3_block11_concat[0][0]',   \n",
            " ate)                                                             'conv3_block12_2_conv[0][0]']   \n",
            "                                                                                                  \n",
            " pool3_bn (BatchNormalization)  (None, 28, 28, 512)  2048        ['conv3_block12_concat[0][0]']   \n",
            "                                                                                                  \n",
            " pool3_relu (Activation)        (None, 28, 28, 512)  0           ['pool3_bn[0][0]']               \n",
            "                                                                                                  \n",
            " pool3_conv (Conv2D)            (None, 28, 28, 256)  131072      ['pool3_relu[0][0]']             \n",
            "                                                                                                  \n",
            " pool3_pool (AveragePooling2D)  (None, 14, 14, 256)  0           ['pool3_conv[0][0]']             \n",
            "                                                                                                  \n",
            " conv4_block1_0_bn (BatchNormal  (None, 14, 14, 256)  1024       ['pool3_pool[0][0]']             \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block1_0_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block1_0_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block1_1_conv (Conv2D)   (None, 14, 14, 128)  32768       ['conv4_block1_0_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv4_block1_1_bn (BatchNormal  (None, 14, 14, 128)  512        ['conv4_block1_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block1_1_relu (Activatio  (None, 14, 14, 128)  0          ['conv4_block1_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block1_2_conv (Conv2D)   (None, 14, 14, 32)   36864       ['conv4_block1_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv4_block1_concat (Concatena  (None, 14, 14, 288)  0          ['pool3_pool[0][0]',             \n",
            " te)                                                              'conv4_block1_2_conv[0][0]']    \n",
            "                                                                                                  \n",
            " conv4_block2_0_bn (BatchNormal  (None, 14, 14, 288)  1152       ['conv4_block1_concat[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block2_0_relu (Activatio  (None, 14, 14, 288)  0          ['conv4_block2_0_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block2_1_conv (Conv2D)   (None, 14, 14, 128)  36864       ['conv4_block2_0_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv4_block2_1_bn (BatchNormal  (None, 14, 14, 128)  512        ['conv4_block2_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block2_1_relu (Activatio  (None, 14, 14, 128)  0          ['conv4_block2_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block2_2_conv (Conv2D)   (None, 14, 14, 32)   36864       ['conv4_block2_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv4_block2_concat (Concatena  (None, 14, 14, 320)  0          ['conv4_block1_concat[0][0]',    \n",
            " te)                                                              'conv4_block2_2_conv[0][0]']    \n",
            "                                                                                                  \n",
            " conv4_block3_0_bn (BatchNormal  (None, 14, 14, 320)  1280       ['conv4_block2_concat[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block3_0_relu (Activatio  (None, 14, 14, 320)  0          ['conv4_block3_0_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block3_1_conv (Conv2D)   (None, 14, 14, 128)  40960       ['conv4_block3_0_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv4_block3_1_bn (BatchNormal  (None, 14, 14, 128)  512        ['conv4_block3_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block3_1_relu (Activatio  (None, 14, 14, 128)  0          ['conv4_block3_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block3_2_conv (Conv2D)   (None, 14, 14, 32)   36864       ['conv4_block3_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv4_block3_concat (Concatena  (None, 14, 14, 352)  0          ['conv4_block2_concat[0][0]',    \n",
            " te)                                                              'conv4_block3_2_conv[0][0]']    \n",
            "                                                                                                  \n",
            " conv4_block4_0_bn (BatchNormal  (None, 14, 14, 352)  1408       ['conv4_block3_concat[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block4_0_relu (Activatio  (None, 14, 14, 352)  0          ['conv4_block4_0_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block4_1_conv (Conv2D)   (None, 14, 14, 128)  45056       ['conv4_block4_0_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv4_block4_1_bn (BatchNormal  (None, 14, 14, 128)  512        ['conv4_block4_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block4_1_relu (Activatio  (None, 14, 14, 128)  0          ['conv4_block4_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block4_2_conv (Conv2D)   (None, 14, 14, 32)   36864       ['conv4_block4_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv4_block4_concat (Concatena  (None, 14, 14, 384)  0          ['conv4_block3_concat[0][0]',    \n",
            " te)                                                              'conv4_block4_2_conv[0][0]']    \n",
            "                                                                                                  \n",
            " conv4_block5_0_bn (BatchNormal  (None, 14, 14, 384)  1536       ['conv4_block4_concat[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block5_0_relu (Activatio  (None, 14, 14, 384)  0          ['conv4_block5_0_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block5_1_conv (Conv2D)   (None, 14, 14, 128)  49152       ['conv4_block5_0_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv4_block5_1_bn (BatchNormal  (None, 14, 14, 128)  512        ['conv4_block5_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block5_1_relu (Activatio  (None, 14, 14, 128)  0          ['conv4_block5_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block5_2_conv (Conv2D)   (None, 14, 14, 32)   36864       ['conv4_block5_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv4_block5_concat (Concatena  (None, 14, 14, 416)  0          ['conv4_block4_concat[0][0]',    \n",
            " te)                                                              'conv4_block5_2_conv[0][0]']    \n",
            "                                                                                                  \n",
            " conv4_block6_0_bn (BatchNormal  (None, 14, 14, 416)  1664       ['conv4_block5_concat[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block6_0_relu (Activatio  (None, 14, 14, 416)  0          ['conv4_block6_0_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block6_1_conv (Conv2D)   (None, 14, 14, 128)  53248       ['conv4_block6_0_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv4_block6_1_bn (BatchNormal  (None, 14, 14, 128)  512        ['conv4_block6_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block6_1_relu (Activatio  (None, 14, 14, 128)  0          ['conv4_block6_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block6_2_conv (Conv2D)   (None, 14, 14, 32)   36864       ['conv4_block6_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv4_block6_concat (Concatena  (None, 14, 14, 448)  0          ['conv4_block5_concat[0][0]',    \n",
            " te)                                                              'conv4_block6_2_conv[0][0]']    \n",
            "                                                                                                  \n",
            " conv4_block7_0_bn (BatchNormal  (None, 14, 14, 448)  1792       ['conv4_block6_concat[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block7_0_relu (Activatio  (None, 14, 14, 448)  0          ['conv4_block7_0_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block7_1_conv (Conv2D)   (None, 14, 14, 128)  57344       ['conv4_block7_0_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv4_block7_1_bn (BatchNormal  (None, 14, 14, 128)  512        ['conv4_block7_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block7_1_relu (Activatio  (None, 14, 14, 128)  0          ['conv4_block7_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block7_2_conv (Conv2D)   (None, 14, 14, 32)   36864       ['conv4_block7_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv4_block7_concat (Concatena  (None, 14, 14, 480)  0          ['conv4_block6_concat[0][0]',    \n",
            " te)                                                              'conv4_block7_2_conv[0][0]']    \n",
            "                                                                                                  \n",
            " conv4_block8_0_bn (BatchNormal  (None, 14, 14, 480)  1920       ['conv4_block7_concat[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block8_0_relu (Activatio  (None, 14, 14, 480)  0          ['conv4_block8_0_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block8_1_conv (Conv2D)   (None, 14, 14, 128)  61440       ['conv4_block8_0_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv4_block8_1_bn (BatchNormal  (None, 14, 14, 128)  512        ['conv4_block8_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block8_1_relu (Activatio  (None, 14, 14, 128)  0          ['conv4_block8_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block8_2_conv (Conv2D)   (None, 14, 14, 32)   36864       ['conv4_block8_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv4_block8_concat (Concatena  (None, 14, 14, 512)  0          ['conv4_block7_concat[0][0]',    \n",
            " te)                                                              'conv4_block8_2_conv[0][0]']    \n",
            "                                                                                                  \n",
            " conv4_block9_0_bn (BatchNormal  (None, 14, 14, 512)  2048       ['conv4_block8_concat[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block9_0_relu (Activatio  (None, 14, 14, 512)  0          ['conv4_block9_0_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block9_1_conv (Conv2D)   (None, 14, 14, 128)  65536       ['conv4_block9_0_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv4_block9_1_bn (BatchNormal  (None, 14, 14, 128)  512        ['conv4_block9_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block9_1_relu (Activatio  (None, 14, 14, 128)  0          ['conv4_block9_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block9_2_conv (Conv2D)   (None, 14, 14, 32)   36864       ['conv4_block9_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv4_block9_concat (Concatena  (None, 14, 14, 544)  0          ['conv4_block8_concat[0][0]',    \n",
            " te)                                                              'conv4_block9_2_conv[0][0]']    \n",
            "                                                                                                  \n",
            " conv4_block10_0_bn (BatchNorma  (None, 14, 14, 544)  2176       ['conv4_block9_concat[0][0]']    \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " conv4_block10_0_relu (Activati  (None, 14, 14, 544)  0          ['conv4_block10_0_bn[0][0]']     \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv4_block10_1_conv (Conv2D)  (None, 14, 14, 128)  69632       ['conv4_block10_0_relu[0][0]']   \n",
            "                                                                                                  \n",
            " conv4_block10_1_bn (BatchNorma  (None, 14, 14, 128)  512        ['conv4_block10_1_conv[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " conv4_block10_1_relu (Activati  (None, 14, 14, 128)  0          ['conv4_block10_1_bn[0][0]']     \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv4_block10_2_conv (Conv2D)  (None, 14, 14, 32)   36864       ['conv4_block10_1_relu[0][0]']   \n",
            "                                                                                                  \n",
            " conv4_block10_concat (Concaten  (None, 14, 14, 576)  0          ['conv4_block9_concat[0][0]',    \n",
            " ate)                                                             'conv4_block10_2_conv[0][0]']   \n",
            "                                                                                                  \n",
            " conv4_block11_0_bn (BatchNorma  (None, 14, 14, 576)  2304       ['conv4_block10_concat[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " conv4_block11_0_relu (Activati  (None, 14, 14, 576)  0          ['conv4_block11_0_bn[0][0]']     \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv4_block11_1_conv (Conv2D)  (None, 14, 14, 128)  73728       ['conv4_block11_0_relu[0][0]']   \n",
            "                                                                                                  \n",
            " conv4_block11_1_bn (BatchNorma  (None, 14, 14, 128)  512        ['conv4_block11_1_conv[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " conv4_block11_1_relu (Activati  (None, 14, 14, 128)  0          ['conv4_block11_1_bn[0][0]']     \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv4_block11_2_conv (Conv2D)  (None, 14, 14, 32)   36864       ['conv4_block11_1_relu[0][0]']   \n",
            "                                                                                                  \n",
            " conv4_block11_concat (Concaten  (None, 14, 14, 608)  0          ['conv4_block10_concat[0][0]',   \n",
            " ate)                                                             'conv4_block11_2_conv[0][0]']   \n",
            "                                                                                                  \n",
            " conv4_block12_0_bn (BatchNorma  (None, 14, 14, 608)  2432       ['conv4_block11_concat[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " conv4_block12_0_relu (Activati  (None, 14, 14, 608)  0          ['conv4_block12_0_bn[0][0]']     \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv4_block12_1_conv (Conv2D)  (None, 14, 14, 128)  77824       ['conv4_block12_0_relu[0][0]']   \n",
            "                                                                                                  \n",
            " conv4_block12_1_bn (BatchNorma  (None, 14, 14, 128)  512        ['conv4_block12_1_conv[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " conv4_block12_1_relu (Activati  (None, 14, 14, 128)  0          ['conv4_block12_1_bn[0][0]']     \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv4_block12_2_conv (Conv2D)  (None, 14, 14, 32)   36864       ['conv4_block12_1_relu[0][0]']   \n",
            "                                                                                                  \n",
            " conv4_block12_concat (Concaten  (None, 14, 14, 640)  0          ['conv4_block11_concat[0][0]',   \n",
            " ate)                                                             'conv4_block12_2_conv[0][0]']   \n",
            "                                                                                                  \n",
            " conv4_block13_0_bn (BatchNorma  (None, 14, 14, 640)  2560       ['conv4_block12_concat[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " conv4_block13_0_relu (Activati  (None, 14, 14, 640)  0          ['conv4_block13_0_bn[0][0]']     \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv4_block13_1_conv (Conv2D)  (None, 14, 14, 128)  81920       ['conv4_block13_0_relu[0][0]']   \n",
            "                                                                                                  \n",
            " conv4_block13_1_bn (BatchNorma  (None, 14, 14, 128)  512        ['conv4_block13_1_conv[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " conv4_block13_1_relu (Activati  (None, 14, 14, 128)  0          ['conv4_block13_1_bn[0][0]']     \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv4_block13_2_conv (Conv2D)  (None, 14, 14, 32)   36864       ['conv4_block13_1_relu[0][0]']   \n",
            "                                                                                                  \n",
            " conv4_block13_concat (Concaten  (None, 14, 14, 672)  0          ['conv4_block12_concat[0][0]',   \n",
            " ate)                                                             'conv4_block13_2_conv[0][0]']   \n",
            "                                                                                                  \n",
            " conv4_block14_0_bn (BatchNorma  (None, 14, 14, 672)  2688       ['conv4_block13_concat[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " conv4_block14_0_relu (Activati  (None, 14, 14, 672)  0          ['conv4_block14_0_bn[0][0]']     \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv4_block14_1_conv (Conv2D)  (None, 14, 14, 128)  86016       ['conv4_block14_0_relu[0][0]']   \n",
            "                                                                                                  \n",
            " conv4_block14_1_bn (BatchNorma  (None, 14, 14, 128)  512        ['conv4_block14_1_conv[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " conv4_block14_1_relu (Activati  (None, 14, 14, 128)  0          ['conv4_block14_1_bn[0][0]']     \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv4_block14_2_conv (Conv2D)  (None, 14, 14, 32)   36864       ['conv4_block14_1_relu[0][0]']   \n",
            "                                                                                                  \n",
            " conv4_block14_concat (Concaten  (None, 14, 14, 704)  0          ['conv4_block13_concat[0][0]',   \n",
            " ate)                                                             'conv4_block14_2_conv[0][0]']   \n",
            "                                                                                                  \n",
            " conv4_block15_0_bn (BatchNorma  (None, 14, 14, 704)  2816       ['conv4_block14_concat[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " conv4_block15_0_relu (Activati  (None, 14, 14, 704)  0          ['conv4_block15_0_bn[0][0]']     \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv4_block15_1_conv (Conv2D)  (None, 14, 14, 128)  90112       ['conv4_block15_0_relu[0][0]']   \n",
            "                                                                                                  \n",
            " conv4_block15_1_bn (BatchNorma  (None, 14, 14, 128)  512        ['conv4_block15_1_conv[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " conv4_block15_1_relu (Activati  (None, 14, 14, 128)  0          ['conv4_block15_1_bn[0][0]']     \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv4_block15_2_conv (Conv2D)  (None, 14, 14, 32)   36864       ['conv4_block15_1_relu[0][0]']   \n",
            "                                                                                                  \n",
            " conv4_block15_concat (Concaten  (None, 14, 14, 736)  0          ['conv4_block14_concat[0][0]',   \n",
            " ate)                                                             'conv4_block15_2_conv[0][0]']   \n",
            "                                                                                                  \n",
            " conv4_block16_0_bn (BatchNorma  (None, 14, 14, 736)  2944       ['conv4_block15_concat[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " conv4_block16_0_relu (Activati  (None, 14, 14, 736)  0          ['conv4_block16_0_bn[0][0]']     \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv4_block16_1_conv (Conv2D)  (None, 14, 14, 128)  94208       ['conv4_block16_0_relu[0][0]']   \n",
            "                                                                                                  \n",
            " conv4_block16_1_bn (BatchNorma  (None, 14, 14, 128)  512        ['conv4_block16_1_conv[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " conv4_block16_1_relu (Activati  (None, 14, 14, 128)  0          ['conv4_block16_1_bn[0][0]']     \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv4_block16_2_conv (Conv2D)  (None, 14, 14, 32)   36864       ['conv4_block16_1_relu[0][0]']   \n",
            "                                                                                                  \n",
            " conv4_block16_concat (Concaten  (None, 14, 14, 768)  0          ['conv4_block15_concat[0][0]',   \n",
            " ate)                                                             'conv4_block16_2_conv[0][0]']   \n",
            "                                                                                                  \n",
            " conv4_block17_0_bn (BatchNorma  (None, 14, 14, 768)  3072       ['conv4_block16_concat[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " conv4_block17_0_relu (Activati  (None, 14, 14, 768)  0          ['conv4_block17_0_bn[0][0]']     \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv4_block17_1_conv (Conv2D)  (None, 14, 14, 128)  98304       ['conv4_block17_0_relu[0][0]']   \n",
            "                                                                                                  \n",
            " conv4_block17_1_bn (BatchNorma  (None, 14, 14, 128)  512        ['conv4_block17_1_conv[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " conv4_block17_1_relu (Activati  (None, 14, 14, 128)  0          ['conv4_block17_1_bn[0][0]']     \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv4_block17_2_conv (Conv2D)  (None, 14, 14, 32)   36864       ['conv4_block17_1_relu[0][0]']   \n",
            "                                                                                                  \n",
            " conv4_block17_concat (Concaten  (None, 14, 14, 800)  0          ['conv4_block16_concat[0][0]',   \n",
            " ate)                                                             'conv4_block17_2_conv[0][0]']   \n",
            "                                                                                                  \n",
            " conv4_block18_0_bn (BatchNorma  (None, 14, 14, 800)  3200       ['conv4_block17_concat[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " conv4_block18_0_relu (Activati  (None, 14, 14, 800)  0          ['conv4_block18_0_bn[0][0]']     \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv4_block18_1_conv (Conv2D)  (None, 14, 14, 128)  102400      ['conv4_block18_0_relu[0][0]']   \n",
            "                                                                                                  \n",
            " conv4_block18_1_bn (BatchNorma  (None, 14, 14, 128)  512        ['conv4_block18_1_conv[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " conv4_block18_1_relu (Activati  (None, 14, 14, 128)  0          ['conv4_block18_1_bn[0][0]']     \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv4_block18_2_conv (Conv2D)  (None, 14, 14, 32)   36864       ['conv4_block18_1_relu[0][0]']   \n",
            "                                                                                                  \n",
            " conv4_block18_concat (Concaten  (None, 14, 14, 832)  0          ['conv4_block17_concat[0][0]',   \n",
            " ate)                                                             'conv4_block18_2_conv[0][0]']   \n",
            "                                                                                                  \n",
            " conv4_block19_0_bn (BatchNorma  (None, 14, 14, 832)  3328       ['conv4_block18_concat[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " conv4_block19_0_relu (Activati  (None, 14, 14, 832)  0          ['conv4_block19_0_bn[0][0]']     \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv4_block19_1_conv (Conv2D)  (None, 14, 14, 128)  106496      ['conv4_block19_0_relu[0][0]']   \n",
            "                                                                                                  \n",
            " conv4_block19_1_bn (BatchNorma  (None, 14, 14, 128)  512        ['conv4_block19_1_conv[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " conv4_block19_1_relu (Activati  (None, 14, 14, 128)  0          ['conv4_block19_1_bn[0][0]']     \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv4_block19_2_conv (Conv2D)  (None, 14, 14, 32)   36864       ['conv4_block19_1_relu[0][0]']   \n",
            "                                                                                                  \n",
            " conv4_block19_concat (Concaten  (None, 14, 14, 864)  0          ['conv4_block18_concat[0][0]',   \n",
            " ate)                                                             'conv4_block19_2_conv[0][0]']   \n",
            "                                                                                                  \n",
            " conv4_block20_0_bn (BatchNorma  (None, 14, 14, 864)  3456       ['conv4_block19_concat[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " conv4_block20_0_relu (Activati  (None, 14, 14, 864)  0          ['conv4_block20_0_bn[0][0]']     \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv4_block20_1_conv (Conv2D)  (None, 14, 14, 128)  110592      ['conv4_block20_0_relu[0][0]']   \n",
            "                                                                                                  \n",
            " conv4_block20_1_bn (BatchNorma  (None, 14, 14, 128)  512        ['conv4_block20_1_conv[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " conv4_block20_1_relu (Activati  (None, 14, 14, 128)  0          ['conv4_block20_1_bn[0][0]']     \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv4_block20_2_conv (Conv2D)  (None, 14, 14, 32)   36864       ['conv4_block20_1_relu[0][0]']   \n",
            "                                                                                                  \n",
            " conv4_block20_concat (Concaten  (None, 14, 14, 896)  0          ['conv4_block19_concat[0][0]',   \n",
            " ate)                                                             'conv4_block20_2_conv[0][0]']   \n",
            "                                                                                                  \n",
            " conv4_block21_0_bn (BatchNorma  (None, 14, 14, 896)  3584       ['conv4_block20_concat[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " conv4_block21_0_relu (Activati  (None, 14, 14, 896)  0          ['conv4_block21_0_bn[0][0]']     \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv4_block21_1_conv (Conv2D)  (None, 14, 14, 128)  114688      ['conv4_block21_0_relu[0][0]']   \n",
            "                                                                                                  \n",
            " conv4_block21_1_bn (BatchNorma  (None, 14, 14, 128)  512        ['conv4_block21_1_conv[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " conv4_block21_1_relu (Activati  (None, 14, 14, 128)  0          ['conv4_block21_1_bn[0][0]']     \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv4_block21_2_conv (Conv2D)  (None, 14, 14, 32)   36864       ['conv4_block21_1_relu[0][0]']   \n",
            "                                                                                                  \n",
            " conv4_block21_concat (Concaten  (None, 14, 14, 928)  0          ['conv4_block20_concat[0][0]',   \n",
            " ate)                                                             'conv4_block21_2_conv[0][0]']   \n",
            "                                                                                                  \n",
            " conv4_block22_0_bn (BatchNorma  (None, 14, 14, 928)  3712       ['conv4_block21_concat[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " conv4_block22_0_relu (Activati  (None, 14, 14, 928)  0          ['conv4_block22_0_bn[0][0]']     \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv4_block22_1_conv (Conv2D)  (None, 14, 14, 128)  118784      ['conv4_block22_0_relu[0][0]']   \n",
            "                                                                                                  \n",
            " conv4_block22_1_bn (BatchNorma  (None, 14, 14, 128)  512        ['conv4_block22_1_conv[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " conv4_block22_1_relu (Activati  (None, 14, 14, 128)  0          ['conv4_block22_1_bn[0][0]']     \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv4_block22_2_conv (Conv2D)  (None, 14, 14, 32)   36864       ['conv4_block22_1_relu[0][0]']   \n",
            "                                                                                                  \n",
            " conv4_block22_concat (Concaten  (None, 14, 14, 960)  0          ['conv4_block21_concat[0][0]',   \n",
            " ate)                                                             'conv4_block22_2_conv[0][0]']   \n",
            "                                                                                                  \n",
            " conv4_block23_0_bn (BatchNorma  (None, 14, 14, 960)  3840       ['conv4_block22_concat[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " conv4_block23_0_relu (Activati  (None, 14, 14, 960)  0          ['conv4_block23_0_bn[0][0]']     \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv4_block23_1_conv (Conv2D)  (None, 14, 14, 128)  122880      ['conv4_block23_0_relu[0][0]']   \n",
            "                                                                                                  \n",
            " conv4_block23_1_bn (BatchNorma  (None, 14, 14, 128)  512        ['conv4_block23_1_conv[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " conv4_block23_1_relu (Activati  (None, 14, 14, 128)  0          ['conv4_block23_1_bn[0][0]']     \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv4_block23_2_conv (Conv2D)  (None, 14, 14, 32)   36864       ['conv4_block23_1_relu[0][0]']   \n",
            "                                                                                                  \n",
            " conv4_block23_concat (Concaten  (None, 14, 14, 992)  0          ['conv4_block22_concat[0][0]',   \n",
            " ate)                                                             'conv4_block23_2_conv[0][0]']   \n",
            "                                                                                                  \n",
            " conv4_block24_0_bn (BatchNorma  (None, 14, 14, 992)  3968       ['conv4_block23_concat[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " conv4_block24_0_relu (Activati  (None, 14, 14, 992)  0          ['conv4_block24_0_bn[0][0]']     \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv4_block24_1_conv (Conv2D)  (None, 14, 14, 128)  126976      ['conv4_block24_0_relu[0][0]']   \n",
            "                                                                                                  \n",
            " conv4_block24_1_bn (BatchNorma  (None, 14, 14, 128)  512        ['conv4_block24_1_conv[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " conv4_block24_1_relu (Activati  (None, 14, 14, 128)  0          ['conv4_block24_1_bn[0][0]']     \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv4_block24_2_conv (Conv2D)  (None, 14, 14, 32)   36864       ['conv4_block24_1_relu[0][0]']   \n",
            "                                                                                                  \n",
            " conv4_block24_concat (Concaten  (None, 14, 14, 1024  0          ['conv4_block23_concat[0][0]',   \n",
            " ate)                           )                                 'conv4_block24_2_conv[0][0]']   \n",
            "                                                                                                  \n",
            " pool4_bn (BatchNormalization)  (None, 14, 14, 1024  4096        ['conv4_block24_concat[0][0]']   \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " pool4_relu (Activation)        (None, 14, 14, 1024  0           ['pool4_bn[0][0]']               \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " pool4_conv (Conv2D)            (None, 14, 14, 512)  524288      ['pool4_relu[0][0]']             \n",
            "                                                                                                  \n",
            " pool4_pool (AveragePooling2D)  (None, 7, 7, 512)    0           ['pool4_conv[0][0]']             \n",
            "                                                                                                  \n",
            " conv5_block1_0_bn (BatchNormal  (None, 7, 7, 512)   2048        ['pool4_pool[0][0]']             \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv5_block1_0_relu (Activatio  (None, 7, 7, 512)   0           ['conv5_block1_0_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv5_block1_1_conv (Conv2D)   (None, 7, 7, 128)    65536       ['conv5_block1_0_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv5_block1_1_bn (BatchNormal  (None, 7, 7, 128)   512         ['conv5_block1_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv5_block1_1_relu (Activatio  (None, 7, 7, 128)   0           ['conv5_block1_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv5_block1_2_conv (Conv2D)   (None, 7, 7, 32)     36864       ['conv5_block1_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv5_block1_concat (Concatena  (None, 7, 7, 544)   0           ['pool4_pool[0][0]',             \n",
            " te)                                                              'conv5_block1_2_conv[0][0]']    \n",
            "                                                                                                  \n",
            " conv5_block2_0_bn (BatchNormal  (None, 7, 7, 544)   2176        ['conv5_block1_concat[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv5_block2_0_relu (Activatio  (None, 7, 7, 544)   0           ['conv5_block2_0_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv5_block2_1_conv (Conv2D)   (None, 7, 7, 128)    69632       ['conv5_block2_0_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv5_block2_1_bn (BatchNormal  (None, 7, 7, 128)   512         ['conv5_block2_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv5_block2_1_relu (Activatio  (None, 7, 7, 128)   0           ['conv5_block2_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv5_block2_2_conv (Conv2D)   (None, 7, 7, 32)     36864       ['conv5_block2_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv5_block2_concat (Concatena  (None, 7, 7, 576)   0           ['conv5_block1_concat[0][0]',    \n",
            " te)                                                              'conv5_block2_2_conv[0][0]']    \n",
            "                                                                                                  \n",
            " conv5_block3_0_bn (BatchNormal  (None, 7, 7, 576)   2304        ['conv5_block2_concat[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv5_block3_0_relu (Activatio  (None, 7, 7, 576)   0           ['conv5_block3_0_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv5_block3_1_conv (Conv2D)   (None, 7, 7, 128)    73728       ['conv5_block3_0_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv5_block3_1_bn (BatchNormal  (None, 7, 7, 128)   512         ['conv5_block3_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv5_block3_1_relu (Activatio  (None, 7, 7, 128)   0           ['conv5_block3_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv5_block3_2_conv (Conv2D)   (None, 7, 7, 32)     36864       ['conv5_block3_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv5_block3_concat (Concatena  (None, 7, 7, 608)   0           ['conv5_block2_concat[0][0]',    \n",
            " te)                                                              'conv5_block3_2_conv[0][0]']    \n",
            "                                                                                                  \n",
            " conv5_block4_0_bn (BatchNormal  (None, 7, 7, 608)   2432        ['conv5_block3_concat[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv5_block4_0_relu (Activatio  (None, 7, 7, 608)   0           ['conv5_block4_0_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv5_block4_1_conv (Conv2D)   (None, 7, 7, 128)    77824       ['conv5_block4_0_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv5_block4_1_bn (BatchNormal  (None, 7, 7, 128)   512         ['conv5_block4_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv5_block4_1_relu (Activatio  (None, 7, 7, 128)   0           ['conv5_block4_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv5_block4_2_conv (Conv2D)   (None, 7, 7, 32)     36864       ['conv5_block4_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv5_block4_concat (Concatena  (None, 7, 7, 640)   0           ['conv5_block3_concat[0][0]',    \n",
            " te)                                                              'conv5_block4_2_conv[0][0]']    \n",
            "                                                                                                  \n",
            " conv5_block5_0_bn (BatchNormal  (None, 7, 7, 640)   2560        ['conv5_block4_concat[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv5_block5_0_relu (Activatio  (None, 7, 7, 640)   0           ['conv5_block5_0_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv5_block5_1_conv (Conv2D)   (None, 7, 7, 128)    81920       ['conv5_block5_0_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv5_block5_1_bn (BatchNormal  (None, 7, 7, 128)   512         ['conv5_block5_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv5_block5_1_relu (Activatio  (None, 7, 7, 128)   0           ['conv5_block5_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv5_block5_2_conv (Conv2D)   (None, 7, 7, 32)     36864       ['conv5_block5_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv5_block5_concat (Concatena  (None, 7, 7, 672)   0           ['conv5_block4_concat[0][0]',    \n",
            " te)                                                              'conv5_block5_2_conv[0][0]']    \n",
            "                                                                                                  \n",
            " conv5_block6_0_bn (BatchNormal  (None, 7, 7, 672)   2688        ['conv5_block5_concat[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv5_block6_0_relu (Activatio  (None, 7, 7, 672)   0           ['conv5_block6_0_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv5_block6_1_conv (Conv2D)   (None, 7, 7, 128)    86016       ['conv5_block6_0_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv5_block6_1_bn (BatchNormal  (None, 7, 7, 128)   512         ['conv5_block6_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv5_block6_1_relu (Activatio  (None, 7, 7, 128)   0           ['conv5_block6_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv5_block6_2_conv (Conv2D)   (None, 7, 7, 32)     36864       ['conv5_block6_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv5_block6_concat (Concatena  (None, 7, 7, 704)   0           ['conv5_block5_concat[0][0]',    \n",
            " te)                                                              'conv5_block6_2_conv[0][0]']    \n",
            "                                                                                                  \n",
            " conv5_block7_0_bn (BatchNormal  (None, 7, 7, 704)   2816        ['conv5_block6_concat[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv5_block7_0_relu (Activatio  (None, 7, 7, 704)   0           ['conv5_block7_0_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv5_block7_1_conv (Conv2D)   (None, 7, 7, 128)    90112       ['conv5_block7_0_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv5_block7_1_bn (BatchNormal  (None, 7, 7, 128)   512         ['conv5_block7_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv5_block7_1_relu (Activatio  (None, 7, 7, 128)   0           ['conv5_block7_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv5_block7_2_conv (Conv2D)   (None, 7, 7, 32)     36864       ['conv5_block7_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv5_block7_concat (Concatena  (None, 7, 7, 736)   0           ['conv5_block6_concat[0][0]',    \n",
            " te)                                                              'conv5_block7_2_conv[0][0]']    \n",
            "                                                                                                  \n",
            " conv5_block8_0_bn (BatchNormal  (None, 7, 7, 736)   2944        ['conv5_block7_concat[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv5_block8_0_relu (Activatio  (None, 7, 7, 736)   0           ['conv5_block8_0_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv5_block8_1_conv (Conv2D)   (None, 7, 7, 128)    94208       ['conv5_block8_0_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv5_block8_1_bn (BatchNormal  (None, 7, 7, 128)   512         ['conv5_block8_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv5_block8_1_relu (Activatio  (None, 7, 7, 128)   0           ['conv5_block8_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv5_block8_2_conv (Conv2D)   (None, 7, 7, 32)     36864       ['conv5_block8_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv5_block8_concat (Concatena  (None, 7, 7, 768)   0           ['conv5_block7_concat[0][0]',    \n",
            " te)                                                              'conv5_block8_2_conv[0][0]']    \n",
            "                                                                                                  \n",
            " conv5_block9_0_bn (BatchNormal  (None, 7, 7, 768)   3072        ['conv5_block8_concat[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv5_block9_0_relu (Activatio  (None, 7, 7, 768)   0           ['conv5_block9_0_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv5_block9_1_conv (Conv2D)   (None, 7, 7, 128)    98304       ['conv5_block9_0_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv5_block9_1_bn (BatchNormal  (None, 7, 7, 128)   512         ['conv5_block9_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv5_block9_1_relu (Activatio  (None, 7, 7, 128)   0           ['conv5_block9_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv5_block9_2_conv (Conv2D)   (None, 7, 7, 32)     36864       ['conv5_block9_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv5_block9_concat (Concatena  (None, 7, 7, 800)   0           ['conv5_block8_concat[0][0]',    \n",
            " te)                                                              'conv5_block9_2_conv[0][0]']    \n",
            "                                                                                                  \n",
            " conv5_block10_0_bn (BatchNorma  (None, 7, 7, 800)   3200        ['conv5_block9_concat[0][0]']    \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " conv5_block10_0_relu (Activati  (None, 7, 7, 800)   0           ['conv5_block10_0_bn[0][0]']     \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv5_block10_1_conv (Conv2D)  (None, 7, 7, 128)    102400      ['conv5_block10_0_relu[0][0]']   \n",
            "                                                                                                  \n",
            " conv5_block10_1_bn (BatchNorma  (None, 7, 7, 128)   512         ['conv5_block10_1_conv[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " conv5_block10_1_relu (Activati  (None, 7, 7, 128)   0           ['conv5_block10_1_bn[0][0]']     \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv5_block10_2_conv (Conv2D)  (None, 7, 7, 32)     36864       ['conv5_block10_1_relu[0][0]']   \n",
            "                                                                                                  \n",
            " conv5_block10_concat (Concaten  (None, 7, 7, 832)   0           ['conv5_block9_concat[0][0]',    \n",
            " ate)                                                             'conv5_block10_2_conv[0][0]']   \n",
            "                                                                                                  \n",
            " conv5_block11_0_bn (BatchNorma  (None, 7, 7, 832)   3328        ['conv5_block10_concat[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " conv5_block11_0_relu (Activati  (None, 7, 7, 832)   0           ['conv5_block11_0_bn[0][0]']     \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv5_block11_1_conv (Conv2D)  (None, 7, 7, 128)    106496      ['conv5_block11_0_relu[0][0]']   \n",
            "                                                                                                  \n",
            " conv5_block11_1_bn (BatchNorma  (None, 7, 7, 128)   512         ['conv5_block11_1_conv[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " conv5_block11_1_relu (Activati  (None, 7, 7, 128)   0           ['conv5_block11_1_bn[0][0]']     \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv5_block11_2_conv (Conv2D)  (None, 7, 7, 32)     36864       ['conv5_block11_1_relu[0][0]']   \n",
            "                                                                                                  \n",
            " conv5_block11_concat (Concaten  (None, 7, 7, 864)   0           ['conv5_block10_concat[0][0]',   \n",
            " ate)                                                             'conv5_block11_2_conv[0][0]']   \n",
            "                                                                                                  \n",
            " conv5_block12_0_bn (BatchNorma  (None, 7, 7, 864)   3456        ['conv5_block11_concat[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " conv5_block12_0_relu (Activati  (None, 7, 7, 864)   0           ['conv5_block12_0_bn[0][0]']     \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv5_block12_1_conv (Conv2D)  (None, 7, 7, 128)    110592      ['conv5_block12_0_relu[0][0]']   \n",
            "                                                                                                  \n",
            " conv5_block12_1_bn (BatchNorma  (None, 7, 7, 128)   512         ['conv5_block12_1_conv[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " conv5_block12_1_relu (Activati  (None, 7, 7, 128)   0           ['conv5_block12_1_bn[0][0]']     \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv5_block12_2_conv (Conv2D)  (None, 7, 7, 32)     36864       ['conv5_block12_1_relu[0][0]']   \n",
            "                                                                                                  \n",
            " conv5_block12_concat (Concaten  (None, 7, 7, 896)   0           ['conv5_block11_concat[0][0]',   \n",
            " ate)                                                             'conv5_block12_2_conv[0][0]']   \n",
            "                                                                                                  \n",
            " conv5_block13_0_bn (BatchNorma  (None, 7, 7, 896)   3584        ['conv5_block12_concat[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " conv5_block13_0_relu (Activati  (None, 7, 7, 896)   0           ['conv5_block13_0_bn[0][0]']     \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv5_block13_1_conv (Conv2D)  (None, 7, 7, 128)    114688      ['conv5_block13_0_relu[0][0]']   \n",
            "                                                                                                  \n",
            " conv5_block13_1_bn (BatchNorma  (None, 7, 7, 128)   512         ['conv5_block13_1_conv[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " conv5_block13_1_relu (Activati  (None, 7, 7, 128)   0           ['conv5_block13_1_bn[0][0]']     \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv5_block13_2_conv (Conv2D)  (None, 7, 7, 32)     36864       ['conv5_block13_1_relu[0][0]']   \n",
            "                                                                                                  \n",
            " conv5_block13_concat (Concaten  (None, 7, 7, 928)   0           ['conv5_block12_concat[0][0]',   \n",
            " ate)                                                             'conv5_block13_2_conv[0][0]']   \n",
            "                                                                                                  \n",
            " conv5_block14_0_bn (BatchNorma  (None, 7, 7, 928)   3712        ['conv5_block13_concat[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " conv5_block14_0_relu (Activati  (None, 7, 7, 928)   0           ['conv5_block14_0_bn[0][0]']     \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv5_block14_1_conv (Conv2D)  (None, 7, 7, 128)    118784      ['conv5_block14_0_relu[0][0]']   \n",
            "                                                                                                  \n",
            " conv5_block14_1_bn (BatchNorma  (None, 7, 7, 128)   512         ['conv5_block14_1_conv[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " conv5_block14_1_relu (Activati  (None, 7, 7, 128)   0           ['conv5_block14_1_bn[0][0]']     \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv5_block14_2_conv (Conv2D)  (None, 7, 7, 32)     36864       ['conv5_block14_1_relu[0][0]']   \n",
            "                                                                                                  \n",
            " conv5_block14_concat (Concaten  (None, 7, 7, 960)   0           ['conv5_block13_concat[0][0]',   \n",
            " ate)                                                             'conv5_block14_2_conv[0][0]']   \n",
            "                                                                                                  \n",
            " conv5_block15_0_bn (BatchNorma  (None, 7, 7, 960)   3840        ['conv5_block14_concat[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " conv5_block15_0_relu (Activati  (None, 7, 7, 960)   0           ['conv5_block15_0_bn[0][0]']     \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv5_block15_1_conv (Conv2D)  (None, 7, 7, 128)    122880      ['conv5_block15_0_relu[0][0]']   \n",
            "                                                                                                  \n",
            " conv5_block15_1_bn (BatchNorma  (None, 7, 7, 128)   512         ['conv5_block15_1_conv[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " conv5_block15_1_relu (Activati  (None, 7, 7, 128)   0           ['conv5_block15_1_bn[0][0]']     \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv5_block15_2_conv (Conv2D)  (None, 7, 7, 32)     36864       ['conv5_block15_1_relu[0][0]']   \n",
            "                                                                                                  \n",
            " conv5_block15_concat (Concaten  (None, 7, 7, 992)   0           ['conv5_block14_concat[0][0]',   \n",
            " ate)                                                             'conv5_block15_2_conv[0][0]']   \n",
            "                                                                                                  \n",
            " conv5_block16_0_bn (BatchNorma  (None, 7, 7, 992)   3968        ['conv5_block15_concat[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " conv5_block16_0_relu (Activati  (None, 7, 7, 992)   0           ['conv5_block16_0_bn[0][0]']     \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv5_block16_1_conv (Conv2D)  (None, 7, 7, 128)    126976      ['conv5_block16_0_relu[0][0]']   \n",
            "                                                                                                  \n",
            " conv5_block16_1_bn (BatchNorma  (None, 7, 7, 128)   512         ['conv5_block16_1_conv[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " conv5_block16_1_relu (Activati  (None, 7, 7, 128)   0           ['conv5_block16_1_bn[0][0]']     \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv5_block16_2_conv (Conv2D)  (None, 7, 7, 32)     36864       ['conv5_block16_1_relu[0][0]']   \n",
            "                                                                                                  \n",
            " conv5_block16_concat (Concaten  (None, 7, 7, 1024)  0           ['conv5_block15_concat[0][0]',   \n",
            " ate)                                                             'conv5_block16_2_conv[0][0]']   \n",
            "                                                                                                  \n",
            " bn (BatchNormalization)        (None, 7, 7, 1024)   4096        ['conv5_block16_concat[0][0]']   \n",
            "                                                                                                  \n",
            " relu (Activation)              (None, 7, 7, 1024)   0           ['bn[0][0]']                     \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 7,037,504\n",
            "Trainable params: 0\n",
            "Non-trainable params: 7,037,504\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Add extra layers to the pre trained model\n",
        "no_of_categories = 4\n",
        "x =  AveragePooling2D(pool_size = (4, 4))(densenet121.output)\n",
        "x = Flatten()(x)\n",
        "x = Dense(units = 16, activation = 'relu')(x)\n",
        "x = Dropout(0.2)(x)\n",
        "x = Dense(units = 512, activation = 'relu')(x)\n",
        "predictions = Dense(units = no_of_categories, activation = tf.nn.softmax)(x)\n",
        "model = Model(inputs = densenet121.input, outputs = predictions)\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vI-ivqJOR3ab",
        "outputId": "e9d78d08-37ce-479a-af40-714c34bfb5cc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_1\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_2 (InputLayer)           [(None, 224, 224, 3  0           []                               \n",
            "                                )]                                                                \n",
            "                                                                                                  \n",
            " zero_padding2d (ZeroPadding2D)  (None, 230, 230, 3)  0          ['input_2[0][0]']                \n",
            "                                                                                                  \n",
            " conv1/conv (Conv2D)            (None, 112, 112, 64  9408        ['zero_padding2d[0][0]']         \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv1/bn (BatchNormalization)  (None, 112, 112, 64  256         ['conv1/conv[0][0]']             \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv1/relu (Activation)        (None, 112, 112, 64  0           ['conv1/bn[0][0]']               \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " zero_padding2d_1 (ZeroPadding2  (None, 114, 114, 64  0          ['conv1/relu[0][0]']             \n",
            " D)                             )                                                                 \n",
            "                                                                                                  \n",
            " pool1 (MaxPooling2D)           (None, 56, 56, 64)   0           ['zero_padding2d_1[0][0]']       \n",
            "                                                                                                  \n",
            " conv2_block1_0_bn (BatchNormal  (None, 56, 56, 64)  256         ['pool1[0][0]']                  \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv2_block1_0_relu (Activatio  (None, 56, 56, 64)  0           ['conv2_block1_0_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv2_block1_1_conv (Conv2D)   (None, 56, 56, 128)  8192        ['conv2_block1_0_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv2_block1_1_bn (BatchNormal  (None, 56, 56, 128)  512        ['conv2_block1_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv2_block1_1_relu (Activatio  (None, 56, 56, 128)  0          ['conv2_block1_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv2_block1_2_conv (Conv2D)   (None, 56, 56, 32)   36864       ['conv2_block1_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv2_block1_concat (Concatena  (None, 56, 56, 96)  0           ['pool1[0][0]',                  \n",
            " te)                                                              'conv2_block1_2_conv[0][0]']    \n",
            "                                                                                                  \n",
            " conv2_block2_0_bn (BatchNormal  (None, 56, 56, 96)  384         ['conv2_block1_concat[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv2_block2_0_relu (Activatio  (None, 56, 56, 96)  0           ['conv2_block2_0_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv2_block2_1_conv (Conv2D)   (None, 56, 56, 128)  12288       ['conv2_block2_0_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv2_block2_1_bn (BatchNormal  (None, 56, 56, 128)  512        ['conv2_block2_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv2_block2_1_relu (Activatio  (None, 56, 56, 128)  0          ['conv2_block2_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv2_block2_2_conv (Conv2D)   (None, 56, 56, 32)   36864       ['conv2_block2_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv2_block2_concat (Concatena  (None, 56, 56, 128)  0          ['conv2_block1_concat[0][0]',    \n",
            " te)                                                              'conv2_block2_2_conv[0][0]']    \n",
            "                                                                                                  \n",
            " conv2_block3_0_bn (BatchNormal  (None, 56, 56, 128)  512        ['conv2_block2_concat[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv2_block3_0_relu (Activatio  (None, 56, 56, 128)  0          ['conv2_block3_0_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv2_block3_1_conv (Conv2D)   (None, 56, 56, 128)  16384       ['conv2_block3_0_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv2_block3_1_bn (BatchNormal  (None, 56, 56, 128)  512        ['conv2_block3_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv2_block3_1_relu (Activatio  (None, 56, 56, 128)  0          ['conv2_block3_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv2_block3_2_conv (Conv2D)   (None, 56, 56, 32)   36864       ['conv2_block3_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv2_block3_concat (Concatena  (None, 56, 56, 160)  0          ['conv2_block2_concat[0][0]',    \n",
            " te)                                                              'conv2_block3_2_conv[0][0]']    \n",
            "                                                                                                  \n",
            " conv2_block4_0_bn (BatchNormal  (None, 56, 56, 160)  640        ['conv2_block3_concat[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv2_block4_0_relu (Activatio  (None, 56, 56, 160)  0          ['conv2_block4_0_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv2_block4_1_conv (Conv2D)   (None, 56, 56, 128)  20480       ['conv2_block4_0_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv2_block4_1_bn (BatchNormal  (None, 56, 56, 128)  512        ['conv2_block4_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv2_block4_1_relu (Activatio  (None, 56, 56, 128)  0          ['conv2_block4_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv2_block4_2_conv (Conv2D)   (None, 56, 56, 32)   36864       ['conv2_block4_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv2_block4_concat (Concatena  (None, 56, 56, 192)  0          ['conv2_block3_concat[0][0]',    \n",
            " te)                                                              'conv2_block4_2_conv[0][0]']    \n",
            "                                                                                                  \n",
            " conv2_block5_0_bn (BatchNormal  (None, 56, 56, 192)  768        ['conv2_block4_concat[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv2_block5_0_relu (Activatio  (None, 56, 56, 192)  0          ['conv2_block5_0_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv2_block5_1_conv (Conv2D)   (None, 56, 56, 128)  24576       ['conv2_block5_0_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv2_block5_1_bn (BatchNormal  (None, 56, 56, 128)  512        ['conv2_block5_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv2_block5_1_relu (Activatio  (None, 56, 56, 128)  0          ['conv2_block5_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv2_block5_2_conv (Conv2D)   (None, 56, 56, 32)   36864       ['conv2_block5_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv2_block5_concat (Concatena  (None, 56, 56, 224)  0          ['conv2_block4_concat[0][0]',    \n",
            " te)                                                              'conv2_block5_2_conv[0][0]']    \n",
            "                                                                                                  \n",
            " conv2_block6_0_bn (BatchNormal  (None, 56, 56, 224)  896        ['conv2_block5_concat[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv2_block6_0_relu (Activatio  (None, 56, 56, 224)  0          ['conv2_block6_0_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv2_block6_1_conv (Conv2D)   (None, 56, 56, 128)  28672       ['conv2_block6_0_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv2_block6_1_bn (BatchNormal  (None, 56, 56, 128)  512        ['conv2_block6_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv2_block6_1_relu (Activatio  (None, 56, 56, 128)  0          ['conv2_block6_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv2_block6_2_conv (Conv2D)   (None, 56, 56, 32)   36864       ['conv2_block6_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv2_block6_concat (Concatena  (None, 56, 56, 256)  0          ['conv2_block5_concat[0][0]',    \n",
            " te)                                                              'conv2_block6_2_conv[0][0]']    \n",
            "                                                                                                  \n",
            " pool2_bn (BatchNormalization)  (None, 56, 56, 256)  1024        ['conv2_block6_concat[0][0]']    \n",
            "                                                                                                  \n",
            " pool2_relu (Activation)        (None, 56, 56, 256)  0           ['pool2_bn[0][0]']               \n",
            "                                                                                                  \n",
            " pool2_conv (Conv2D)            (None, 56, 56, 128)  32768       ['pool2_relu[0][0]']             \n",
            "                                                                                                  \n",
            " pool2_pool (AveragePooling2D)  (None, 28, 28, 128)  0           ['pool2_conv[0][0]']             \n",
            "                                                                                                  \n",
            " conv3_block1_0_bn (BatchNormal  (None, 28, 28, 128)  512        ['pool2_pool[0][0]']             \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv3_block1_0_relu (Activatio  (None, 28, 28, 128)  0          ['conv3_block1_0_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv3_block1_1_conv (Conv2D)   (None, 28, 28, 128)  16384       ['conv3_block1_0_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv3_block1_1_bn (BatchNormal  (None, 28, 28, 128)  512        ['conv3_block1_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv3_block1_1_relu (Activatio  (None, 28, 28, 128)  0          ['conv3_block1_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv3_block1_2_conv (Conv2D)   (None, 28, 28, 32)   36864       ['conv3_block1_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv3_block1_concat (Concatena  (None, 28, 28, 160)  0          ['pool2_pool[0][0]',             \n",
            " te)                                                              'conv3_block1_2_conv[0][0]']    \n",
            "                                                                                                  \n",
            " conv3_block2_0_bn (BatchNormal  (None, 28, 28, 160)  640        ['conv3_block1_concat[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv3_block2_0_relu (Activatio  (None, 28, 28, 160)  0          ['conv3_block2_0_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv3_block2_1_conv (Conv2D)   (None, 28, 28, 128)  20480       ['conv3_block2_0_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv3_block2_1_bn (BatchNormal  (None, 28, 28, 128)  512        ['conv3_block2_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv3_block2_1_relu (Activatio  (None, 28, 28, 128)  0          ['conv3_block2_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv3_block2_2_conv (Conv2D)   (None, 28, 28, 32)   36864       ['conv3_block2_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv3_block2_concat (Concatena  (None, 28, 28, 192)  0          ['conv3_block1_concat[0][0]',    \n",
            " te)                                                              'conv3_block2_2_conv[0][0]']    \n",
            "                                                                                                  \n",
            " conv3_block3_0_bn (BatchNormal  (None, 28, 28, 192)  768        ['conv3_block2_concat[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv3_block3_0_relu (Activatio  (None, 28, 28, 192)  0          ['conv3_block3_0_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv3_block3_1_conv (Conv2D)   (None, 28, 28, 128)  24576       ['conv3_block3_0_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv3_block3_1_bn (BatchNormal  (None, 28, 28, 128)  512        ['conv3_block3_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv3_block3_1_relu (Activatio  (None, 28, 28, 128)  0          ['conv3_block3_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv3_block3_2_conv (Conv2D)   (None, 28, 28, 32)   36864       ['conv3_block3_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv3_block3_concat (Concatena  (None, 28, 28, 224)  0          ['conv3_block2_concat[0][0]',    \n",
            " te)                                                              'conv3_block3_2_conv[0][0]']    \n",
            "                                                                                                  \n",
            " conv3_block4_0_bn (BatchNormal  (None, 28, 28, 224)  896        ['conv3_block3_concat[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv3_block4_0_relu (Activatio  (None, 28, 28, 224)  0          ['conv3_block4_0_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv3_block4_1_conv (Conv2D)   (None, 28, 28, 128)  28672       ['conv3_block4_0_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv3_block4_1_bn (BatchNormal  (None, 28, 28, 128)  512        ['conv3_block4_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv3_block4_1_relu (Activatio  (None, 28, 28, 128)  0          ['conv3_block4_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv3_block4_2_conv (Conv2D)   (None, 28, 28, 32)   36864       ['conv3_block4_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv3_block4_concat (Concatena  (None, 28, 28, 256)  0          ['conv3_block3_concat[0][0]',    \n",
            " te)                                                              'conv3_block4_2_conv[0][0]']    \n",
            "                                                                                                  \n",
            " conv3_block5_0_bn (BatchNormal  (None, 28, 28, 256)  1024       ['conv3_block4_concat[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv3_block5_0_relu (Activatio  (None, 28, 28, 256)  0          ['conv3_block5_0_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv3_block5_1_conv (Conv2D)   (None, 28, 28, 128)  32768       ['conv3_block5_0_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv3_block5_1_bn (BatchNormal  (None, 28, 28, 128)  512        ['conv3_block5_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv3_block5_1_relu (Activatio  (None, 28, 28, 128)  0          ['conv3_block5_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv3_block5_2_conv (Conv2D)   (None, 28, 28, 32)   36864       ['conv3_block5_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv3_block5_concat (Concatena  (None, 28, 28, 288)  0          ['conv3_block4_concat[0][0]',    \n",
            " te)                                                              'conv3_block5_2_conv[0][0]']    \n",
            "                                                                                                  \n",
            " conv3_block6_0_bn (BatchNormal  (None, 28, 28, 288)  1152       ['conv3_block5_concat[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv3_block6_0_relu (Activatio  (None, 28, 28, 288)  0          ['conv3_block6_0_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv3_block6_1_conv (Conv2D)   (None, 28, 28, 128)  36864       ['conv3_block6_0_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv3_block6_1_bn (BatchNormal  (None, 28, 28, 128)  512        ['conv3_block6_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv3_block6_1_relu (Activatio  (None, 28, 28, 128)  0          ['conv3_block6_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv3_block6_2_conv (Conv2D)   (None, 28, 28, 32)   36864       ['conv3_block6_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv3_block6_concat (Concatena  (None, 28, 28, 320)  0          ['conv3_block5_concat[0][0]',    \n",
            " te)                                                              'conv3_block6_2_conv[0][0]']    \n",
            "                                                                                                  \n",
            " conv3_block7_0_bn (BatchNormal  (None, 28, 28, 320)  1280       ['conv3_block6_concat[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv3_block7_0_relu (Activatio  (None, 28, 28, 320)  0          ['conv3_block7_0_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv3_block7_1_conv (Conv2D)   (None, 28, 28, 128)  40960       ['conv3_block7_0_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv3_block7_1_bn (BatchNormal  (None, 28, 28, 128)  512        ['conv3_block7_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv3_block7_1_relu (Activatio  (None, 28, 28, 128)  0          ['conv3_block7_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv3_block7_2_conv (Conv2D)   (None, 28, 28, 32)   36864       ['conv3_block7_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv3_block7_concat (Concatena  (None, 28, 28, 352)  0          ['conv3_block6_concat[0][0]',    \n",
            " te)                                                              'conv3_block7_2_conv[0][0]']    \n",
            "                                                                                                  \n",
            " conv3_block8_0_bn (BatchNormal  (None, 28, 28, 352)  1408       ['conv3_block7_concat[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv3_block8_0_relu (Activatio  (None, 28, 28, 352)  0          ['conv3_block8_0_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv3_block8_1_conv (Conv2D)   (None, 28, 28, 128)  45056       ['conv3_block8_0_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv3_block8_1_bn (BatchNormal  (None, 28, 28, 128)  512        ['conv3_block8_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv3_block8_1_relu (Activatio  (None, 28, 28, 128)  0          ['conv3_block8_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv3_block8_2_conv (Conv2D)   (None, 28, 28, 32)   36864       ['conv3_block8_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv3_block8_concat (Concatena  (None, 28, 28, 384)  0          ['conv3_block7_concat[0][0]',    \n",
            " te)                                                              'conv3_block8_2_conv[0][0]']    \n",
            "                                                                                                  \n",
            " conv3_block9_0_bn (BatchNormal  (None, 28, 28, 384)  1536       ['conv3_block8_concat[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv3_block9_0_relu (Activatio  (None, 28, 28, 384)  0          ['conv3_block9_0_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv3_block9_1_conv (Conv2D)   (None, 28, 28, 128)  49152       ['conv3_block9_0_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv3_block9_1_bn (BatchNormal  (None, 28, 28, 128)  512        ['conv3_block9_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv3_block9_1_relu (Activatio  (None, 28, 28, 128)  0          ['conv3_block9_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv3_block9_2_conv (Conv2D)   (None, 28, 28, 32)   36864       ['conv3_block9_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv3_block9_concat (Concatena  (None, 28, 28, 416)  0          ['conv3_block8_concat[0][0]',    \n",
            " te)                                                              'conv3_block9_2_conv[0][0]']    \n",
            "                                                                                                  \n",
            " conv3_block10_0_bn (BatchNorma  (None, 28, 28, 416)  1664       ['conv3_block9_concat[0][0]']    \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " conv3_block10_0_relu (Activati  (None, 28, 28, 416)  0          ['conv3_block10_0_bn[0][0]']     \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv3_block10_1_conv (Conv2D)  (None, 28, 28, 128)  53248       ['conv3_block10_0_relu[0][0]']   \n",
            "                                                                                                  \n",
            " conv3_block10_1_bn (BatchNorma  (None, 28, 28, 128)  512        ['conv3_block10_1_conv[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " conv3_block10_1_relu (Activati  (None, 28, 28, 128)  0          ['conv3_block10_1_bn[0][0]']     \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv3_block10_2_conv (Conv2D)  (None, 28, 28, 32)   36864       ['conv3_block10_1_relu[0][0]']   \n",
            "                                                                                                  \n",
            " conv3_block10_concat (Concaten  (None, 28, 28, 448)  0          ['conv3_block9_concat[0][0]',    \n",
            " ate)                                                             'conv3_block10_2_conv[0][0]']   \n",
            "                                                                                                  \n",
            " conv3_block11_0_bn (BatchNorma  (None, 28, 28, 448)  1792       ['conv3_block10_concat[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " conv3_block11_0_relu (Activati  (None, 28, 28, 448)  0          ['conv3_block11_0_bn[0][0]']     \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv3_block11_1_conv (Conv2D)  (None, 28, 28, 128)  57344       ['conv3_block11_0_relu[0][0]']   \n",
            "                                                                                                  \n",
            " conv3_block11_1_bn (BatchNorma  (None, 28, 28, 128)  512        ['conv3_block11_1_conv[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " conv3_block11_1_relu (Activati  (None, 28, 28, 128)  0          ['conv3_block11_1_bn[0][0]']     \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv3_block11_2_conv (Conv2D)  (None, 28, 28, 32)   36864       ['conv3_block11_1_relu[0][0]']   \n",
            "                                                                                                  \n",
            " conv3_block11_concat (Concaten  (None, 28, 28, 480)  0          ['conv3_block10_concat[0][0]',   \n",
            " ate)                                                             'conv3_block11_2_conv[0][0]']   \n",
            "                                                                                                  \n",
            " conv3_block12_0_bn (BatchNorma  (None, 28, 28, 480)  1920       ['conv3_block11_concat[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " conv3_block12_0_relu (Activati  (None, 28, 28, 480)  0          ['conv3_block12_0_bn[0][0]']     \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv3_block12_1_conv (Conv2D)  (None, 28, 28, 128)  61440       ['conv3_block12_0_relu[0][0]']   \n",
            "                                                                                                  \n",
            " conv3_block12_1_bn (BatchNorma  (None, 28, 28, 128)  512        ['conv3_block12_1_conv[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " conv3_block12_1_relu (Activati  (None, 28, 28, 128)  0          ['conv3_block12_1_bn[0][0]']     \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv3_block12_2_conv (Conv2D)  (None, 28, 28, 32)   36864       ['conv3_block12_1_relu[0][0]']   \n",
            "                                                                                                  \n",
            " conv3_block12_concat (Concaten  (None, 28, 28, 512)  0          ['conv3_block11_concat[0][0]',   \n",
            " ate)                                                             'conv3_block12_2_conv[0][0]']   \n",
            "                                                                                                  \n",
            " pool3_bn (BatchNormalization)  (None, 28, 28, 512)  2048        ['conv3_block12_concat[0][0]']   \n",
            "                                                                                                  \n",
            " pool3_relu (Activation)        (None, 28, 28, 512)  0           ['pool3_bn[0][0]']               \n",
            "                                                                                                  \n",
            " pool3_conv (Conv2D)            (None, 28, 28, 256)  131072      ['pool3_relu[0][0]']             \n",
            "                                                                                                  \n",
            " pool3_pool (AveragePooling2D)  (None, 14, 14, 256)  0           ['pool3_conv[0][0]']             \n",
            "                                                                                                  \n",
            " conv4_block1_0_bn (BatchNormal  (None, 14, 14, 256)  1024       ['pool3_pool[0][0]']             \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block1_0_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block1_0_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block1_1_conv (Conv2D)   (None, 14, 14, 128)  32768       ['conv4_block1_0_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv4_block1_1_bn (BatchNormal  (None, 14, 14, 128)  512        ['conv4_block1_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block1_1_relu (Activatio  (None, 14, 14, 128)  0          ['conv4_block1_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block1_2_conv (Conv2D)   (None, 14, 14, 32)   36864       ['conv4_block1_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv4_block1_concat (Concatena  (None, 14, 14, 288)  0          ['pool3_pool[0][0]',             \n",
            " te)                                                              'conv4_block1_2_conv[0][0]']    \n",
            "                                                                                                  \n",
            " conv4_block2_0_bn (BatchNormal  (None, 14, 14, 288)  1152       ['conv4_block1_concat[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block2_0_relu (Activatio  (None, 14, 14, 288)  0          ['conv4_block2_0_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block2_1_conv (Conv2D)   (None, 14, 14, 128)  36864       ['conv4_block2_0_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv4_block2_1_bn (BatchNormal  (None, 14, 14, 128)  512        ['conv4_block2_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block2_1_relu (Activatio  (None, 14, 14, 128)  0          ['conv4_block2_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block2_2_conv (Conv2D)   (None, 14, 14, 32)   36864       ['conv4_block2_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv4_block2_concat (Concatena  (None, 14, 14, 320)  0          ['conv4_block1_concat[0][0]',    \n",
            " te)                                                              'conv4_block2_2_conv[0][0]']    \n",
            "                                                                                                  \n",
            " conv4_block3_0_bn (BatchNormal  (None, 14, 14, 320)  1280       ['conv4_block2_concat[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block3_0_relu (Activatio  (None, 14, 14, 320)  0          ['conv4_block3_0_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block3_1_conv (Conv2D)   (None, 14, 14, 128)  40960       ['conv4_block3_0_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv4_block3_1_bn (BatchNormal  (None, 14, 14, 128)  512        ['conv4_block3_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block3_1_relu (Activatio  (None, 14, 14, 128)  0          ['conv4_block3_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block3_2_conv (Conv2D)   (None, 14, 14, 32)   36864       ['conv4_block3_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv4_block3_concat (Concatena  (None, 14, 14, 352)  0          ['conv4_block2_concat[0][0]',    \n",
            " te)                                                              'conv4_block3_2_conv[0][0]']    \n",
            "                                                                                                  \n",
            " conv4_block4_0_bn (BatchNormal  (None, 14, 14, 352)  1408       ['conv4_block3_concat[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block4_0_relu (Activatio  (None, 14, 14, 352)  0          ['conv4_block4_0_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block4_1_conv (Conv2D)   (None, 14, 14, 128)  45056       ['conv4_block4_0_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv4_block4_1_bn (BatchNormal  (None, 14, 14, 128)  512        ['conv4_block4_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block4_1_relu (Activatio  (None, 14, 14, 128)  0          ['conv4_block4_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block4_2_conv (Conv2D)   (None, 14, 14, 32)   36864       ['conv4_block4_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv4_block4_concat (Concatena  (None, 14, 14, 384)  0          ['conv4_block3_concat[0][0]',    \n",
            " te)                                                              'conv4_block4_2_conv[0][0]']    \n",
            "                                                                                                  \n",
            " conv4_block5_0_bn (BatchNormal  (None, 14, 14, 384)  1536       ['conv4_block4_concat[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block5_0_relu (Activatio  (None, 14, 14, 384)  0          ['conv4_block5_0_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block5_1_conv (Conv2D)   (None, 14, 14, 128)  49152       ['conv4_block5_0_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv4_block5_1_bn (BatchNormal  (None, 14, 14, 128)  512        ['conv4_block5_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block5_1_relu (Activatio  (None, 14, 14, 128)  0          ['conv4_block5_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block5_2_conv (Conv2D)   (None, 14, 14, 32)   36864       ['conv4_block5_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv4_block5_concat (Concatena  (None, 14, 14, 416)  0          ['conv4_block4_concat[0][0]',    \n",
            " te)                                                              'conv4_block5_2_conv[0][0]']    \n",
            "                                                                                                  \n",
            " conv4_block6_0_bn (BatchNormal  (None, 14, 14, 416)  1664       ['conv4_block5_concat[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block6_0_relu (Activatio  (None, 14, 14, 416)  0          ['conv4_block6_0_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block6_1_conv (Conv2D)   (None, 14, 14, 128)  53248       ['conv4_block6_0_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv4_block6_1_bn (BatchNormal  (None, 14, 14, 128)  512        ['conv4_block6_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block6_1_relu (Activatio  (None, 14, 14, 128)  0          ['conv4_block6_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block6_2_conv (Conv2D)   (None, 14, 14, 32)   36864       ['conv4_block6_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv4_block6_concat (Concatena  (None, 14, 14, 448)  0          ['conv4_block5_concat[0][0]',    \n",
            " te)                                                              'conv4_block6_2_conv[0][0]']    \n",
            "                                                                                                  \n",
            " conv4_block7_0_bn (BatchNormal  (None, 14, 14, 448)  1792       ['conv4_block6_concat[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block7_0_relu (Activatio  (None, 14, 14, 448)  0          ['conv4_block7_0_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block7_1_conv (Conv2D)   (None, 14, 14, 128)  57344       ['conv4_block7_0_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv4_block7_1_bn (BatchNormal  (None, 14, 14, 128)  512        ['conv4_block7_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block7_1_relu (Activatio  (None, 14, 14, 128)  0          ['conv4_block7_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block7_2_conv (Conv2D)   (None, 14, 14, 32)   36864       ['conv4_block7_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv4_block7_concat (Concatena  (None, 14, 14, 480)  0          ['conv4_block6_concat[0][0]',    \n",
            " te)                                                              'conv4_block7_2_conv[0][0]']    \n",
            "                                                                                                  \n",
            " conv4_block8_0_bn (BatchNormal  (None, 14, 14, 480)  1920       ['conv4_block7_concat[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block8_0_relu (Activatio  (None, 14, 14, 480)  0          ['conv4_block8_0_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block8_1_conv (Conv2D)   (None, 14, 14, 128)  61440       ['conv4_block8_0_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv4_block8_1_bn (BatchNormal  (None, 14, 14, 128)  512        ['conv4_block8_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block8_1_relu (Activatio  (None, 14, 14, 128)  0          ['conv4_block8_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block8_2_conv (Conv2D)   (None, 14, 14, 32)   36864       ['conv4_block8_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv4_block8_concat (Concatena  (None, 14, 14, 512)  0          ['conv4_block7_concat[0][0]',    \n",
            " te)                                                              'conv4_block8_2_conv[0][0]']    \n",
            "                                                                                                  \n",
            " conv4_block9_0_bn (BatchNormal  (None, 14, 14, 512)  2048       ['conv4_block8_concat[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block9_0_relu (Activatio  (None, 14, 14, 512)  0          ['conv4_block9_0_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block9_1_conv (Conv2D)   (None, 14, 14, 128)  65536       ['conv4_block9_0_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv4_block9_1_bn (BatchNormal  (None, 14, 14, 128)  512        ['conv4_block9_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block9_1_relu (Activatio  (None, 14, 14, 128)  0          ['conv4_block9_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block9_2_conv (Conv2D)   (None, 14, 14, 32)   36864       ['conv4_block9_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv4_block9_concat (Concatena  (None, 14, 14, 544)  0          ['conv4_block8_concat[0][0]',    \n",
            " te)                                                              'conv4_block9_2_conv[0][0]']    \n",
            "                                                                                                  \n",
            " conv4_block10_0_bn (BatchNorma  (None, 14, 14, 544)  2176       ['conv4_block9_concat[0][0]']    \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " conv4_block10_0_relu (Activati  (None, 14, 14, 544)  0          ['conv4_block10_0_bn[0][0]']     \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv4_block10_1_conv (Conv2D)  (None, 14, 14, 128)  69632       ['conv4_block10_0_relu[0][0]']   \n",
            "                                                                                                  \n",
            " conv4_block10_1_bn (BatchNorma  (None, 14, 14, 128)  512        ['conv4_block10_1_conv[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " conv4_block10_1_relu (Activati  (None, 14, 14, 128)  0          ['conv4_block10_1_bn[0][0]']     \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv4_block10_2_conv (Conv2D)  (None, 14, 14, 32)   36864       ['conv4_block10_1_relu[0][0]']   \n",
            "                                                                                                  \n",
            " conv4_block10_concat (Concaten  (None, 14, 14, 576)  0          ['conv4_block9_concat[0][0]',    \n",
            " ate)                                                             'conv4_block10_2_conv[0][0]']   \n",
            "                                                                                                  \n",
            " conv4_block11_0_bn (BatchNorma  (None, 14, 14, 576)  2304       ['conv4_block10_concat[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " conv4_block11_0_relu (Activati  (None, 14, 14, 576)  0          ['conv4_block11_0_bn[0][0]']     \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv4_block11_1_conv (Conv2D)  (None, 14, 14, 128)  73728       ['conv4_block11_0_relu[0][0]']   \n",
            "                                                                                                  \n",
            " conv4_block11_1_bn (BatchNorma  (None, 14, 14, 128)  512        ['conv4_block11_1_conv[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " conv4_block11_1_relu (Activati  (None, 14, 14, 128)  0          ['conv4_block11_1_bn[0][0]']     \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv4_block11_2_conv (Conv2D)  (None, 14, 14, 32)   36864       ['conv4_block11_1_relu[0][0]']   \n",
            "                                                                                                  \n",
            " conv4_block11_concat (Concaten  (None, 14, 14, 608)  0          ['conv4_block10_concat[0][0]',   \n",
            " ate)                                                             'conv4_block11_2_conv[0][0]']   \n",
            "                                                                                                  \n",
            " conv4_block12_0_bn (BatchNorma  (None, 14, 14, 608)  2432       ['conv4_block11_concat[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " conv4_block12_0_relu (Activati  (None, 14, 14, 608)  0          ['conv4_block12_0_bn[0][0]']     \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv4_block12_1_conv (Conv2D)  (None, 14, 14, 128)  77824       ['conv4_block12_0_relu[0][0]']   \n",
            "                                                                                                  \n",
            " conv4_block12_1_bn (BatchNorma  (None, 14, 14, 128)  512        ['conv4_block12_1_conv[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " conv4_block12_1_relu (Activati  (None, 14, 14, 128)  0          ['conv4_block12_1_bn[0][0]']     \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv4_block12_2_conv (Conv2D)  (None, 14, 14, 32)   36864       ['conv4_block12_1_relu[0][0]']   \n",
            "                                                                                                  \n",
            " conv4_block12_concat (Concaten  (None, 14, 14, 640)  0          ['conv4_block11_concat[0][0]',   \n",
            " ate)                                                             'conv4_block12_2_conv[0][0]']   \n",
            "                                                                                                  \n",
            " conv4_block13_0_bn (BatchNorma  (None, 14, 14, 640)  2560       ['conv4_block12_concat[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " conv4_block13_0_relu (Activati  (None, 14, 14, 640)  0          ['conv4_block13_0_bn[0][0]']     \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv4_block13_1_conv (Conv2D)  (None, 14, 14, 128)  81920       ['conv4_block13_0_relu[0][0]']   \n",
            "                                                                                                  \n",
            " conv4_block13_1_bn (BatchNorma  (None, 14, 14, 128)  512        ['conv4_block13_1_conv[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " conv4_block13_1_relu (Activati  (None, 14, 14, 128)  0          ['conv4_block13_1_bn[0][0]']     \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv4_block13_2_conv (Conv2D)  (None, 14, 14, 32)   36864       ['conv4_block13_1_relu[0][0]']   \n",
            "                                                                                                  \n",
            " conv4_block13_concat (Concaten  (None, 14, 14, 672)  0          ['conv4_block12_concat[0][0]',   \n",
            " ate)                                                             'conv4_block13_2_conv[0][0]']   \n",
            "                                                                                                  \n",
            " conv4_block14_0_bn (BatchNorma  (None, 14, 14, 672)  2688       ['conv4_block13_concat[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " conv4_block14_0_relu (Activati  (None, 14, 14, 672)  0          ['conv4_block14_0_bn[0][0]']     \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv4_block14_1_conv (Conv2D)  (None, 14, 14, 128)  86016       ['conv4_block14_0_relu[0][0]']   \n",
            "                                                                                                  \n",
            " conv4_block14_1_bn (BatchNorma  (None, 14, 14, 128)  512        ['conv4_block14_1_conv[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " conv4_block14_1_relu (Activati  (None, 14, 14, 128)  0          ['conv4_block14_1_bn[0][0]']     \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv4_block14_2_conv (Conv2D)  (None, 14, 14, 32)   36864       ['conv4_block14_1_relu[0][0]']   \n",
            "                                                                                                  \n",
            " conv4_block14_concat (Concaten  (None, 14, 14, 704)  0          ['conv4_block13_concat[0][0]',   \n",
            " ate)                                                             'conv4_block14_2_conv[0][0]']   \n",
            "                                                                                                  \n",
            " conv4_block15_0_bn (BatchNorma  (None, 14, 14, 704)  2816       ['conv4_block14_concat[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " conv4_block15_0_relu (Activati  (None, 14, 14, 704)  0          ['conv4_block15_0_bn[0][0]']     \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv4_block15_1_conv (Conv2D)  (None, 14, 14, 128)  90112       ['conv4_block15_0_relu[0][0]']   \n",
            "                                                                                                  \n",
            " conv4_block15_1_bn (BatchNorma  (None, 14, 14, 128)  512        ['conv4_block15_1_conv[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " conv4_block15_1_relu (Activati  (None, 14, 14, 128)  0          ['conv4_block15_1_bn[0][0]']     \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv4_block15_2_conv (Conv2D)  (None, 14, 14, 32)   36864       ['conv4_block15_1_relu[0][0]']   \n",
            "                                                                                                  \n",
            " conv4_block15_concat (Concaten  (None, 14, 14, 736)  0          ['conv4_block14_concat[0][0]',   \n",
            " ate)                                                             'conv4_block15_2_conv[0][0]']   \n",
            "                                                                                                  \n",
            " conv4_block16_0_bn (BatchNorma  (None, 14, 14, 736)  2944       ['conv4_block15_concat[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " conv4_block16_0_relu (Activati  (None, 14, 14, 736)  0          ['conv4_block16_0_bn[0][0]']     \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv4_block16_1_conv (Conv2D)  (None, 14, 14, 128)  94208       ['conv4_block16_0_relu[0][0]']   \n",
            "                                                                                                  \n",
            " conv4_block16_1_bn (BatchNorma  (None, 14, 14, 128)  512        ['conv4_block16_1_conv[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " conv4_block16_1_relu (Activati  (None, 14, 14, 128)  0          ['conv4_block16_1_bn[0][0]']     \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv4_block16_2_conv (Conv2D)  (None, 14, 14, 32)   36864       ['conv4_block16_1_relu[0][0]']   \n",
            "                                                                                                  \n",
            " conv4_block16_concat (Concaten  (None, 14, 14, 768)  0          ['conv4_block15_concat[0][0]',   \n",
            " ate)                                                             'conv4_block16_2_conv[0][0]']   \n",
            "                                                                                                  \n",
            " conv4_block17_0_bn (BatchNorma  (None, 14, 14, 768)  3072       ['conv4_block16_concat[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " conv4_block17_0_relu (Activati  (None, 14, 14, 768)  0          ['conv4_block17_0_bn[0][0]']     \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv4_block17_1_conv (Conv2D)  (None, 14, 14, 128)  98304       ['conv4_block17_0_relu[0][0]']   \n",
            "                                                                                                  \n",
            " conv4_block17_1_bn (BatchNorma  (None, 14, 14, 128)  512        ['conv4_block17_1_conv[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " conv4_block17_1_relu (Activati  (None, 14, 14, 128)  0          ['conv4_block17_1_bn[0][0]']     \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv4_block17_2_conv (Conv2D)  (None, 14, 14, 32)   36864       ['conv4_block17_1_relu[0][0]']   \n",
            "                                                                                                  \n",
            " conv4_block17_concat (Concaten  (None, 14, 14, 800)  0          ['conv4_block16_concat[0][0]',   \n",
            " ate)                                                             'conv4_block17_2_conv[0][0]']   \n",
            "                                                                                                  \n",
            " conv4_block18_0_bn (BatchNorma  (None, 14, 14, 800)  3200       ['conv4_block17_concat[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " conv4_block18_0_relu (Activati  (None, 14, 14, 800)  0          ['conv4_block18_0_bn[0][0]']     \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv4_block18_1_conv (Conv2D)  (None, 14, 14, 128)  102400      ['conv4_block18_0_relu[0][0]']   \n",
            "                                                                                                  \n",
            " conv4_block18_1_bn (BatchNorma  (None, 14, 14, 128)  512        ['conv4_block18_1_conv[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " conv4_block18_1_relu (Activati  (None, 14, 14, 128)  0          ['conv4_block18_1_bn[0][0]']     \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv4_block18_2_conv (Conv2D)  (None, 14, 14, 32)   36864       ['conv4_block18_1_relu[0][0]']   \n",
            "                                                                                                  \n",
            " conv4_block18_concat (Concaten  (None, 14, 14, 832)  0          ['conv4_block17_concat[0][0]',   \n",
            " ate)                                                             'conv4_block18_2_conv[0][0]']   \n",
            "                                                                                                  \n",
            " conv4_block19_0_bn (BatchNorma  (None, 14, 14, 832)  3328       ['conv4_block18_concat[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " conv4_block19_0_relu (Activati  (None, 14, 14, 832)  0          ['conv4_block19_0_bn[0][0]']     \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv4_block19_1_conv (Conv2D)  (None, 14, 14, 128)  106496      ['conv4_block19_0_relu[0][0]']   \n",
            "                                                                                                  \n",
            " conv4_block19_1_bn (BatchNorma  (None, 14, 14, 128)  512        ['conv4_block19_1_conv[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " conv4_block19_1_relu (Activati  (None, 14, 14, 128)  0          ['conv4_block19_1_bn[0][0]']     \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv4_block19_2_conv (Conv2D)  (None, 14, 14, 32)   36864       ['conv4_block19_1_relu[0][0]']   \n",
            "                                                                                                  \n",
            " conv4_block19_concat (Concaten  (None, 14, 14, 864)  0          ['conv4_block18_concat[0][0]',   \n",
            " ate)                                                             'conv4_block19_2_conv[0][0]']   \n",
            "                                                                                                  \n",
            " conv4_block20_0_bn (BatchNorma  (None, 14, 14, 864)  3456       ['conv4_block19_concat[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " conv4_block20_0_relu (Activati  (None, 14, 14, 864)  0          ['conv4_block20_0_bn[0][0]']     \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv4_block20_1_conv (Conv2D)  (None, 14, 14, 128)  110592      ['conv4_block20_0_relu[0][0]']   \n",
            "                                                                                                  \n",
            " conv4_block20_1_bn (BatchNorma  (None, 14, 14, 128)  512        ['conv4_block20_1_conv[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " conv4_block20_1_relu (Activati  (None, 14, 14, 128)  0          ['conv4_block20_1_bn[0][0]']     \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv4_block20_2_conv (Conv2D)  (None, 14, 14, 32)   36864       ['conv4_block20_1_relu[0][0]']   \n",
            "                                                                                                  \n",
            " conv4_block20_concat (Concaten  (None, 14, 14, 896)  0          ['conv4_block19_concat[0][0]',   \n",
            " ate)                                                             'conv4_block20_2_conv[0][0]']   \n",
            "                                                                                                  \n",
            " conv4_block21_0_bn (BatchNorma  (None, 14, 14, 896)  3584       ['conv4_block20_concat[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " conv4_block21_0_relu (Activati  (None, 14, 14, 896)  0          ['conv4_block21_0_bn[0][0]']     \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv4_block21_1_conv (Conv2D)  (None, 14, 14, 128)  114688      ['conv4_block21_0_relu[0][0]']   \n",
            "                                                                                                  \n",
            " conv4_block21_1_bn (BatchNorma  (None, 14, 14, 128)  512        ['conv4_block21_1_conv[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " conv4_block21_1_relu (Activati  (None, 14, 14, 128)  0          ['conv4_block21_1_bn[0][0]']     \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv4_block21_2_conv (Conv2D)  (None, 14, 14, 32)   36864       ['conv4_block21_1_relu[0][0]']   \n",
            "                                                                                                  \n",
            " conv4_block21_concat (Concaten  (None, 14, 14, 928)  0          ['conv4_block20_concat[0][0]',   \n",
            " ate)                                                             'conv4_block21_2_conv[0][0]']   \n",
            "                                                                                                  \n",
            " conv4_block22_0_bn (BatchNorma  (None, 14, 14, 928)  3712       ['conv4_block21_concat[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " conv4_block22_0_relu (Activati  (None, 14, 14, 928)  0          ['conv4_block22_0_bn[0][0]']     \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv4_block22_1_conv (Conv2D)  (None, 14, 14, 128)  118784      ['conv4_block22_0_relu[0][0]']   \n",
            "                                                                                                  \n",
            " conv4_block22_1_bn (BatchNorma  (None, 14, 14, 128)  512        ['conv4_block22_1_conv[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " conv4_block22_1_relu (Activati  (None, 14, 14, 128)  0          ['conv4_block22_1_bn[0][0]']     \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv4_block22_2_conv (Conv2D)  (None, 14, 14, 32)   36864       ['conv4_block22_1_relu[0][0]']   \n",
            "                                                                                                  \n",
            " conv4_block22_concat (Concaten  (None, 14, 14, 960)  0          ['conv4_block21_concat[0][0]',   \n",
            " ate)                                                             'conv4_block22_2_conv[0][0]']   \n",
            "                                                                                                  \n",
            " conv4_block23_0_bn (BatchNorma  (None, 14, 14, 960)  3840       ['conv4_block22_concat[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " conv4_block23_0_relu (Activati  (None, 14, 14, 960)  0          ['conv4_block23_0_bn[0][0]']     \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv4_block23_1_conv (Conv2D)  (None, 14, 14, 128)  122880      ['conv4_block23_0_relu[0][0]']   \n",
            "                                                                                                  \n",
            " conv4_block23_1_bn (BatchNorma  (None, 14, 14, 128)  512        ['conv4_block23_1_conv[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " conv4_block23_1_relu (Activati  (None, 14, 14, 128)  0          ['conv4_block23_1_bn[0][0]']     \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv4_block23_2_conv (Conv2D)  (None, 14, 14, 32)   36864       ['conv4_block23_1_relu[0][0]']   \n",
            "                                                                                                  \n",
            " conv4_block23_concat (Concaten  (None, 14, 14, 992)  0          ['conv4_block22_concat[0][0]',   \n",
            " ate)                                                             'conv4_block23_2_conv[0][0]']   \n",
            "                                                                                                  \n",
            " conv4_block24_0_bn (BatchNorma  (None, 14, 14, 992)  3968       ['conv4_block23_concat[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " conv4_block24_0_relu (Activati  (None, 14, 14, 992)  0          ['conv4_block24_0_bn[0][0]']     \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv4_block24_1_conv (Conv2D)  (None, 14, 14, 128)  126976      ['conv4_block24_0_relu[0][0]']   \n",
            "                                                                                                  \n",
            " conv4_block24_1_bn (BatchNorma  (None, 14, 14, 128)  512        ['conv4_block24_1_conv[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " conv4_block24_1_relu (Activati  (None, 14, 14, 128)  0          ['conv4_block24_1_bn[0][0]']     \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv4_block24_2_conv (Conv2D)  (None, 14, 14, 32)   36864       ['conv4_block24_1_relu[0][0]']   \n",
            "                                                                                                  \n",
            " conv4_block24_concat (Concaten  (None, 14, 14, 1024  0          ['conv4_block23_concat[0][0]',   \n",
            " ate)                           )                                 'conv4_block24_2_conv[0][0]']   \n",
            "                                                                                                  \n",
            " pool4_bn (BatchNormalization)  (None, 14, 14, 1024  4096        ['conv4_block24_concat[0][0]']   \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " pool4_relu (Activation)        (None, 14, 14, 1024  0           ['pool4_bn[0][0]']               \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " pool4_conv (Conv2D)            (None, 14, 14, 512)  524288      ['pool4_relu[0][0]']             \n",
            "                                                                                                  \n",
            " pool4_pool (AveragePooling2D)  (None, 7, 7, 512)    0           ['pool4_conv[0][0]']             \n",
            "                                                                                                  \n",
            " conv5_block1_0_bn (BatchNormal  (None, 7, 7, 512)   2048        ['pool4_pool[0][0]']             \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv5_block1_0_relu (Activatio  (None, 7, 7, 512)   0           ['conv5_block1_0_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv5_block1_1_conv (Conv2D)   (None, 7, 7, 128)    65536       ['conv5_block1_0_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv5_block1_1_bn (BatchNormal  (None, 7, 7, 128)   512         ['conv5_block1_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv5_block1_1_relu (Activatio  (None, 7, 7, 128)   0           ['conv5_block1_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv5_block1_2_conv (Conv2D)   (None, 7, 7, 32)     36864       ['conv5_block1_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv5_block1_concat (Concatena  (None, 7, 7, 544)   0           ['pool4_pool[0][0]',             \n",
            " te)                                                              'conv5_block1_2_conv[0][0]']    \n",
            "                                                                                                  \n",
            " conv5_block2_0_bn (BatchNormal  (None, 7, 7, 544)   2176        ['conv5_block1_concat[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv5_block2_0_relu (Activatio  (None, 7, 7, 544)   0           ['conv5_block2_0_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv5_block2_1_conv (Conv2D)   (None, 7, 7, 128)    69632       ['conv5_block2_0_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv5_block2_1_bn (BatchNormal  (None, 7, 7, 128)   512         ['conv5_block2_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv5_block2_1_relu (Activatio  (None, 7, 7, 128)   0           ['conv5_block2_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv5_block2_2_conv (Conv2D)   (None, 7, 7, 32)     36864       ['conv5_block2_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv5_block2_concat (Concatena  (None, 7, 7, 576)   0           ['conv5_block1_concat[0][0]',    \n",
            " te)                                                              'conv5_block2_2_conv[0][0]']    \n",
            "                                                                                                  \n",
            " conv5_block3_0_bn (BatchNormal  (None, 7, 7, 576)   2304        ['conv5_block2_concat[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv5_block3_0_relu (Activatio  (None, 7, 7, 576)   0           ['conv5_block3_0_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv5_block3_1_conv (Conv2D)   (None, 7, 7, 128)    73728       ['conv5_block3_0_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv5_block3_1_bn (BatchNormal  (None, 7, 7, 128)   512         ['conv5_block3_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv5_block3_1_relu (Activatio  (None, 7, 7, 128)   0           ['conv5_block3_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv5_block3_2_conv (Conv2D)   (None, 7, 7, 32)     36864       ['conv5_block3_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv5_block3_concat (Concatena  (None, 7, 7, 608)   0           ['conv5_block2_concat[0][0]',    \n",
            " te)                                                              'conv5_block3_2_conv[0][0]']    \n",
            "                                                                                                  \n",
            " conv5_block4_0_bn (BatchNormal  (None, 7, 7, 608)   2432        ['conv5_block3_concat[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv5_block4_0_relu (Activatio  (None, 7, 7, 608)   0           ['conv5_block4_0_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv5_block4_1_conv (Conv2D)   (None, 7, 7, 128)    77824       ['conv5_block4_0_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv5_block4_1_bn (BatchNormal  (None, 7, 7, 128)   512         ['conv5_block4_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv5_block4_1_relu (Activatio  (None, 7, 7, 128)   0           ['conv5_block4_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv5_block4_2_conv (Conv2D)   (None, 7, 7, 32)     36864       ['conv5_block4_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv5_block4_concat (Concatena  (None, 7, 7, 640)   0           ['conv5_block3_concat[0][0]',    \n",
            " te)                                                              'conv5_block4_2_conv[0][0]']    \n",
            "                                                                                                  \n",
            " conv5_block5_0_bn (BatchNormal  (None, 7, 7, 640)   2560        ['conv5_block4_concat[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv5_block5_0_relu (Activatio  (None, 7, 7, 640)   0           ['conv5_block5_0_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv5_block5_1_conv (Conv2D)   (None, 7, 7, 128)    81920       ['conv5_block5_0_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv5_block5_1_bn (BatchNormal  (None, 7, 7, 128)   512         ['conv5_block5_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv5_block5_1_relu (Activatio  (None, 7, 7, 128)   0           ['conv5_block5_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv5_block5_2_conv (Conv2D)   (None, 7, 7, 32)     36864       ['conv5_block5_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv5_block5_concat (Concatena  (None, 7, 7, 672)   0           ['conv5_block4_concat[0][0]',    \n",
            " te)                                                              'conv5_block5_2_conv[0][0]']    \n",
            "                                                                                                  \n",
            " conv5_block6_0_bn (BatchNormal  (None, 7, 7, 672)   2688        ['conv5_block5_concat[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv5_block6_0_relu (Activatio  (None, 7, 7, 672)   0           ['conv5_block6_0_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv5_block6_1_conv (Conv2D)   (None, 7, 7, 128)    86016       ['conv5_block6_0_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv5_block6_1_bn (BatchNormal  (None, 7, 7, 128)   512         ['conv5_block6_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv5_block6_1_relu (Activatio  (None, 7, 7, 128)   0           ['conv5_block6_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv5_block6_2_conv (Conv2D)   (None, 7, 7, 32)     36864       ['conv5_block6_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv5_block6_concat (Concatena  (None, 7, 7, 704)   0           ['conv5_block5_concat[0][0]',    \n",
            " te)                                                              'conv5_block6_2_conv[0][0]']    \n",
            "                                                                                                  \n",
            " conv5_block7_0_bn (BatchNormal  (None, 7, 7, 704)   2816        ['conv5_block6_concat[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv5_block7_0_relu (Activatio  (None, 7, 7, 704)   0           ['conv5_block7_0_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv5_block7_1_conv (Conv2D)   (None, 7, 7, 128)    90112       ['conv5_block7_0_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv5_block7_1_bn (BatchNormal  (None, 7, 7, 128)   512         ['conv5_block7_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv5_block7_1_relu (Activatio  (None, 7, 7, 128)   0           ['conv5_block7_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv5_block7_2_conv (Conv2D)   (None, 7, 7, 32)     36864       ['conv5_block7_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv5_block7_concat (Concatena  (None, 7, 7, 736)   0           ['conv5_block6_concat[0][0]',    \n",
            " te)                                                              'conv5_block7_2_conv[0][0]']    \n",
            "                                                                                                  \n",
            " conv5_block8_0_bn (BatchNormal  (None, 7, 7, 736)   2944        ['conv5_block7_concat[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv5_block8_0_relu (Activatio  (None, 7, 7, 736)   0           ['conv5_block8_0_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv5_block8_1_conv (Conv2D)   (None, 7, 7, 128)    94208       ['conv5_block8_0_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv5_block8_1_bn (BatchNormal  (None, 7, 7, 128)   512         ['conv5_block8_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv5_block8_1_relu (Activatio  (None, 7, 7, 128)   0           ['conv5_block8_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv5_block8_2_conv (Conv2D)   (None, 7, 7, 32)     36864       ['conv5_block8_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv5_block8_concat (Concatena  (None, 7, 7, 768)   0           ['conv5_block7_concat[0][0]',    \n",
            " te)                                                              'conv5_block8_2_conv[0][0]']    \n",
            "                                                                                                  \n",
            " conv5_block9_0_bn (BatchNormal  (None, 7, 7, 768)   3072        ['conv5_block8_concat[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv5_block9_0_relu (Activatio  (None, 7, 7, 768)   0           ['conv5_block9_0_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv5_block9_1_conv (Conv2D)   (None, 7, 7, 128)    98304       ['conv5_block9_0_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv5_block9_1_bn (BatchNormal  (None, 7, 7, 128)   512         ['conv5_block9_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv5_block9_1_relu (Activatio  (None, 7, 7, 128)   0           ['conv5_block9_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv5_block9_2_conv (Conv2D)   (None, 7, 7, 32)     36864       ['conv5_block9_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv5_block9_concat (Concatena  (None, 7, 7, 800)   0           ['conv5_block8_concat[0][0]',    \n",
            " te)                                                              'conv5_block9_2_conv[0][0]']    \n",
            "                                                                                                  \n",
            " conv5_block10_0_bn (BatchNorma  (None, 7, 7, 800)   3200        ['conv5_block9_concat[0][0]']    \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " conv5_block10_0_relu (Activati  (None, 7, 7, 800)   0           ['conv5_block10_0_bn[0][0]']     \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv5_block10_1_conv (Conv2D)  (None, 7, 7, 128)    102400      ['conv5_block10_0_relu[0][0]']   \n",
            "                                                                                                  \n",
            " conv5_block10_1_bn (BatchNorma  (None, 7, 7, 128)   512         ['conv5_block10_1_conv[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " conv5_block10_1_relu (Activati  (None, 7, 7, 128)   0           ['conv5_block10_1_bn[0][0]']     \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv5_block10_2_conv (Conv2D)  (None, 7, 7, 32)     36864       ['conv5_block10_1_relu[0][0]']   \n",
            "                                                                                                  \n",
            " conv5_block10_concat (Concaten  (None, 7, 7, 832)   0           ['conv5_block9_concat[0][0]',    \n",
            " ate)                                                             'conv5_block10_2_conv[0][0]']   \n",
            "                                                                                                  \n",
            " conv5_block11_0_bn (BatchNorma  (None, 7, 7, 832)   3328        ['conv5_block10_concat[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " conv5_block11_0_relu (Activati  (None, 7, 7, 832)   0           ['conv5_block11_0_bn[0][0]']     \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv5_block11_1_conv (Conv2D)  (None, 7, 7, 128)    106496      ['conv5_block11_0_relu[0][0]']   \n",
            "                                                                                                  \n",
            " conv5_block11_1_bn (BatchNorma  (None, 7, 7, 128)   512         ['conv5_block11_1_conv[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " conv5_block11_1_relu (Activati  (None, 7, 7, 128)   0           ['conv5_block11_1_bn[0][0]']     \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv5_block11_2_conv (Conv2D)  (None, 7, 7, 32)     36864       ['conv5_block11_1_relu[0][0]']   \n",
            "                                                                                                  \n",
            " conv5_block11_concat (Concaten  (None, 7, 7, 864)   0           ['conv5_block10_concat[0][0]',   \n",
            " ate)                                                             'conv5_block11_2_conv[0][0]']   \n",
            "                                                                                                  \n",
            " conv5_block12_0_bn (BatchNorma  (None, 7, 7, 864)   3456        ['conv5_block11_concat[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " conv5_block12_0_relu (Activati  (None, 7, 7, 864)   0           ['conv5_block12_0_bn[0][0]']     \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv5_block12_1_conv (Conv2D)  (None, 7, 7, 128)    110592      ['conv5_block12_0_relu[0][0]']   \n",
            "                                                                                                  \n",
            " conv5_block12_1_bn (BatchNorma  (None, 7, 7, 128)   512         ['conv5_block12_1_conv[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " conv5_block12_1_relu (Activati  (None, 7, 7, 128)   0           ['conv5_block12_1_bn[0][0]']     \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv5_block12_2_conv (Conv2D)  (None, 7, 7, 32)     36864       ['conv5_block12_1_relu[0][0]']   \n",
            "                                                                                                  \n",
            " conv5_block12_concat (Concaten  (None, 7, 7, 896)   0           ['conv5_block11_concat[0][0]',   \n",
            " ate)                                                             'conv5_block12_2_conv[0][0]']   \n",
            "                                                                                                  \n",
            " conv5_block13_0_bn (BatchNorma  (None, 7, 7, 896)   3584        ['conv5_block12_concat[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " conv5_block13_0_relu (Activati  (None, 7, 7, 896)   0           ['conv5_block13_0_bn[0][0]']     \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv5_block13_1_conv (Conv2D)  (None, 7, 7, 128)    114688      ['conv5_block13_0_relu[0][0]']   \n",
            "                                                                                                  \n",
            " conv5_block13_1_bn (BatchNorma  (None, 7, 7, 128)   512         ['conv5_block13_1_conv[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " conv5_block13_1_relu (Activati  (None, 7, 7, 128)   0           ['conv5_block13_1_bn[0][0]']     \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv5_block13_2_conv (Conv2D)  (None, 7, 7, 32)     36864       ['conv5_block13_1_relu[0][0]']   \n",
            "                                                                                                  \n",
            " conv5_block13_concat (Concaten  (None, 7, 7, 928)   0           ['conv5_block12_concat[0][0]',   \n",
            " ate)                                                             'conv5_block13_2_conv[0][0]']   \n",
            "                                                                                                  \n",
            " conv5_block14_0_bn (BatchNorma  (None, 7, 7, 928)   3712        ['conv5_block13_concat[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " conv5_block14_0_relu (Activati  (None, 7, 7, 928)   0           ['conv5_block14_0_bn[0][0]']     \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv5_block14_1_conv (Conv2D)  (None, 7, 7, 128)    118784      ['conv5_block14_0_relu[0][0]']   \n",
            "                                                                                                  \n",
            " conv5_block14_1_bn (BatchNorma  (None, 7, 7, 128)   512         ['conv5_block14_1_conv[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " conv5_block14_1_relu (Activati  (None, 7, 7, 128)   0           ['conv5_block14_1_bn[0][0]']     \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv5_block14_2_conv (Conv2D)  (None, 7, 7, 32)     36864       ['conv5_block14_1_relu[0][0]']   \n",
            "                                                                                                  \n",
            " conv5_block14_concat (Concaten  (None, 7, 7, 960)   0           ['conv5_block13_concat[0][0]',   \n",
            " ate)                                                             'conv5_block14_2_conv[0][0]']   \n",
            "                                                                                                  \n",
            " conv5_block15_0_bn (BatchNorma  (None, 7, 7, 960)   3840        ['conv5_block14_concat[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " conv5_block15_0_relu (Activati  (None, 7, 7, 960)   0           ['conv5_block15_0_bn[0][0]']     \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv5_block15_1_conv (Conv2D)  (None, 7, 7, 128)    122880      ['conv5_block15_0_relu[0][0]']   \n",
            "                                                                                                  \n",
            " conv5_block15_1_bn (BatchNorma  (None, 7, 7, 128)   512         ['conv5_block15_1_conv[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " conv5_block15_1_relu (Activati  (None, 7, 7, 128)   0           ['conv5_block15_1_bn[0][0]']     \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv5_block15_2_conv (Conv2D)  (None, 7, 7, 32)     36864       ['conv5_block15_1_relu[0][0]']   \n",
            "                                                                                                  \n",
            " conv5_block15_concat (Concaten  (None, 7, 7, 992)   0           ['conv5_block14_concat[0][0]',   \n",
            " ate)                                                             'conv5_block15_2_conv[0][0]']   \n",
            "                                                                                                  \n",
            " conv5_block16_0_bn (BatchNorma  (None, 7, 7, 992)   3968        ['conv5_block15_concat[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " conv5_block16_0_relu (Activati  (None, 7, 7, 992)   0           ['conv5_block16_0_bn[0][0]']     \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv5_block16_1_conv (Conv2D)  (None, 7, 7, 128)    126976      ['conv5_block16_0_relu[0][0]']   \n",
            "                                                                                                  \n",
            " conv5_block16_1_bn (BatchNorma  (None, 7, 7, 128)   512         ['conv5_block16_1_conv[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " conv5_block16_1_relu (Activati  (None, 7, 7, 128)   0           ['conv5_block16_1_bn[0][0]']     \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv5_block16_2_conv (Conv2D)  (None, 7, 7, 32)     36864       ['conv5_block16_1_relu[0][0]']   \n",
            "                                                                                                  \n",
            " conv5_block16_concat (Concaten  (None, 7, 7, 1024)  0           ['conv5_block15_concat[0][0]',   \n",
            " ate)                                                             'conv5_block16_2_conv[0][0]']   \n",
            "                                                                                                  \n",
            " bn (BatchNormalization)        (None, 7, 7, 1024)   4096        ['conv5_block16_concat[0][0]']   \n",
            "                                                                                                  \n",
            " relu (Activation)              (None, 7, 7, 1024)   0           ['bn[0][0]']                     \n",
            "                                                                                                  \n",
            " average_pooling2d_1 (AveragePo  (None, 1, 1, 1024)  0           ['relu[0][0]']                   \n",
            " oling2D)                                                                                         \n",
            "                                                                                                  \n",
            " flatten_1 (Flatten)            (None, 1024)         0           ['average_pooling2d_1[0][0]']    \n",
            "                                                                                                  \n",
            " dense_3 (Dense)                (None, 16)           16400       ['flatten_1[0][0]']              \n",
            "                                                                                                  \n",
            " dropout_1 (Dropout)            (None, 16)           0           ['dense_3[0][0]']                \n",
            "                                                                                                  \n",
            " dense_4 (Dense)                (None, 512)          8704        ['dropout_1[0][0]']              \n",
            "                                                                                                  \n",
            " dense_5 (Dense)                (None, 4)            2052        ['dense_4[0][0]']                \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 7,064,660\n",
            "Trainable params: 27,156\n",
            "Non-trainable params: 7,037,504\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Compile the model\n",
        "model.compile(optimizer = 'adam', \n",
        "              loss = 'categorical_crossentropy', \n",
        "              metrics = ['accuracy'])\n"
      ],
      "metadata": {
        "id": "OCKH8f28SGUt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Train the model\n",
        "densenet_model = model.fit(train_generator,\n",
        "                    epochs = 100,\n",
        "                    validation_data= valid_generator,\n",
        "                    callbacks = [EarlyStoppingCallBack, CheckPointCallback],\n",
        "                    verbose = 1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i2HcqF8mSKUj",
        "outputId": "ac2c54e3-81a7-4cd1-fab1-e28d175c0658"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "91/91 [==============================] - ETA: 0s - loss: 1.0648 - accuracy: 0.5221\n",
            "Epoch 1: val_loss did not improve from 0.40137\n",
            "91/91 [==============================] - 88s 899ms/step - loss: 1.0648 - accuracy: 0.5221 - val_loss: 0.7547 - val_accuracy: 0.7029\n",
            "Epoch 2/100\n",
            "91/91 [==============================] - ETA: 0s - loss: 0.8107 - accuracy: 0.6603\n",
            "Epoch 2: val_loss did not improve from 0.40137\n",
            "91/91 [==============================] - 77s 847ms/step - loss: 0.8107 - accuracy: 0.6603 - val_loss: 0.6088 - val_accuracy: 0.7729\n",
            "Epoch 3/100\n",
            "91/91 [==============================] - ETA: 0s - loss: 0.7135 - accuracy: 0.7124\n",
            "Epoch 3: val_loss did not improve from 0.40137\n",
            "91/91 [==============================] - 78s 853ms/step - loss: 0.7135 - accuracy: 0.7124 - val_loss: 0.5870 - val_accuracy: 0.7512\n",
            "Epoch 4/100\n",
            "91/91 [==============================] - ETA: 0s - loss: 0.6418 - accuracy: 0.7400\n",
            "Epoch 4: val_loss did not improve from 0.40137\n",
            "91/91 [==============================] - 77s 849ms/step - loss: 0.6418 - accuracy: 0.7400 - val_loss: 0.5689 - val_accuracy: 0.7585\n",
            "Epoch 5/100\n",
            "91/91 [==============================] - ETA: 0s - loss: 0.6062 - accuracy: 0.7572\n",
            "Epoch 5: val_loss did not improve from 0.40137\n",
            "91/91 [==============================] - 76s 840ms/step - loss: 0.6062 - accuracy: 0.7572 - val_loss: 0.5280 - val_accuracy: 0.7826\n",
            "Epoch 6/100\n",
            "91/91 [==============================] - ETA: 0s - loss: 0.6006 - accuracy: 0.7579\n",
            "Epoch 6: val_loss did not improve from 0.40137\n",
            "91/91 [==============================] - 77s 846ms/step - loss: 0.6006 - accuracy: 0.7579 - val_loss: 0.5416 - val_accuracy: 0.7560\n",
            "Epoch 7/100\n",
            "91/91 [==============================] - ETA: 0s - loss: 0.5574 - accuracy: 0.7769\n",
            "Epoch 7: val_loss did not improve from 0.40137\n",
            "91/91 [==============================] - 77s 848ms/step - loss: 0.5574 - accuracy: 0.7769 - val_loss: 0.5317 - val_accuracy: 0.7850\n",
            "Epoch 8/100\n",
            "91/91 [==============================] - ETA: 0s - loss: 0.5457 - accuracy: 0.7717\n",
            "Epoch 8: val_loss did not improve from 0.40137\n",
            "91/91 [==============================] - 77s 844ms/step - loss: 0.5457 - accuracy: 0.7717 - val_loss: 0.4569 - val_accuracy: 0.8068\n",
            "Epoch 9/100\n",
            "91/91 [==============================] - ETA: 0s - loss: 0.5376 - accuracy: 0.7879\n",
            "Epoch 9: val_loss did not improve from 0.40137\n",
            "91/91 [==============================] - 77s 843ms/step - loss: 0.5376 - accuracy: 0.7879 - val_loss: 0.4722 - val_accuracy: 0.7995\n",
            "Epoch 10/100\n",
            "91/91 [==============================] - ETA: 0s - loss: 0.5202 - accuracy: 0.7969\n",
            "Epoch 10: val_loss did not improve from 0.40137\n",
            "91/91 [==============================] - 77s 845ms/step - loss: 0.5202 - accuracy: 0.7969 - val_loss: 0.4391 - val_accuracy: 0.8285\n",
            "Epoch 11/100\n",
            "91/91 [==============================] - ETA: 0s - loss: 0.5195 - accuracy: 0.7828\n",
            "Epoch 11: val_loss did not improve from 0.40137\n",
            "91/91 [==============================] - 77s 847ms/step - loss: 0.5195 - accuracy: 0.7828 - val_loss: 0.4901 - val_accuracy: 0.8043\n",
            "Epoch 12/100\n",
            "91/91 [==============================] - ETA: 0s - loss: 0.5255 - accuracy: 0.7910\n",
            "Epoch 12: val_loss did not improve from 0.40137\n",
            "91/91 [==============================] - 77s 847ms/step - loss: 0.5255 - accuracy: 0.7910 - val_loss: 0.4587 - val_accuracy: 0.8152\n",
            "Epoch 13/100\n",
            "91/91 [==============================] - ETA: 0s - loss: 0.5081 - accuracy: 0.7962\n",
            "Epoch 13: val_loss did not improve from 0.40137\n",
            "91/91 [==============================] - 77s 846ms/step - loss: 0.5081 - accuracy: 0.7962 - val_loss: 0.4590 - val_accuracy: 0.8140\n",
            "Epoch 14/100\n",
            "91/91 [==============================] - ETA: 0s - loss: 0.4877 - accuracy: 0.8045\n",
            "Epoch 14: val_loss did not improve from 0.40137\n",
            "91/91 [==============================] - 77s 844ms/step - loss: 0.4877 - accuracy: 0.8045 - val_loss: 0.4644 - val_accuracy: 0.8152\n",
            "Epoch 15/100\n",
            "91/91 [==============================] - ETA: 0s - loss: 0.5031 - accuracy: 0.7928\n",
            "Epoch 15: val_loss did not improve from 0.40137\n",
            "91/91 [==============================] - 77s 843ms/step - loss: 0.5031 - accuracy: 0.7928 - val_loss: 0.4694 - val_accuracy: 0.8140\n",
            "Epoch 16/100\n",
            "91/91 [==============================] - ETA: 0s - loss: 0.4941 - accuracy: 0.8038\n",
            "Epoch 16: val_loss did not improve from 0.40137\n",
            "91/91 [==============================] - 77s 845ms/step - loss: 0.4941 - accuracy: 0.8038 - val_loss: 0.4452 - val_accuracy: 0.8225\n",
            "Epoch 17/100\n",
            "91/91 [==============================] - ETA: 0s - loss: 0.4772 - accuracy: 0.8169\n",
            "Epoch 17: val_loss did not improve from 0.40137\n",
            "91/91 [==============================] - 77s 842ms/step - loss: 0.4772 - accuracy: 0.8169 - val_loss: 0.4806 - val_accuracy: 0.8152\n",
            "Epoch 18/100\n",
            "91/91 [==============================] - ETA: 0s - loss: 0.4815 - accuracy: 0.8138\n",
            "Epoch 18: val_loss did not improve from 0.40137\n",
            "91/91 [==============================] - 77s 849ms/step - loss: 0.4815 - accuracy: 0.8138 - val_loss: 0.4384 - val_accuracy: 0.8321\n",
            "Epoch 19/100\n",
            "91/91 [==============================] - ETA: 0s - loss: 0.4661 - accuracy: 0.8179\n",
            "Epoch 19: val_loss did not improve from 0.40137\n",
            "91/91 [==============================] - 77s 848ms/step - loss: 0.4661 - accuracy: 0.8179 - val_loss: 0.4431 - val_accuracy: 0.8200\n",
            "Epoch 20/100\n",
            "91/91 [==============================] - ETA: 0s - loss: 0.4629 - accuracy: 0.8131\n",
            "Epoch 20: val_loss did not improve from 0.40137\n",
            "91/91 [==============================] - 77s 841ms/step - loss: 0.4629 - accuracy: 0.8131 - val_loss: 0.4505 - val_accuracy: 0.8225\n",
            "Epoch 21/100\n",
            "91/91 [==============================] - ETA: 0s - loss: 0.4646 - accuracy: 0.8210\n",
            "Epoch 21: val_loss did not improve from 0.40137\n",
            "91/91 [==============================] - 77s 852ms/step - loss: 0.4646 - accuracy: 0.8210 - val_loss: 0.4299 - val_accuracy: 0.8200\n",
            "Epoch 22/100\n",
            "91/91 [==============================] - ETA: 0s - loss: 0.4435 - accuracy: 0.8255\n",
            "Epoch 22: val_loss did not improve from 0.40137\n",
            "91/91 [==============================] - 77s 843ms/step - loss: 0.4435 - accuracy: 0.8255 - val_loss: 0.4541 - val_accuracy: 0.8068\n",
            "Epoch 23/100\n",
            "91/91 [==============================] - ETA: 0s - loss: 0.4416 - accuracy: 0.8200\n",
            "Epoch 23: val_loss did not improve from 0.40137\n",
            "91/91 [==============================] - 77s 851ms/step - loss: 0.4416 - accuracy: 0.8200 - val_loss: 0.4243 - val_accuracy: 0.8309\n",
            "Epoch 24/100\n",
            "91/91 [==============================] - ETA: 0s - loss: 0.4744 - accuracy: 0.8045\n",
            "Epoch 24: val_loss did not improve from 0.40137\n",
            "91/91 [==============================] - 77s 845ms/step - loss: 0.4744 - accuracy: 0.8045 - val_loss: 0.4353 - val_accuracy: 0.8297\n",
            "Epoch 25/100\n",
            "91/91 [==============================] - ETA: 0s - loss: 0.4587 - accuracy: 0.8117\n",
            "Epoch 25: val_loss did not improve from 0.40137\n",
            "91/91 [==============================] - 78s 861ms/step - loss: 0.4587 - accuracy: 0.8117 - val_loss: 0.4142 - val_accuracy: 0.8213\n",
            "Epoch 26/100\n",
            "91/91 [==============================] - ETA: 0s - loss: 0.4810 - accuracy: 0.8055\n",
            "Epoch 26: val_loss did not improve from 0.40137\n",
            "91/91 [==============================] - 77s 847ms/step - loss: 0.4810 - accuracy: 0.8055 - val_loss: 0.4328 - val_accuracy: 0.8345\n",
            "Epoch 27/100\n",
            "91/91 [==============================] - ETA: 0s - loss: 0.4434 - accuracy: 0.8169\n",
            "Epoch 27: val_loss did not improve from 0.40137\n",
            "91/91 [==============================] - 77s 842ms/step - loss: 0.4434 - accuracy: 0.8169 - val_loss: 0.4443 - val_accuracy: 0.8261\n",
            "Epoch 28/100\n",
            "91/91 [==============================] - ETA: 0s - loss: 0.4510 - accuracy: 0.8207\n",
            "Epoch 28: val_loss improved from 0.40137 to 0.40071, saving model to chest-xray.h5\n",
            "91/91 [==============================] - 78s 857ms/step - loss: 0.4510 - accuracy: 0.8207 - val_loss: 0.4007 - val_accuracy: 0.8345\n",
            "Epoch 29/100\n",
            "91/91 [==============================] - ETA: 0s - loss: 0.4413 - accuracy: 0.8186\n",
            "Epoch 29: val_loss did not improve from 0.40071\n",
            "91/91 [==============================] - 77s 842ms/step - loss: 0.4413 - accuracy: 0.8186 - val_loss: 0.4209 - val_accuracy: 0.8297\n",
            "Epoch 30/100\n",
            "91/91 [==============================] - ETA: 0s - loss: 0.4344 - accuracy: 0.8310\n",
            "Epoch 30: val_loss did not improve from 0.40071\n",
            "91/91 [==============================] - 77s 842ms/step - loss: 0.4344 - accuracy: 0.8310 - val_loss: 0.4172 - val_accuracy: 0.8321\n",
            "Epoch 31/100\n",
            "91/91 [==============================] - ETA: 0s - loss: 0.4339 - accuracy: 0.8217\n",
            "Epoch 31: val_loss improved from 0.40071 to 0.38881, saving model to chest-xray.h5\n",
            "91/91 [==============================] - 77s 853ms/step - loss: 0.4339 - accuracy: 0.8217 - val_loss: 0.3888 - val_accuracy: 0.8394\n",
            "Epoch 32/100\n",
            "91/91 [==============================] - ETA: 0s - loss: 0.4314 - accuracy: 0.8241\n",
            "Epoch 32: val_loss did not improve from 0.38881\n",
            "91/91 [==============================] - 77s 837ms/step - loss: 0.4314 - accuracy: 0.8241 - val_loss: 0.4448 - val_accuracy: 0.8261\n",
            "Epoch 33/100\n",
            "91/91 [==============================] - ETA: 0s - loss: 0.4249 - accuracy: 0.8348\n",
            "Epoch 33: val_loss did not improve from 0.38881\n",
            "91/91 [==============================] - 76s 838ms/step - loss: 0.4249 - accuracy: 0.8348 - val_loss: 0.4277 - val_accuracy: 0.8152\n",
            "Epoch 34/100\n",
            "91/91 [==============================] - ETA: 0s - loss: 0.4621 - accuracy: 0.8107\n",
            "Epoch 34: val_loss did not improve from 0.38881\n",
            "91/91 [==============================] - 76s 841ms/step - loss: 0.4621 - accuracy: 0.8107 - val_loss: 0.4393 - val_accuracy: 0.8188\n",
            "Epoch 35/100\n",
            "91/91 [==============================] - ETA: 0s - loss: 0.4270 - accuracy: 0.8248\n",
            "Epoch 35: val_loss did not improve from 0.38881\n",
            "91/91 [==============================] - 77s 847ms/step - loss: 0.4270 - accuracy: 0.8248 - val_loss: 0.4353 - val_accuracy: 0.8092\n",
            "Epoch 36/100\n",
            "91/91 [==============================] - ETA: 0s - loss: 0.4338 - accuracy: 0.8252\n",
            "Epoch 36: val_loss did not improve from 0.38881\n",
            "91/91 [==============================] - 76s 840ms/step - loss: 0.4338 - accuracy: 0.8252 - val_loss: 0.4091 - val_accuracy: 0.8454\n",
            "Epoch 37/100\n",
            "91/91 [==============================] - ETA: 0s - loss: 0.4272 - accuracy: 0.8259\n",
            "Epoch 37: val_loss did not improve from 0.38881\n",
            "91/91 [==============================] - 77s 844ms/step - loss: 0.4272 - accuracy: 0.8259 - val_loss: 0.4312 - val_accuracy: 0.8261\n",
            "Epoch 38/100\n",
            "91/91 [==============================] - ETA: 0s - loss: 0.4213 - accuracy: 0.8310\n",
            "Epoch 38: val_loss did not improve from 0.38881\n",
            "91/91 [==============================] - 77s 844ms/step - loss: 0.4213 - accuracy: 0.8310 - val_loss: 0.4207 - val_accuracy: 0.8321\n",
            "Epoch 39/100\n",
            "91/91 [==============================] - ETA: 0s - loss: 0.4218 - accuracy: 0.8307\n",
            "Epoch 39: val_loss did not improve from 0.38881\n",
            "91/91 [==============================] - 77s 847ms/step - loss: 0.4218 - accuracy: 0.8307 - val_loss: 0.4263 - val_accuracy: 0.8321\n",
            "Epoch 40/100\n",
            "91/91 [==============================] - ETA: 0s - loss: 0.4125 - accuracy: 0.8317\n",
            "Epoch 40: val_loss did not improve from 0.38881\n",
            "91/91 [==============================] - 77s 845ms/step - loss: 0.4125 - accuracy: 0.8317 - val_loss: 0.4497 - val_accuracy: 0.8104\n",
            "Epoch 41/100\n",
            "91/91 [==============================] - ETA: 0s - loss: 0.4280 - accuracy: 0.8190\n",
            "Epoch 41: val_loss improved from 0.38881 to 0.38172, saving model to chest-xray.h5\n",
            "91/91 [==============================] - 78s 857ms/step - loss: 0.4280 - accuracy: 0.8190 - val_loss: 0.3817 - val_accuracy: 0.8382\n",
            "Epoch 42/100\n",
            "91/91 [==============================] - ETA: 0s - loss: 0.4360 - accuracy: 0.8234\n",
            "Epoch 42: val_loss did not improve from 0.38172\n",
            "91/91 [==============================] - 77s 851ms/step - loss: 0.4360 - accuracy: 0.8234 - val_loss: 0.4248 - val_accuracy: 0.8261\n",
            "Epoch 43/100\n",
            "91/91 [==============================] - ETA: 0s - loss: 0.4141 - accuracy: 0.8352\n",
            "Epoch 43: val_loss improved from 0.38172 to 0.38130, saving model to chest-xray.h5\n",
            "91/91 [==============================] - 78s 857ms/step - loss: 0.4141 - accuracy: 0.8352 - val_loss: 0.3813 - val_accuracy: 0.8382\n",
            "Epoch 44/100\n",
            "91/91 [==============================] - ETA: 0s - loss: 0.4151 - accuracy: 0.8266\n",
            "Epoch 44: val_loss did not improve from 0.38130\n",
            "91/91 [==============================] - 77s 852ms/step - loss: 0.4151 - accuracy: 0.8266 - val_loss: 0.4354 - val_accuracy: 0.8176\n",
            "Epoch 45/100\n",
            "91/91 [==============================] - ETA: 0s - loss: 0.4207 - accuracy: 0.8321\n",
            "Epoch 45: val_loss did not improve from 0.38130\n",
            "91/91 [==============================] - 77s 852ms/step - loss: 0.4207 - accuracy: 0.8321 - val_loss: 0.4052 - val_accuracy: 0.8442\n",
            "Epoch 46/100\n",
            "91/91 [==============================] - ETA: 0s - loss: 0.3991 - accuracy: 0.8372\n",
            "Epoch 46: val_loss did not improve from 0.38130\n",
            "91/91 [==============================] - 77s 852ms/step - loss: 0.3991 - accuracy: 0.8372 - val_loss: 0.4304 - val_accuracy: 0.8309\n",
            "Epoch 47/100\n",
            "91/91 [==============================] - ETA: 0s - loss: 0.4062 - accuracy: 0.8366\n",
            "Epoch 47: val_loss did not improve from 0.38130\n",
            "91/91 [==============================] - 77s 848ms/step - loss: 0.4062 - accuracy: 0.8366 - val_loss: 0.4223 - val_accuracy: 0.8333\n",
            "Epoch 48/100\n",
            "91/91 [==============================] - ETA: 0s - loss: 0.4179 - accuracy: 0.8238\n",
            "Epoch 48: val_loss did not improve from 0.38130\n",
            "91/91 [==============================] - 77s 845ms/step - loss: 0.4179 - accuracy: 0.8238 - val_loss: 0.4125 - val_accuracy: 0.8357\n",
            "Epoch 49/100\n",
            "91/91 [==============================] - ETA: 0s - loss: 0.4017 - accuracy: 0.8379\n",
            "Epoch 49: val_loss did not improve from 0.38130\n",
            "91/91 [==============================] - 77s 844ms/step - loss: 0.4017 - accuracy: 0.8379 - val_loss: 0.4366 - val_accuracy: 0.8031\n",
            "Epoch 50/100\n",
            "91/91 [==============================] - ETA: 0s - loss: 0.3786 - accuracy: 0.8434\n",
            "Epoch 50: val_loss improved from 0.38130 to 0.37660, saving model to chest-xray.h5\n",
            "91/91 [==============================] - 77s 854ms/step - loss: 0.3786 - accuracy: 0.8434 - val_loss: 0.3766 - val_accuracy: 0.8502\n",
            "Epoch 51/100\n",
            "91/91 [==============================] - ETA: 0s - loss: 0.3779 - accuracy: 0.8490\n",
            "Epoch 51: val_loss did not improve from 0.37660\n",
            "91/91 [==============================] - 77s 845ms/step - loss: 0.3779 - accuracy: 0.8490 - val_loss: 0.4259 - val_accuracy: 0.8406\n",
            "Epoch 52/100\n",
            "91/91 [==============================] - ETA: 0s - loss: 0.4121 - accuracy: 0.8348\n",
            "Epoch 52: val_loss did not improve from 0.37660\n",
            "91/91 [==============================] - 77s 847ms/step - loss: 0.4121 - accuracy: 0.8348 - val_loss: 0.3775 - val_accuracy: 0.8527\n",
            "Epoch 53/100\n",
            "91/91 [==============================] - ETA: 0s - loss: 0.4106 - accuracy: 0.8293\n",
            "Epoch 53: val_loss did not improve from 0.37660\n",
            "91/91 [==============================] - 77s 853ms/step - loss: 0.4106 - accuracy: 0.8293 - val_loss: 0.4085 - val_accuracy: 0.8273\n",
            "Epoch 54/100\n",
            "91/91 [==============================] - ETA: 0s - loss: 0.4123 - accuracy: 0.8359\n",
            "Epoch 54: val_loss did not improve from 0.37660\n",
            "91/91 [==============================] - 76s 843ms/step - loss: 0.4123 - accuracy: 0.8359 - val_loss: 0.4163 - val_accuracy: 0.8237\n",
            "Epoch 55/100\n",
            "91/91 [==============================] - ETA: 0s - loss: 0.4063 - accuracy: 0.8324\n",
            "Epoch 55: val_loss did not improve from 0.37660\n",
            "91/91 [==============================] - 77s 846ms/step - loss: 0.4063 - accuracy: 0.8324 - val_loss: 0.3856 - val_accuracy: 0.8442\n",
            "Epoch 56/100\n",
            "91/91 [==============================] - ETA: 0s - loss: 0.4226 - accuracy: 0.8310\n",
            "Epoch 56: val_loss did not improve from 0.37660\n",
            "91/91 [==============================] - 76s 840ms/step - loss: 0.4226 - accuracy: 0.8310 - val_loss: 0.4458 - val_accuracy: 0.8104\n",
            "Epoch 57/100\n",
            "91/91 [==============================] - ETA: 0s - loss: 0.4070 - accuracy: 0.8328\n",
            "Epoch 57: val_loss did not improve from 0.37660\n",
            "91/91 [==============================] - 77s 844ms/step - loss: 0.4070 - accuracy: 0.8328 - val_loss: 0.3922 - val_accuracy: 0.8430\n",
            "Epoch 58/100\n",
            "91/91 [==============================] - ETA: 0s - loss: 0.3752 - accuracy: 0.8531\n",
            "Epoch 58: val_loss did not improve from 0.37660\n",
            "91/91 [==============================] - 78s 851ms/step - loss: 0.3752 - accuracy: 0.8531 - val_loss: 0.4060 - val_accuracy: 0.8370\n",
            "Epoch 59/100\n",
            "91/91 [==============================] - ETA: 0s - loss: 0.3961 - accuracy: 0.8390\n",
            "Epoch 59: val_loss did not improve from 0.37660\n",
            "91/91 [==============================] - 77s 848ms/step - loss: 0.3961 - accuracy: 0.8390 - val_loss: 0.4352 - val_accuracy: 0.8188\n",
            "Epoch 60/100\n",
            "91/91 [==============================] - ETA: 0s - loss: 0.3952 - accuracy: 0.8414\n",
            "Epoch 60: val_loss did not improve from 0.37660\n",
            "91/91 [==============================] - 77s 847ms/step - loss: 0.3952 - accuracy: 0.8414 - val_loss: 0.4162 - val_accuracy: 0.8418\n",
            "Epoch 61/100\n",
            "91/91 [==============================] - ETA: 0s - loss: 0.3935 - accuracy: 0.8445\n",
            "Epoch 61: val_loss did not improve from 0.37660\n",
            "91/91 [==============================] - 77s 843ms/step - loss: 0.3935 - accuracy: 0.8445 - val_loss: 0.4164 - val_accuracy: 0.8297\n",
            "Epoch 62/100\n",
            "91/91 [==============================] - ETA: 0s - loss: 0.3902 - accuracy: 0.8448\n",
            "Epoch 62: val_loss did not improve from 0.37660\n",
            "91/91 [==============================] - 77s 850ms/step - loss: 0.3902 - accuracy: 0.8448 - val_loss: 0.4066 - val_accuracy: 0.8321\n",
            "Epoch 63/100\n",
            "91/91 [==============================] - ETA: 0s - loss: 0.3803 - accuracy: 0.8400\n",
            "Epoch 63: val_loss did not improve from 0.37660\n",
            "91/91 [==============================] - 77s 852ms/step - loss: 0.3803 - accuracy: 0.8400 - val_loss: 0.4009 - val_accuracy: 0.8527\n",
            "Epoch 64/100\n",
            "91/91 [==============================] - ETA: 0s - loss: 0.3980 - accuracy: 0.8328\n",
            "Epoch 64: val_loss did not improve from 0.37660\n",
            "91/91 [==============================] - 76s 841ms/step - loss: 0.3980 - accuracy: 0.8328 - val_loss: 0.3875 - val_accuracy: 0.8442\n",
            "Epoch 65/100\n",
            "91/91 [==============================] - ETA: 0s - loss: 0.3868 - accuracy: 0.8403\n",
            "Epoch 65: val_loss did not improve from 0.37660\n",
            "91/91 [==============================] - 76s 843ms/step - loss: 0.3868 - accuracy: 0.8403 - val_loss: 0.4107 - val_accuracy: 0.8370\n",
            "Epoch 66/100\n",
            "91/91 [==============================] - ETA: 0s - loss: 0.3863 - accuracy: 0.8445\n",
            "Epoch 66: val_loss did not improve from 0.37660\n",
            "91/91 [==============================] - 77s 844ms/step - loss: 0.3863 - accuracy: 0.8445 - val_loss: 0.4009 - val_accuracy: 0.8285\n",
            "Epoch 67/100\n",
            "91/91 [==============================] - ETA: 0s - loss: 0.3863 - accuracy: 0.8414\n",
            "Epoch 67: val_loss improved from 0.37660 to 0.37430, saving model to chest-xray.h5\n",
            "91/91 [==============================] - 77s 851ms/step - loss: 0.3863 - accuracy: 0.8414 - val_loss: 0.3743 - val_accuracy: 0.8454\n",
            "Epoch 68/100\n",
            "91/91 [==============================] - ETA: 0s - loss: 0.3851 - accuracy: 0.8448\n",
            "Epoch 68: val_loss did not improve from 0.37430\n",
            "91/91 [==============================] - 77s 843ms/step - loss: 0.3851 - accuracy: 0.8448 - val_loss: 0.4078 - val_accuracy: 0.8394\n",
            "Epoch 69/100\n",
            "91/91 [==============================] - ETA: 0s - loss: 0.3920 - accuracy: 0.8393\n",
            "Epoch 69: val_loss did not improve from 0.37430\n",
            "91/91 [==============================] - 77s 844ms/step - loss: 0.3920 - accuracy: 0.8393 - val_loss: 0.3883 - val_accuracy: 0.8321\n",
            "Epoch 70/100\n",
            "91/91 [==============================] - ETA: 0s - loss: 0.3865 - accuracy: 0.8459\n",
            "Epoch 70: val_loss did not improve from 0.37430\n",
            "91/91 [==============================] - 77s 842ms/step - loss: 0.3865 - accuracy: 0.8459 - val_loss: 0.4075 - val_accuracy: 0.8527\n",
            "Epoch 71/100\n",
            "91/91 [==============================] - ETA: 0s - loss: 0.3801 - accuracy: 0.8390\n",
            "Epoch 71: val_loss did not improve from 0.37430\n",
            "91/91 [==============================] - 77s 846ms/step - loss: 0.3801 - accuracy: 0.8390 - val_loss: 0.4001 - val_accuracy: 0.8478\n",
            "Epoch 72/100\n",
            "91/91 [==============================] - ETA: 0s - loss: 0.3984 - accuracy: 0.8376\n",
            "Epoch 72: val_loss did not improve from 0.37430\n",
            "91/91 [==============================] - 77s 846ms/step - loss: 0.3984 - accuracy: 0.8376 - val_loss: 0.4250 - val_accuracy: 0.8213\n",
            "Epoch 72: early stopping\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Save the Model\n",
        "model.save('/content/drive/MyDrive/models/densenet_model_100.h5')"
      ],
      "metadata": {
        "id": "fYyM-oFMSOxC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Call Evaluate function\n",
        "eval_model(model, test_generator)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qXAmL2zMSSYz",
        "outputId": "ed0d376a-a8ae-4c8b-b6e6-d1096b1aa57c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "       covid       0.74      0.81      0.78       102\n",
            "      normal       0.68      0.70      0.69       102\n",
            "   pneumonia       0.96      0.80      0.88       102\n",
            "tuberculosis       0.94      0.98      0.96       102\n",
            "\n",
            "    accuracy                           0.82       408\n",
            "   macro avg       0.83      0.82      0.83       408\n",
            "weighted avg       0.83      0.82      0.83       408\n",
            "\n",
            "[[ 83  16   0   3]\n",
            " [ 25  71   3   3]\n",
            " [  2  18  82   0]\n",
            " [  2   0   0 100]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Evaludation"
      ],
      "metadata": {
        "id": "cQ1u9f4-rSIR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Evaluate all the saved model"
      ],
      "metadata": {
        "id": "SdC0o2a95Nn7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Load all the Saved models\n",
        "densenet_model = keras.models.load_model(\"/content/drive/MyDrive/models/densenet_model_100.h5\")\n",
        "vgg16_model = keras.models.load_model(\"/content/drive/MyDrive/models/vgg16_model_100.h5\")\n",
        "cnn_model = keras.models.load_model(\"/content/drive/MyDrive/models/cnn_model82_100 epochs-last.h5\")"
      ],
      "metadata": {
        "id": "YTiBLyNsrRdt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Evaluate Loaded models one by one\n",
        "eval_model(cnn_model, test_generator)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BnSeCPjdAxZx",
        "outputId": "92f9ce41-087f-4e81-cb44-68b244b9f704"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "       covid       0.84      0.93      0.88       102\n",
            "      normal       0.88      0.83      0.85       102\n",
            "   pneumonia       0.95      0.94      0.95       102\n",
            "tuberculosis       0.99      0.94      0.96       102\n",
            "\n",
            "    accuracy                           0.91       408\n",
            "   macro avg       0.91      0.91      0.91       408\n",
            "weighted avg       0.91      0.91      0.91       408\n",
            "\n",
            "[[95  5  1  1]\n",
            " [15 85  2  0]\n",
            " [ 0  6 96  0]\n",
            " [ 3  1  2 96]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Function for confusion Matrix\n",
        "\n",
        "def plot_model(model):\n",
        "    test_steps_per_epoch = numpy.math.ceil(test_generator.samples / test_generator.batch_size)\n",
        "    predictions = model.predict(test_generator, steps=test_steps_per_epoch)\n",
        "    # Get most likely class\n",
        "    predicted_classes = numpy.argmax(predictions, axis=1)\n",
        "    true_classes = test_generator.classes\n",
        "    class_labels = list(test_generator.class_indices.keys()) \n",
        "    y_pred = predicted_classes\n",
        "    y_test = true_classes\n",
        "    labels = class_labels\n",
        "\n",
        "    cm = confusion_matrix(y_test, y_pred)\n",
        "\n",
        "    disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=labels)\n",
        "\n",
        "    disp.plot(cmap=plt.cm.Blues)\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "50eMGS8RtPSF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Creating the confusion Matrix\n",
        "plot_model(densenet_model)\n",
        "plot_model(vgg16_model)\n",
        "plot_model(cnn_model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 811
        },
        "id": "_wmT2eEGIPi1",
        "outputId": "39c729ba-b89b-4dde-fc22-8624c4e04869"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAWgAAAEGCAYAAABIGw//AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3dd5xU1f3/8dd7d6UqsAoiooCCDVARCQFURCxRJPbeEDUiGjHFWBJ/dr9fa2LB8rWGYqzBiMagxi5KpKhUsSCgSBSQKnV3P78/7hkZ12V2dnd27t318+QxD24953NnZz9z9tx7z5WZ4ZxzLnkK4g7AOedcxTxBO+dcQnmCds65hPIE7ZxzCeUJ2jnnEqoo7gB+ClTU2NSwWdxh5Nweu2wXdwi1pkCKOwRXBfPnzWXx4sU1+qEVNmtvVrImq21tzaIXzezQmtSXDU/QeaCGzWi460lxh5Fzr7x5W9wh1JrGmxXGHYKrgn17/6zGZVjJGhruckJW26794O6WNa4wC56gnXMOAIGS1evrCdo55wAEFCTrLydP0M45l5Kwcw+eoJ1zDvAuDuecSzJvQTvnXAIJb0E751wyyVvQzjmXWH4Vh3POJZGfJHTOuWQS3sXhnHOJ5S1o55xLIu/icM65ZBJQ6CcJnXMumbwP2jnnksi7OJxzLrm8Be2ccwnlLWjnnEsg+a3ezjmXXH6rt3POJZGfJHTOueTyLg6XK0NO3J9BR/YGwchn3+W+x9/g0nMO5Ywje7Nk2SoArrv3n7z8zsyYI62ZXsddQ9MmjSgsEEWFhbzw0O/jDiknLrzuUV4aP52WxVsw/rE/xh1OztTZ4/LxoOsmSdcCb5rZv8st7wdcbGYD8x3Tbju2YdCRvTlw8G2sLynl6dvP48W3ZwBw7+OvM/zR1/IdUq166s4L2LLF5nGHkVMnD/w55xzfl/OvGRV3KDlVd4/LuzjqJDO7Mu4Yytu5Q2smzZjHmnUbABj//qf8st8eMUflqqLPXp2Y/9WSuMPIuTp9XAk7SZisr4taIukMSVMlfShplKQOkl4Ny16R1E5Sc0nzpOgrVFJTSV9I2kzSXyUdF5YfKukjSVOAY+I6pllzFtK7244UN2tC44abcXCfzrRtXQzAr47bj7dHX8pdV5xM8y0axxVizkjilN/dx2Fn3croZ9+JOxxXn6UutavslSf1vgUtqQtwBdDHzBZL2hIYAYwwsxGSzgLuNLOjJH0A7A+8BgwEXjSzDQo/EEmNgAeA/sCnwBP5P6LIx3O/5o6RrzDmrvNZvWYd0z9eQGlZGQ+PGc8tD7+IGfxpyACuv+goLrz+sbjCzIkx9wyjTasWLF66kpN/cy+d2remV7eOcYfl6hslr4sjWdHUjv7AU2a2GMDMvgV6A38L60cB+4bpJ4ATw/RJ/DgB7wp8bmafmJkBozdVqaRzJU2SNMlK1uTmSMoZ/dwEDhh0K4efdxfLVq7hs/mLWPTtSsrKDDNjxLPvsnfn9rVSdz61adUCgJbFW3Bo3935YOa8mCNy9VbCWtA/hQRdFWOBQ0Mre2/g1eoWZGb3m1kPM+uhotrpZmhZHJ002651MQP77cFTL06m9VbNvl8/cP89mDVnYa3UnS+r16xj1eq130+/OXE2u+zYJuaoXH0lKatXvtT7Lg6iJPuMpD+b2ZKQfN8haiGPAk4F3gIws1WSJgJ3AM+bWWm5sj4COkjqaGafASfn7SgqMPLGsyhu3pSSklL+cMvTrFi1hpsvPpbdd2qLGcxfuITf3vhknCHW2KJvV3LOHx8GoLS0jKMO7s4BvXaLOarc+NUVjzB+yqcsWbaKrgP/H5edO4DTjugdd1g1VlePK3rilV8HnVdmNkPSDcAbkkqB94ELgUck/QFYBAxO2+UJ4CmgXwVlrZV0LvBPSauJEvsWtXwImzRgyJ0/Wnbe1ZvsdamT2rdtycsjLok7jFrxwPWDK9+oDqqzxyWhAk/QeWdmI4hODKbrv4ltnyb6Mk1fdmba9DiivmjnXD2TtBa090E751yQyz5oSb+VNEPSdEmPSWokaQdJ/5H0qaQnJDXIVIYnaOecC3KVoCW1BYYBPcysK1BIdN7rJuAvZtYJWAqcnakcT9DOOQfhLGGWr+wUAY0lFQFNgIVEXatPh/UjgKMyFeAJ2jnnAJFd6zmbFrSZLQBuBeYTJeblwGRgmZmVhM2+BNpmKscTtHPOBQUFBVm9gJapG9HC69z0ciQVA0cCOwDbAk2BQ6saz0/iKg7nnMtGFa7iWGxmPTKsP4joruNFodwxwD5AC0lFoRW9HbAgUyXegnbOOch1H/R8oJekJoqy/oHATKJxfo4L2wwCns1UiCdo55wLctgH/R+ik4FTgGlEufZ+4FLgd5I+BbYCHspUjndxOOccG08S5oqZXQVcVW7xHKBntmV4gnbOucBv9XbOuSRS8m719gTtnHOBJ2jnnEsoT9DOOZdAuT5JmAueoJ1zLiVZ+dkTtHPOASBSt3Enhido55wLvIvDOeeSKln52RO0c86leAvaOecSqCqPs8oXT9DOORd4gv4J6typLX//5//GHUbObXfKg3GHUGsWPXlu5RvVQUWFybpKIVdylVZ9LA7nnEsob0E751wS+WBJzjmXTAISlp89QTvnXMSv4nDOucQq8JOEzjmXQPIuDuecSyThLWjnnEssb0E751xC+UlC55xLIu+Dds65ZBLyAfudcy6pvAXtnHMJ5X3QzjmXRN4H7ZxzyRSNxZGsDO0J2jnngoTlZ0/QzjmX4ncSOudcEvl40M45l0w+HrRzziWWjwftnHOJlbD87AnaOecAkJ8kdM65RPLroF1OXfXnJ3nzvVls2WJz/n7f7wG4d/RLjBn3HsXNmwJw4aBD2a/nbnGGWS1DB+7B6QftCgYz5y/hguGv8+chfdmncxtWrF4PwPnDX2P63CUxR1o9C75eygXXjGLRtyuRxOlH9WHIif3iDitn/v3OTC6/7WlKy8o4/cg+/PbMQ+IOKSueoOsZSXOBHma2ON91H3FwD046og9X3PrED5afdtR+DDpu/3yHkzNttmzKkAFd6fWbJ1i7vpSHf38wx+zbCYArR05g7IQ5MUdYc4WFBVwz7Gj23HV7Vn23lgPPvIV+PXdhlx3axB1ajZWWlvGHm5/kmeG/ZtvWLeg/6BYO67s7u+6Y/GPLZX6W1AJ4EOgKGHAWMBt4AugAzAVOMLOlmyojWWPr5ZmkOv0FtffuO9JsiyZxh1ErigoLaNSgiMIC0aRBEf/99ru4Q8qpbVo2Z89dtwdg86aN2LlDaxZ+szzmqHJj8oy57Lh9Szps15IGmxVxzMHdeeGNqXGHlRVJWb2ydAcwzsx2BfYEZgGXAa+Y2U7AK2F+k+p8gpbUQdIsSQ9ImiHpJUmNJXWTNEHSVEnPSCoO278u6XZJk4CLwvxfJE0K5fxM0hhJn0i6Pq2ef0iaHOo4N7YDzsLjz73D8UP/zFV/fpIVK1fHHU6VLfz2O+4a+yHT7juNjx48gxWr1/Pah18CcMUpPXn7z8dzw5l9aFBU5z++AMz/agnTPl7A3l3bxx1KTixctJy2rYu/n9+2dTELF9WBL58wWFI2r0qLkpoDfYGHAMxsvZktA44ERoTNRgBHZSqnfnzCYSfgbjPrAiwDjgVGApea2R7ANOCqtO0bmFkPM7stzK83sx7AfcCzwAVEf5acKWmrsM1ZZrY30AMYlra8QpLODUl/0tIl+ev9OOHw3jz/8KU8cfdvaLllM2574Pm81Z0rzZs2YMDPOtDt/EfZ7VejaNKoiBP67sS1o/9Dz2GP0/+Sv1O8eUMuOnqvuEOtsVWr1zH48oe4/jfHsEXTxnGH85MWDdif3Qtomfr9Dq/yjbYdgEXAI5Lel/SgpKZAazNbGLb5L9A6U0z1JUF/bmYfhOnJQEeghZm9EZaNIPo2S/lhpy2MDf9PA2aY2UIzWwfMAbYP64ZJ+hCYEJbtlCkgM7s/fAn0KN6qZbUOqjq2Kt6CwsICCgoKOOawnkz/+Iu81Z0r/fbYjnnfrGDJirWUlJbx3ITP6bnLNny9LPprYH1JGY++Npu9O20dc6Q1s6GklMGXP8Rxv+jBwAP2jDucnGnTqjkLvt7YrfrV10tp06p5jBFlr0DK6gUsTv1+h9f95YoqAroD95rZXsB3lOvOMDMj6pvedDy5O7RYrUubLgVaVLJ9+Q7N1P5l5coqA4ok9QMOAnqb2Z7A+0CjakdbixZ9u+L76VffmU6n9tvEGE31fLl4FT12bk3jBtEpgv13b8vsL5fSusXG/vbDe3Zg1hffxhVijZkZv7nhb+zcoTVDT+kfdzg51b1zez6bv4h5CxazfkMJY16ewmF994g7rKzkqosD+BL40sz+E+afJkrYX0tqE9WlNsA3mQqp0yfJMlgOLJW0n5m9BZwOvFHJPpk0B5aa2WpJuwK9chFkTV1246NMmjqHZSu+45DTbmDo6QczaeocZs/5ChH1/V0x7Ni4w6yyyZ98w9h35/D6rcdSWmpM/XwxI16eyVNXHE7LZo2QxLTPF/O7+9+MO9Rq+8+Hc3jyXxPp3HFb+p1+EwB/GjqQg/t0iTmymisqKuTmS07g2GF3U1pqnHpEL3brWDeu4MjVZXZm9l9JX0jaxcxmAwcCM8NrEHBj+P/ZTOXU1wQN0cHfJ6kJUVfF4BqUNQ44T9IsostkJuQgvhq78bJTf7Ts6F/0jCGS3LvxiUnc+MSkHyw78urnYoom93p168iiCXfGHUatOWSfLhyyT937ssnxjYQXAo9KasDGHFQAPCnpbGAecEKmAjaZoCXdRYb+ETMbVp2Ic83M5hKd0EvN35q2+kctXTPrt6l5M3sdeH0T2x62ifo7VCFc51yC5fJW73BerEcFqw7MtoxMLehJGdY551y9IqIrOZJkkwnazEakz0tqYmZ176Ja55zLUsLGSqr8Kg5JvSXNBD4K83tKuqfWI3POuXzK8i7CfI7Xkc1ldrcDvwCWAJjZh/zwmmLnnKsXcniZXU5kdRWHmX1R7lujtHbCcc65eAhSN6EkRjYJ+gtJfQCTtBlwEdGgH845V68kbcD+bLo4ziMam6It8BXQLcw751y9kW33RqK6OMI4xz++I8I55+qZpHVxZHMVx46SnpO0SNI3kp6VtGM+gnPOuXxSlq98yaaL42/Ak0AbYFvgKeCx2gzKOefiUBcvs2tiZqPMrCS8RpPQkdycc666oqs4snvlS6axOLYMk/+SdBnwONHYHCcCL+QhNuecyx8pcVdxZDpJOJkoIaciHpK2zoDLayso55yLQ515qreZ7ZDPQJxzLk6pLo4kyepOQkldgc6k9T2b2cjaCso55+JQZ1rQKZKuAvoRJegXiMZFfpvooazOOVdvJCs9Z3cVx3FEA0z/18wGA3sSPQLKOefqDQkKC5TVK1+y6eJYY2ZlkkokNSN6yOH2le3knHN1TZ3r4gAmSWoBPEB0Zccq4N1ajco552KQsPyc1Vgc54fJ+ySNA5qZ2dTaDcs55/JLKHFjcWS6UaV7pnVmNqV2QnLOuRjkeaS6bGRqQd+WYZ0B/XMcS73VsKiA9i2bxB1Gzs0ffXbcIdSaVr0S8dD6nFs6cXjcISRanemDNrMD8hmIc87FSUBhXUnQzjn3U1Mn7yR0zrmfAk/QzjmXQNHjrJKVobN5oooknSbpyjDfTlLP2g/NOefyK2njQWdzq/c9QG/g5DC/Eri71iJyzrmY1LmHxgI/N7Pukt4HMLOlkhrUclzOOZdXAooS1sWRTYLeIKmQ6NpnJLUCymo1Kueci0HC8nNWCfpO4Blga0k3EI1ud0WtRuWcc3km1aFbvVPM7FFJk4mGHBVwlJnNqvXInHMuzxKWn7MasL8dsBp4Ln2Zmc2vzcCccy7f6uJ10P9k48NjGwE7ALOBLrUYl3PO5ZUgr4PxZyObLo7d0+fDKHfnb2Jz55yrm/J8jXM2qnwnoZlNkfTz2gjGOefipIQ9lTCbPujfpc0WAN2Br2otIueci4HIbQs6XJ48CVhgZgMl7QA8DmxF9HSq081sfaYysrmTcIu0V0OiPukjaxK4c84lUY5v9b4ISL/i7SbgL2bWCVgKVDqgesYWdPgG2MLMLs46JOecq6NyNViSpO2Aw4EbgN8pKrg/cErYZARwNXBvpnIyPfKqyMxKJO2Tk4idcy7BJCjMpk8h0lLSpLT5+83s/rT524FLiHoeIOrWWGZmJWH+S6BtZZVkakG/R9Tf/IGkscBTwHeplWY2ptJDcM65OqQKdxIuNrMeFa2QNBD4xswmS+pXk3iyuYqjEbCEqHmeuh7aAE/Qzrl6I4cnCfcBjpA0gCh/NgPuAFqkeiaA7YAFlRWUKUFvHa7gmM7GxJxi1Y3cOeeSKhdd0GZ2OXB5VJ76AReb2amSniIay+hxYBDwbGVlZUrQhcDmUOGFgZ6gnXP1jCio3eugLwUel3Q98D7wUGU7ZErQC83s2lxF5mrfv9+ZyeW3PU1pWRmnH9mH3555SNwh5cTylWu45ObH+fjz/yLglstOZu+uHeIOq1qGnNSPQUf1AYmR/xjPfY+9DsCvTtifc47fj9Iy4+W3p3PVXZU2rhKtLn4WRe4HSzKz14HXw/QcoEpPo8qUoJN1S03MJL0AnGJmy+KOpSKlpWX84eYneWb4r9m2dQv6D7qFw/ruzq47tok7tBq7+s4x9Pv5bvzfdYNZv6GENWs3xB1StezWsQ2DjurDgYNuYX1JKU/feT4vvjWdtq2LGbD/7ux3yo2s31BCy+LN4w61RursZ1FQlLB7vTNdVHJg3qKoA8xsQFKTM8DkGXPZcfuWdNiuJQ02K+KYg7vzwhtT4w6rxlasWsN7H87hpMOj0QUabFZE8y0axxxV9ezcYRsmTZ/LmnUbKC0tY/yUT/nlAd0469j9uH3Ey6zfEF2BtXjpqpgjrZm6+llMtaCT9MirTSZoM/s215VJ6iDpI0mPSpol6WlJTSTNlXSNpCmSpknaNWzfVNLDkt6T9L6kI8PyMyUNTyv3+dTlLJJWSbpF0gxJ/5bUU9LrkuZIOiJs00jSI6Gu9yUdkFbuGEnjJH0i6ea0OuZKahmm/yFpcqjj3Fy/T9WxcNFy2rYu/n5+29bFLFy0PMaIcuOLhd+yZYvN+f3/PsZhZ9/KJTc9zuo16+IOq1pmffYVvbt1orh5Uxo33IyD+3ShbetiOrXfmt7dOvLyIxfz/P9dxF6d28Udao3U5c9iQRi0v7JX3uLJW00b7QLcY2a7ASvYODLeYjPrTnRnTerOxT8Br5pZT+AA4BZJTSspv2nYpwvRA26vBw4GjgZSfeoXABZG6jsZGCGpUVjXDTgR2B04UdL2FdRxlpntDfQAhknaqvwGks6VNEnSpEWLF1USstuUktJSpn/yJacftQ//euhiGjdqwD2PvhJ3WNXy8dyvuWPky4y56wKevvMCpn/8JaVlZRQVFlDcrCkHD76VK+/4B4/8z1lxh/qTVWda0LXoCzMbH6ZHA/uG6dR11ZOBDmH6EOAySR8QdbQ3AiprXqwHxoXpacAbZrYhTKfK3TfUjZl9BMwDdg7rXjGz5Wa2FpgJtK+gjmGSPgQmANsDO5XfwMzuN7MeZtajVctWlYRcc21aNWfB10u/n//q66W0adW81uutbW1ataBNq+bs1Tn6MQzotyfTP/4y5qiqb/TYdzngjJs5fMjtLFu5ms/mf8OCb5bx3GsfADBl5jzKzNiqRd3th66rn0URJcRsXvkSR4Iuf4leaj71d2spG09eCjjWzLqFV7vwuK0Sfhh7o7TpDWaWKrMsVa6ZlZHdjTnpfz+nxxIFFHWlHAT0NrM9iS6XSa8/Ft07t+ez+YuYt2Ax6zeUMOblKRzWd4+4w6qxrbdqRputW/DZ/G8AGD/5E3bqsE3MUVVf6gTgdq2LGXjAnjw1bhIvvD6V/XpE7YOO7bamwWZFLFlWd/uh6+xnUcnr4qjyeNA50E5SbzN7l2jgkLeBvTax7YvAhZIuNDOTtJeZvQ/MBc6XVEB0P3uVLl0B3gJOBV6VtDNRq3w20a3tlWkOLDWz1aGvvFcV664VRUWF3HzJCRw77G5KS41Tj+jFbh0TftY8S9dedCzDrhvFhg2ltNt2K269/OS4Q6q2kTedQ3HzppSUlPKHm59kxao1jB77LsOvPJV3Hv8j6zeUMvTqUXGHWSN19bMY3UmYrKs44kjQs4ELJD1M1IVwL3DhJra9jmjQkakhGX8ODATGh+mZRMP5TaliDPcA90qaRtQaP9PM1mU5ktU44DxJs8KxTKhi3bXmkH26cMg+9e9JZF12ass/H/h93GHkxIBzb//Rsg0lpQy5cmQM0dSeuvpZTFZ6jidBl5jZaeWWdUhNmNkkoF+YXgMMKV9A6MI4taLCzWzztOmrK1oX+pcHV7DvX4G/ps0PTJvukLbpYRXV7Zyr2xLWgI4lQTvnXAIpZ+NB50peE7SZzQW65rNO55zLRuoqjiTxFrRzzgV+ktA555JIuXvkVa54gnbOObyLwznnEs1b0M45l1DJSs+eoJ1zDoiSc6G3oJ1zLpkSlp89QTvnXEQoYZ0cnqCdcy7wFrRzziVQdJldsjK0J2jnnINwo0rcQfyQJ2jnnAv8Vm/nnEugaMD+uKP4IU/QzjkX+FUczjmXUAnr4fAE7ZxzKd6Cds65BPI+aOecSyrJr+JwzrmkSlZ69gSdF2XA+pKyuMPIuaYN6+/HZ9GEO+MOoVYU/+zXcYdQK9bNnl/jMqIujmSl6Pr7G+acc1WUrPTsCdo55zZKWIb2BO2cc4F3cTjnXEIlKz17gnbOuY0SlqGT9pRx55yLhUg9U6Xyf5WWJW0v6TVJMyXNkHRRWL6lpJclfRL+L85Ujido55yD78eDzuaVhRLg92bWGegFXCCpM3AZ8IqZ7QS8EuY3yRO0c84FyvJVGTNbaGZTwvRKYBbQFjgSGBE2GwEclakc74N2zjkAhLK/iqOlpElp8/eb2f0Vlip1APYC/gO0NrOFYdV/gdaZKvEE7ZxzQRWusltsZj0qL0+bA38HfmNmK9K/AMzMJFmm/b2LwznnyL57I9scLmkzouT8qJmNCYu/ltQmrG8DfJOpDE/QzjmXkqMMraip/BAwy8z+nLZqLDAoTA8Cns1UjndxOOdckMMB+/cBTgemSfogLPsjcCPwpKSzgXnACZkK8QTtnHNBru70NrO32XRb+8Bsy/EE7Zxz8P110EniCdo55wJ/JqFzziWQ8Ba0c84lVsLysydo55z7XsIytCdo55wLfMB+55xLqGSlZ0/Qzjm3UcIytCfoemLtug0cOfQO1m8oobS0jIEHdOOSXw2IO6wau/C6R3lp/HRaFm/B+Mf+GHc4ObPg66VccM0oFn27EkmcflQfhpzYL+6wqm3ISf0YdFQfkBj5j/Hc99jrAPzqhP055/j9KC0zXn57OlfdlfHO5lilBuxPklpJ0JJaAKeY2T2VbDcX6GFmi2sjjgrq+yvwvJk9XcX9zgNWm9nIWgksBxo2KGLM8Atp2qQhG0pK+eWQ2+nfezd6dN0h7tBq5OSBP+ec4/ty/jWj4g4lpwoLC7hm2NHsuev2rPpuLQeeeQv9eu7CLju0iTu0KtutYxsGHdWHAwfdwvqSUp6+83xefGs6bVsXM2D/3dnvlBtZv6GElsWbxx1qZj+hG1VaAOcDGRN0TUgqMrOS2io/nZndl496akISTZs0BGBDSSklJaVVGds2sfrs1Yn5Xy2JO4yc26Zlc7Zp2RyAzZs2YucOrVn4zfI6maB37rANk6bPZc26DQCMn/IpvzygG912a8ftI15m/Ybo13Tx0lVxhpmVpP3G1NZodjcCHSV9IGmipOdTKyQNl3Rm2raXSJom6T1JncI2rST9Pew7UdI+YfnVkkZJGg+MktRa0jOSPgyvPpI6SJqeVt/Fkq4uH6CkAyW9H+p+WFLDsPzG8ByxqZJuTav34jA9LG394zl/52qgtLSM/mfcRJcBf2T/nruwd5cOcYfksjD/qyVM+3gBe3dtH3co1TLrs6/o3a0Txc2b0rjhZhzcpwttWxfTqf3W9O7WkZcfuZjn/+8i9urcLu5QKxEN2J/NK19qqwV9GdDVzLpJ6gdcnGHb5Wa2u6QzgNuBgcAdwF/M7G1J7YAXgd3C9p2Bfc1sjaQngDfM7GhJhcDmQMaHMAJIagT8FTjQzD6WNBIYKmkUcDSwaxhMu8Umjm0HM1u3ifWxKSws4NWRl7J85WrOvOxBZn32Fbt13DbusFwGq1avY/DlD3H9b45hi6aN4w6nWj6e+zV3jHyZMXddwOo165n+8ZeUlpVRVFhAcbOmHDz4Vrp3bs8j/3MW3Y66Ou5wM0raH51JGA/6sbT/e4fpg4DhYZi+sUCz8GQCgLFmtiZM9wfuBTCzUjNbnmWduwCfm9nHYX4E0BdYDqwFHpJ0DLC6gn2nAo9KOo3owZAVknSupEmSJi1ZtCjLsHKj+RZN2Lf7Trw2YVZe63VVs6GklMGXP8Rxv+jBwAP2jDucGhk99l0OOONmDh9yO8tWruaz+d+w4JtlPPdaNNLmlJnzKDNjqxbJ7YfO9YD9uZCPBF1Srp5G5dZbBdMFQC8z6xZebc0s1YH1XQ3r26TQp90TeJqoJT+ugs0OB+4GugMTJVX4V4iZ3W9mPcysx1atWmUbQrUtXrqS5Suj75M1a9fzxsTZdGqf8XFnLkZmxm9u+Bs7d2jN0FP6xx1OjaVOAG7XupiBB+zJU+Mm8cLrU9mvx84AdGy3NQ02K2LJsoT3QycsQ9dWF8dKYIswPQ/oHPp4GxONhfp22rYnEvVZnwi8G5a9BFwI3AIgqZuZfcCPvQIMBW5P6+L4Gtha0lbAKipOtLOBDpI6mdmnRANrvxFa6U3M7IXQzz0nfSdJBcD2ZvaapLeBk0Kdy7J/a2rH10tWMOza0ZSWGWVmHNm/G4fs2zXusGrsV1c8wvgpn7Jk2Sq6Dvx/XHbuAE47onflOybcfz6cw5P/mkjnjtvS7/SbAPjT0IEc3KdLzJFVz8ibzqG4eVNKSkr5w81PsmLVGkaPfZfhV57KO4//kfUbShl6dfKvxPlJXGZnZkskjQ8n6/4FPPg+C88AAAuOSURBVAlMBz4H3i+3ebGkqcA64OSwbBhwd1heBLwJnFdBVRcB94enE5QCQ83sXUnXAu8BC4CPKohvraTBwFOhBTwRuA/YEng29FEL+F25XQuB0ZKah/V3mlnsyRmgS6e2vDLy0rjDyLkHrh8cdwi1ole3jiyacGfcYeTMgHNv/9GyDSWlDLkysVemVihpfdAyy/hQWZcDe+3dw94Y/17cYeRcUUHCPs05VFZPfy9a9RoWdwi1Yt3sJylb/U2NPpB77LW3vfDqO1ltu/2WjSZn81TvmvI7CZ1z7nvJanR4gnbOOXzAfuecS7SE5WdP0M45l+ItaOecS6ikjV/jCdo554JkpWdP0M45B0TdGwlrQHuCds65lJ/EnYTOOVcnJSs/e4J2zrmUhOVnT9DOORcRBQnrhPYE7ZxzJPNOwiQM2O+cc64C3oJ2zrkgaS1oT9DOORf4ZXbOOZdEfqOKc84lUxJPEnqCds65wLs4nHMuoZLWgvbL7JxzLlCWr6zKkg6VNFvSp5Iuq048nqCdcy4lRxlaUiFwN3AY0Bk4WVLnqobjCdo554jyboGU1SsLPYFPzWyOma0HHgeOrGpM3gedBx9Mmby4eePCeXmqriWwOE915VN9PS6ov8eWz+NqX9MCpkyZ/GLjzdQyy80bSZqUNn+/md2fNt8W+CJt/kvg51WNyRN0HphZq3zVJWmSmfXIV335Ul+PC+rvsdW14zKzQ+OOoTzv4nDOudxbAGyfNr9dWFYlnqCdcy73JgI7SdpBUgPgJGBsVQvxLo765/7KN6mT6utxQf09tvp6XJUysxJJvwZeBAqBh81sRlXLkZnlPDjnnHM1510czjmXUJ6gnXMuoTxB13OSrpV0UAXL+0l6Po6Y4iBprpT1Na51mqQXJLVIm28h6fws9svreyTpr5KOq8Z+50k6ozZiSho/SVjPmdmVccdQU5KKzKwk7jjqCjMbUG5RC+B84J7aqjOfPyMzuy8f9SSBt6ATTtIZkqZK+lDSKEkdJL0alr0iqZ2k5pLmSSoI+zSV9IWkzdJbKWHwlo8kTQGOyfNxdJA0S9IDkmZIeklSY0ndJE0Ix/OMpOKw/euSbg93a10U5v8iaVIo52eSxkj6RNL1afX8Q9LkUMe5NYz3I0mPhvqeltQktDKvkTRF0jRJu4btm0p6WNJ7kt6XdGRYfqak4WnlPi+pX5heJemWEOu/JfUMxzlH0hFhm0aSHgl1vS/pgLRyx0gaF96Dm9Pq+L4lLOkfwBSgc/hMTEz/y0nScElnph36JaGu9yR1Ctu0kvT3sO9ESfuE5VeHz+R4YJSk1uFn+GF49Qnv4/S0+i6WdHUF7/eB4fimhfexYVh+o6SZ4fNxa1q9F4fpYWnrH6/mjzuxPEEnmKQuwBVAfzPbE7gIuAsYYWZ7AI8Cd5rZcuADYP+w60DgRTPbkFZWI+AB4JfA3sA2eTuQjXYC7jazLsAy4FhgJHBpOJ5pwFVp2zcwsx5mdluYXx/uTLsPeBa4AOgKnClpq7DNWWa2N9ADGJa2vDp2Ae4xs92AFUStUIDFZtYduBe4OCz7E/CqmfUEDgBukdS0kvKbhn26ACuB64GDgaOBa8M2FwBmZrsDJwMjws8SoBtwIrA7cKKk9BsjUs4CugOzgOXAdZXEtDzUNRy4PSy7A/iLmf2M6Gf2YNr2nYGDzOxk4E7gjfBZ7Q5kdVlZOJ6/AieGuouAoeFndzTQJXw+rq9g98uAvcL687Kpry7xBJ1s/YGnzGwxgJl9C/QG/hbWjwL2DdNPEP2yQnRR/BPlytoV+NzMPrHo2srRtRn4JnxuZh+E6clAR6CFmb0Rlo0A+qZtX/4YUhf6TwNmmNlCM1sHzGHjXVvDJH0ITAjLdqpBvF+Y2fgwPZqN7/WYtGPoEKYPAS6T9AHwOtAIaFdJ+euBcWF6GlFy2xCmU+XuG+rGzD4C5gE7h3WvmNlyM1sLzKTi8SiGAS8AOxK9H9tVEtNjaf/3DtMHAcPDsY0FmknaPKwba2ZrwnR/oi8tzKw0NByysQvRZ+PjMJ/6HCwH1gIPSToGWF3BvlOBRyWdBtS7bjBP0PXHWOBQSVsStZBfjTmeiqxLmy4l6hvN5LtN7F9WrqwyoCh0HRwE9A6tuPeJEmV1lb9JIDWfqruUjedxBBxrZt3Cq52ZzSJKGum/Z+nxbLCNNyJ8f0xmVkZ254fKv58/2Cft/TgG+Izo/SjMEE/6MaZPFwC90o6trZmtCuvK/4zKy3T8GYU+7Z7A00R/FY6rYLPDiYb17A5MlFSvzqt5gk62V4HjU3+mh+T7DlELGeBU4C2A8AszkejP0efNrLRcWR8BHSR1DPMn13Ls2VgOLJW0X5g/HXgjw/aVaQ4sNbPVoW+4Vw3jaycp1Yo8BXg7w7YvAhdK0ViUkvYKy+cC3SQVhC6InlWM4S2inzOSdiZqlc/Oct/mwFJgEVBM9H78l6g/uqGiKz0OLLfPiWn/vxumXwIuTG0gqdsm6nsFGBq2KZTUHPga2FrSVqFfeWAF+80m+mx2CvOnA2+EVnpzM3sB+C2wZ/pOis65bG9mrwGXhuPdnHqkXn3b1DdmNkPSDUQf1lKiFtCFwCOS/kD0izc4bZcngKeAfhWUtVbRSbN/SlpN9Iu/RS0fQjYGAfdJakLUVTG4ku0zGQecJ2kW0S/9hBrGNhu4QNLDRF0I95KWqMq5jqjPdmpIHJ8TJaPxYXomUT/wlCrGcA9wr6RpRK3RM81snbIbk3gcUb/s20Qt9FKiPuQngekhrvfL7VMsaSpR6zz1JT4MuDssLwLepOL+3ouA+yWdHeoaambvSroWeI9osKCPyu8UPpuDgadCC3gi0XmGLYFnQx+1gN+V27UQGB2+CER0PmZZNm9MXeG3ejtXAUkdiP4S6RpzKO4nzLs4nHMuobwF7ZxzCeUtaOecSyhP0M45l1CeoJ1zLqE8QbvYSSqV9IGk6ZKeCpfcVbes9LFHHpTUOcO2/ST1qUYdFY76tqnl5bZZlWl9Bdt/P+6E++nxBO2SYE24Q60r0e3PP7jGtrp3h5nZOWY2M8Mm/YAqJ2jn8sUTtEuat4BOoXX7lqSxwMxwZ9otYTS1qZKGACgyXNJsSf8Gtk4VpGhkuB5h+lBFI9B9qGgUwA5EXwS/Da33/bTpUdu2UjT63gxJDxLdFJGRMoyqp2hUvhkhjlZhWUdFI9NNDse9ay7eTFe3+Z2ELjFCS/kwNo650B3oamafhyS33Mx+Fm4ZHi/pJWAvosF2OgOtie7Ye7hcua2IRvLrG8ra0sy+lXQfsMrMUsNY/o1o1La3JbUjun17N6IR9t42s2slHQ6cncXhnBXqaEw0RsTfzWwJ0Qh2k8zst5KuDGX/mugBq+eZ2SeSfk50B2H/aryNrh7xBO2SoLGikdIgakE/RNT18J6ZfR6WHwLsoY1P4GhONFJdX+CxMPbIV5IqGiSqF/BmqqwwKmBFDiIapyI1nxq1rS9h/Gwz+6ekpVkc0zBJR4fp1Kh6S4huuU6N0jcaGBPq6EN0q3Nq/4ZZ1OHqOU/QLgnWmNkPBuAJiSp9pDQBF5rZi+W2K//0kJpIjdq2toJYsqYfjqq3WtLrbHoUNwv1Liv/HjjnfdCurniRaBD3zSAa2U3RgPhvEg1WXyipDdFg+eVNAPpK2iHsu2VYvpIfDhi1qVHb3iQazQ5JhxGNDJdJplH1CoDUXwGnEHWdrAA+l3R8qEOSfjBym/tp8gTt6ooHifqXpyh6hNL/Ef0F+AzwSVg3ko1DZH7PzBYB5xJ1J3zIxi6G54CjUycJiUZt6xFOQs5k49Uk1xAl+BlEXR3zK4l1HNH41LOAG/nhqHrfAT3DMfRn45NTTgXODvHNAI7M4j1x9ZyPxeGccwnlLWjnnEsoT9DOOZdQnqCdcy6hPEE751xCeYJ2zrmE8gTtnHMJ5QnaOecS6v8D/x/T6QGuzB0AAAAASUVORK5CYII=\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "machine_shape": "hm",
      "name": "Pre-trained models.ipynb",
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}